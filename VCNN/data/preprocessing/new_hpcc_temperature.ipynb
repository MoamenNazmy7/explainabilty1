{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"service1906_1506.json\") as of:\n",
    "    data = json.load(of)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "computes = [c for c in data.keys() if c!=\"timespan\"]\n",
    "variables = [v for v in data[computes[0]] if v!='index' and v!='arrJob_scheduling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c= compute-1-26\n",
      "v= arrTemperature\n"
     ]
    }
   ],
   "source": [
    "#Check empty array\n",
    "def getEmptyArr(data, c):\n",
    "    cObj = data[c]\n",
    "    cDf = pd.DataFrame()\n",
    "    cDf['compute'] = [c for _ in data['timespan']]\n",
    "    cDf['timespan'] = data['timespan']\n",
    "    for v in variables:\n",
    "        vArr = np.array(cObj[v])\n",
    "        if len(vArr)==0:\n",
    "            print('c=', c)\n",
    "            print('v=', v)\n",
    "for c in computes:\n",
    "    getEmptyArr(data, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTarget(cDf, predictedVar, predictedStep, target):\n",
    "    cDf[target] = cDf[predictedVar].shift(-predictedStep)\n",
    "    cDf.dropna(inplace=True)\n",
    "    return cDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getComputeDf(data, c, predictedVar, predictedStep, target):\n",
    "    cObj = data[c]\n",
    "    cDf = pd.DataFrame()\n",
    "    cDf['compute'] = [c for _ in data['timespan']]\n",
    "    cDf['timespan'] = data['timespan']\n",
    "    for v in variables:\n",
    "        vArr = np.array(cObj[v])\n",
    "        if len(vArr)==0:\n",
    "            return None\n",
    "        else:\n",
    "            for i in range(len(vArr[0])):\n",
    "                cDf[v+str(i)] = vArr[:, i]\n",
    "    cDf['timespan'] = pd.to_datetime(cDf['timespan'])\n",
    "    return addTarget(cDf, predictedVar, predictedStep, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitTrainTest(predictedVar):\n",
    "    target = predictedVar + \"_target\"\n",
    "    predictedSteps = 4\n",
    "    df = pd.concat([x for x in [getComputeDf(data, c, predictedVar, predictedSteps, target) for c in computes] if type(x)!=\"NoneType\"])\n",
    "    \n",
    "    df = df.reset_index().drop('index', axis=1)\n",
    "    features = [x for x in df.columns if x not in ['compute', 'timespan', target]]\n",
    "        \n",
    "    X_dfs = []\n",
    "    y = []\n",
    "    numberOfSequences = 1\n",
    "    sequenceSteps = 20\n",
    "    # generate training data.\n",
    "    for compute in computes:\n",
    "        cDf = df[df['compute']==compute]\n",
    "        if(len(cDf) > sequenceSteps):\n",
    "            randSteps = np.random.randint(0, len(cDf)-sequenceSteps, numberOfSequences)\n",
    "            for randStep in randSteps:\n",
    "                X_dfs.append(cDf.iloc[randStep:randStep+sequenceSteps])\n",
    "                y.append(X_dfs[-1][target].values[-1])\n",
    "\n",
    "    X_train_dfs, X_test_dfs, y_train, y_test = train_test_split(X_dfs, y, test_size=0.33)\n",
    "            \n",
    "    #Scale data\n",
    "\n",
    "    # combine the training data to create a scaler\n",
    "    train_dfs = pd.concat(X_train_dfs)\n",
    "\n",
    "    scaler = StandardScaler().fit(train_dfs[features].values)\n",
    "    \n",
    "    X_train = np.array([scaler.transform(item[features].values) for item in X_train_dfs])\n",
    "    X_test = np.array([scaler.transform(item[features].values) for item in X_test_dfs])\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "\n",
    "# from keras import backend as K\n",
    "# K.set_session(K.tf.Session(config=K.tf.ConfigProto(intra_op_parallelism_threads=36, inter_op_parallelism_threads=36)))\n",
    "\n",
    "\n",
    "def createModel(l1Nodes, l2Nodes, d1Nodes, d2Nodes, inputShape):\n",
    "    # input layer\n",
    "    lstm1 = LSTM(l1Nodes, input_shape=inputShape, return_sequences=True, kernel_regularizer=regularizers.l2(0.1))\n",
    "    do1 = Dropout(0.2)\n",
    "    \n",
    "    lstm2 = LSTM(l2Nodes, return_sequences=True, kernel_regularizer=regularizers.l2(0.1))\n",
    "    do2 = Dropout(0.2)\n",
    "    \n",
    "    flatten = Flatten()\n",
    "    \n",
    "    dense1 = Dense(d1Nodes, activation='relu')\n",
    "    do3 = Dropout(0.2)\n",
    "    \n",
    "    dense2 = Dense(d2Nodes, activation='relu')\n",
    "    do4 = Dropout(0.2)\n",
    "    \n",
    "    # output layer\n",
    "    outL = Dense(1, activation='relu')\n",
    "    # combine the layers\n",
    "#     layers = [lstm1, do1, lstm2, do2, dense1, do3, dense2, do4, outL]\n",
    "    layers = [lstm1, lstm2, flatten,  dense1, dense2, outL]\n",
    "    # create the model\n",
    "    model = Sequential(layers)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-23 18:09:25.736849\n",
      "arrTemperature0\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 3511.3299 - val_loss: 4021.1111\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4021.11108, saving model to arrTemperature0_best_model_fold1_18_09_48.h5\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 0s 588us/step - loss: 3490.0395 - val_loss: 3986.8744\n",
      "\n",
      "Epoch 00002: val_loss improved from 4021.11108 to 3986.87444, saving model to arrTemperature0_best_model_fold1_18_09_48.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 0s 552us/step - loss: 3424.7190 - val_loss: 3896.5302\n",
      "\n",
      "Epoch 00003: val_loss improved from 3986.87444 to 3896.53018, saving model to arrTemperature0_best_model_fold1_18_09_48.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 0s 569us/step - loss: 3266.8588 - val_loss: 3696.6482\n",
      "\n",
      "Epoch 00004: val_loss improved from 3896.53018 to 3696.64823, saving model to arrTemperature0_best_model_fold1_18_09_48.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 0s 573us/step - loss: 2928.7029 - val_loss: 3292.8254\n",
      "\n",
      "Epoch 00005: val_loss improved from 3696.64823 to 3292.82538, saving model to arrTemperature0_best_model_fold1_18_09_48.h5\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 0s 594us/step - loss: 2363.2587 - val_loss: 2673.9084\n",
      "\n",
      "Epoch 00006: val_loss improved from 3292.82538 to 2673.90838, saving model to arrTemperature0_best_model_fold1_18_09_48.h5\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 0s 599us/step - loss: 1673.4645 - val_loss: 1478.9465\n",
      "\n",
      "Epoch 00007: val_loss improved from 2673.90838 to 1478.94651, saving model to arrTemperature0_best_model_fold1_18_09_48.h5\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 0s 574us/step - loss: 779.4978 - val_loss: 618.6962\n",
      "\n",
      "Epoch 00008: val_loss improved from 1478.94651 to 618.69625, saving model to arrTemperature0_best_model_fold1_18_09_48.h5\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 0s 581us/step - loss: 359.6573 - val_loss: 336.1067\n",
      "\n",
      "Epoch 00009: val_loss improved from 618.69625 to 336.10665, saving model to arrTemperature0_best_model_fold1_18_09_48.h5\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 0s 572us/step - loss: 448.5051 - val_loss: 431.7892\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 336.10665\n",
      "Epoch 11/40\n",
      "208/208 [==============================] - 0s 549us/step - loss: 627.8965 - val_loss: 527.9338\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 336.10665\n",
      "Epoch 12/40\n",
      "208/208 [==============================] - 0s 573us/step - loss: 768.4152 - val_loss: 758.5278\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 336.10665\n",
      "Epoch 00012: early stopping\n",
      "104/104 [==============================] - 0s 1ms/step\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 3610.7181 - val_loss: 3592.4869\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3592.48693, saving model to arrTemperature0_best_model_fold2_18_10_04.h5\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 0s 650us/step - loss: 3342.4110 - val_loss: 3117.9351\n",
      "\n",
      "Epoch 00002: val_loss improved from 3592.48693 to 3117.93510, saving model to arrTemperature0_best_model_fold2_18_10_04.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 0s 587us/step - loss: 2666.4986 - val_loss: 2134.3228\n",
      "\n",
      "Epoch 00003: val_loss improved from 3117.93510 to 2134.32275, saving model to arrTemperature0_best_model_fold2_18_10_04.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 0s 588us/step - loss: 1664.8195 - val_loss: 1083.7334\n",
      "\n",
      "Epoch 00004: val_loss improved from 2134.32275 to 1083.73344, saving model to arrTemperature0_best_model_fold2_18_10_04.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 0s 606us/step - loss: 876.1752 - val_loss: 661.3752\n",
      "\n",
      "Epoch 00005: val_loss improved from 1083.73344 to 661.37522, saving model to arrTemperature0_best_model_fold2_18_10_04.h5\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 0s 594us/step - loss: 755.2546 - val_loss: 671.2046\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 661.37522\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 0s 639us/step - loss: 711.7001 - val_loss: 590.2944\n",
      "\n",
      "Epoch 00007: val_loss improved from 661.37522 to 590.29441, saving model to arrTemperature0_best_model_fold2_18_10_04.h5\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 0s 614us/step - loss: 617.6051 - val_loss: 547.2541\n",
      "\n",
      "Epoch 00008: val_loss improved from 590.29441 to 547.25414, saving model to arrTemperature0_best_model_fold2_18_10_04.h5\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 0s 643us/step - loss: 534.5511 - val_loss: 453.2157\n",
      "\n",
      "Epoch 00009: val_loss improved from 547.25414 to 453.21571, saving model to arrTemperature0_best_model_fold2_18_10_04.h5\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 0s 625us/step - loss: 425.5649 - val_loss: 353.6436\n",
      "\n",
      "Epoch 00010: val_loss improved from 453.21571 to 353.64365, saving model to arrTemperature0_best_model_fold2_18_10_04.h5\n",
      "Epoch 11/40\n",
      "208/208 [==============================] - 0s 595us/step - loss: 317.7904 - val_loss: 248.0345\n",
      "\n",
      "Epoch 00011: val_loss improved from 353.64365 to 248.03446, saving model to arrTemperature0_best_model_fold2_18_10_04.h5\n",
      "Epoch 12/40\n",
      "208/208 [==============================] - 0s 607us/step - loss: 208.6584 - val_loss: 158.2642\n",
      "\n",
      "Epoch 00012: val_loss improved from 248.03446 to 158.26421, saving model to arrTemperature0_best_model_fold2_18_10_04.h5\n",
      "Epoch 13/40\n",
      "208/208 [==============================] - 0s 619us/step - loss: 127.4667 - val_loss: 95.1029\n",
      "\n",
      "Epoch 00013: val_loss improved from 158.26421 to 95.10289, saving model to arrTemperature0_best_model_fold2_18_10_04.h5\n",
      "Epoch 14/40\n",
      "208/208 [==============================] - 0s 669us/step - loss: 87.3255 - val_loss: 71.5302\n",
      "\n",
      "Epoch 00014: val_loss improved from 95.10289 to 71.53017, saving model to arrTemperature0_best_model_fold2_18_10_04.h5\n",
      "Epoch 15/40\n",
      "208/208 [==============================] - 0s 673us/step - loss: 80.0583 - val_loss: 69.2189\n",
      "\n",
      "Epoch 00015: val_loss improved from 71.53017 to 69.21893, saving model to arrTemperature0_best_model_fold2_18_10_04.h5\n",
      "Epoch 16/40\n",
      "208/208 [==============================] - 0s 590us/step - loss: 80.6023 - val_loss: 66.3867\n",
      "\n",
      "Epoch 00016: val_loss improved from 69.21893 to 66.38671, saving model to arrTemperature0_best_model_fold2_18_10_04.h5\n",
      "Epoch 17/40\n",
      "208/208 [==============================] - 0s 625us/step - loss: 77.9580 - val_loss: 62.9086\n",
      "\n",
      "Epoch 00017: val_loss improved from 66.38671 to 62.90860, saving model to arrTemperature0_best_model_fold2_18_10_04.h5\n",
      "Epoch 18/40\n",
      "208/208 [==============================] - 0s 594us/step - loss: 72.7669 - val_loss: 61.9704\n",
      "\n",
      "Epoch 00018: val_loss improved from 62.90860 to 61.97044, saving model to arrTemperature0_best_model_fold2_18_10_04.h5\n",
      "Epoch 19/40\n",
      "208/208 [==============================] - 0s 604us/step - loss: 70.7378 - val_loss: 60.0868\n",
      "\n",
      "Epoch 00019: val_loss improved from 61.97044 to 60.08681, saving model to arrTemperature0_best_model_fold2_18_10_04.h5\n",
      "Epoch 20/40\n",
      "208/208 [==============================] - 0s 599us/step - loss: 72.3948 - val_loss: 58.6519\n",
      "\n",
      "Epoch 00020: val_loss improved from 60.08681 to 58.65190, saving model to arrTemperature0_best_model_fold2_18_10_04.h5\n",
      "Epoch 21/40\n",
      "208/208 [==============================] - 0s 584us/step - loss: 70.0297 - val_loss: 58.7588\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 58.65190\n",
      "Epoch 22/40\n",
      "208/208 [==============================] - 0s 686us/step - loss: 67.2867 - val_loss: 55.6851\n",
      "\n",
      "Epoch 00022: val_loss improved from 58.65190 to 55.68507, saving model to arrTemperature0_best_model_fold2_18_10_04.h5\n",
      "Epoch 23/40\n",
      "208/208 [==============================] - 0s 534us/step - loss: 64.4183 - val_loss: 55.7228\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 55.68507\n",
      "Epoch 24/40\n",
      "208/208 [==============================] - 0s 565us/step - loss: 62.4477 - val_loss: 52.8542\n",
      "\n",
      "Epoch 00024: val_loss improved from 55.68507 to 52.85418, saving model to arrTemperature0_best_model_fold2_18_10_04.h5\n",
      "Epoch 25/40\n",
      "208/208 [==============================] - 0s 546us/step - loss: 60.9314 - val_loss: 51.2931\n",
      "\n",
      "Epoch 00025: val_loss improved from 52.85418 to 51.29311, saving model to arrTemperature0_best_model_fold2_18_10_04.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/40\n",
      "208/208 [==============================] - 0s 598us/step - loss: 58.7488 - val_loss: 51.7130\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 51.29311\n",
      "Epoch 27/40\n",
      "208/208 [==============================] - 0s 568us/step - loss: 57.1699 - val_loss: 49.7711\n",
      "\n",
      "Epoch 00027: val_loss improved from 51.29311 to 49.77112, saving model to arrTemperature0_best_model_fold2_18_10_04.h5\n",
      "Epoch 28/40\n",
      "208/208 [==============================] - 0s 538us/step - loss: 56.7085 - val_loss: 50.4343\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 49.77112\n",
      "Epoch 29/40\n",
      "208/208 [==============================] - 0s 541us/step - loss: 54.2914 - val_loss: 47.8505\n",
      "\n",
      "Epoch 00029: val_loss improved from 49.77112 to 47.85050, saving model to arrTemperature0_best_model_fold2_18_10_04.h5\n",
      "Epoch 30/40\n",
      "208/208 [==============================] - 0s 558us/step - loss: 53.7665 - val_loss: 46.4779\n",
      "\n",
      "Epoch 00030: val_loss improved from 47.85050 to 46.47787, saving model to arrTemperature0_best_model_fold2_18_10_04.h5\n",
      "Epoch 31/40\n",
      "208/208 [==============================] - 0s 556us/step - loss: 51.0967 - val_loss: 47.7208\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 46.47787\n",
      "Epoch 32/40\n",
      "208/208 [==============================] - 0s 547us/step - loss: 50.2718 - val_loss: 44.2836\n",
      "\n",
      "Epoch 00032: val_loss improved from 46.47787 to 44.28356, saving model to arrTemperature0_best_model_fold2_18_10_04.h5\n",
      "Epoch 33/40\n",
      "208/208 [==============================] - 0s 528us/step - loss: 50.5255 - val_loss: 54.7700\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 44.28356\n",
      "Epoch 34/40\n",
      "208/208 [==============================] - 0s 556us/step - loss: 52.2899 - val_loss: 45.1090\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 44.28356\n",
      "Epoch 35/40\n",
      "208/208 [==============================] - 0s 521us/step - loss: 49.9035 - val_loss: 53.3408\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 44.28356\n",
      "Epoch 00035: early stopping\n",
      "104/104 [==============================] - 0s 1ms/step\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 3864.1756 - val_loss: 3239.0317\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3239.03166, saving model to arrTemperature0_best_model_fold3_18_10_23.h5\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 0s 637us/step - loss: 3750.0389 - val_loss: 3060.0756\n",
      "\n",
      "Epoch 00002: val_loss improved from 3239.03166 to 3060.07565, saving model to arrTemperature0_best_model_fold3_18_10_23.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 0s 571us/step - loss: 3429.5103 - val_loss: 2685.0258\n",
      "\n",
      "Epoch 00003: val_loss improved from 3060.07565 to 2685.02579, saving model to arrTemperature0_best_model_fold3_18_10_23.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 0s 564us/step - loss: 2887.6340 - val_loss: 2182.9172\n",
      "\n",
      "Epoch 00004: val_loss improved from 2685.02579 to 2182.91720, saving model to arrTemperature0_best_model_fold3_18_10_23.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 0s 577us/step - loss: 2239.8824 - val_loss: 1691.9682\n",
      "\n",
      "Epoch 00005: val_loss improved from 2182.91720 to 1691.96822, saving model to arrTemperature0_best_model_fold3_18_10_23.h5\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 0s 569us/step - loss: 1653.4081 - val_loss: 1311.4766\n",
      "\n",
      "Epoch 00006: val_loss improved from 1691.96822 to 1311.47655, saving model to arrTemperature0_best_model_fold3_18_10_23.h5\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 0s 576us/step - loss: 1208.7745 - val_loss: 1061.1584\n",
      "\n",
      "Epoch 00007: val_loss improved from 1311.47655 to 1061.15843, saving model to arrTemperature0_best_model_fold3_18_10_23.h5\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 0s 575us/step - loss: 933.7494 - val_loss: 936.3023\n",
      "\n",
      "Epoch 00008: val_loss improved from 1061.15843 to 936.30230, saving model to arrTemperature0_best_model_fold3_18_10_23.h5\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 0s 572us/step - loss: 800.7394 - val_loss: 905.0504\n",
      "\n",
      "Epoch 00009: val_loss improved from 936.30230 to 905.05041, saving model to arrTemperature0_best_model_fold3_18_10_23.h5\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 0s 582us/step - loss: 770.0794 - val_loss: 910.5610\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 905.05041\n",
      "Epoch 11/40\n",
      "208/208 [==============================] - 0s 563us/step - loss: 779.4752 - val_loss: 893.8173\n",
      "\n",
      "Epoch 00011: val_loss improved from 905.05041 to 893.81731, saving model to arrTemperature0_best_model_fold3_18_10_23.h5\n",
      "Epoch 12/40\n",
      "208/208 [==============================] - 0s 564us/step - loss: 763.1064 - val_loss: 893.9836\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 893.81731\n",
      "Epoch 13/40\n",
      "208/208 [==============================] - 0s 569us/step - loss: 746.3367 - val_loss: 875.9829\n",
      "\n",
      "Epoch 00013: val_loss improved from 893.81731 to 875.98286, saving model to arrTemperature0_best_model_fold3_18_10_23.h5\n",
      "Epoch 14/40\n",
      "208/208 [==============================] - 0s 587us/step - loss: 727.0691 - val_loss: 843.8150\n",
      "\n",
      "Epoch 00014: val_loss improved from 875.98286 to 843.81500, saving model to arrTemperature0_best_model_fold3_18_10_23.h5\n",
      "Epoch 15/40\n",
      "208/208 [==============================] - 0s 579us/step - loss: 698.3336 - val_loss: 798.6699\n",
      "\n",
      "Epoch 00015: val_loss improved from 843.81500 to 798.66986, saving model to arrTemperature0_best_model_fold3_18_10_23.h5\n",
      "Epoch 16/40\n",
      "208/208 [==============================] - 0s 568us/step - loss: 657.8603 - val_loss: 739.9039\n",
      "\n",
      "Epoch 00016: val_loss improved from 798.66986 to 739.90386, saving model to arrTemperature0_best_model_fold3_18_10_23.h5\n",
      "Epoch 17/40\n",
      "208/208 [==============================] - 0s 594us/step - loss: 602.5734 - val_loss: 655.0673\n",
      "\n",
      "Epoch 00017: val_loss improved from 739.90386 to 655.06730, saving model to arrTemperature0_best_model_fold3_18_10_23.h5\n",
      "Epoch 18/40\n",
      "208/208 [==============================] - 0s 535us/step - loss: 519.6066 - val_loss: 544.5632\n",
      "\n",
      "Epoch 00018: val_loss improved from 655.06730 to 544.56325, saving model to arrTemperature0_best_model_fold3_18_10_23.h5\n",
      "Epoch 19/40\n",
      "208/208 [==============================] - 0s 587us/step - loss: 421.7686 - val_loss: 408.0512\n",
      "\n",
      "Epoch 00019: val_loss improved from 544.56325 to 408.05123, saving model to arrTemperature0_best_model_fold3_18_10_23.h5\n",
      "Epoch 20/40\n",
      "208/208 [==============================] - 0s 566us/step - loss: 298.6719 - val_loss: 264.5789\n",
      "\n",
      "Epoch 00020: val_loss improved from 408.05123 to 264.57886, saving model to arrTemperature0_best_model_fold3_18_10_23.h5\n",
      "Epoch 21/40\n",
      "208/208 [==============================] - 0s 566us/step - loss: 177.8658 - val_loss: 153.5628\n",
      "\n",
      "Epoch 00021: val_loss improved from 264.57886 to 153.56279, saving model to arrTemperature0_best_model_fold3_18_10_23.h5\n",
      "Epoch 22/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 100.4389 - val_loss: 118.4960\n",
      "\n",
      "Epoch 00022: val_loss improved from 153.56279 to 118.49599, saving model to arrTemperature0_best_model_fold3_18_10_23.h5\n",
      "Epoch 23/40\n",
      "208/208 [==============================] - 0s 564us/step - loss: 76.0398 - val_loss: 137.4029\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 118.49599\n",
      "Epoch 24/40\n",
      "208/208 [==============================] - 0s 543us/step - loss: 77.7663 - val_loss: 127.6699\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 118.49599\n",
      "Epoch 25/40\n",
      "208/208 [==============================] - 0s 534us/step - loss: 66.0644 - val_loss: 111.2216\n",
      "\n",
      "Epoch 00025: val_loss improved from 118.49599 to 111.22165, saving model to arrTemperature0_best_model_fold3_18_10_23.h5\n",
      "Epoch 26/40\n",
      "208/208 [==============================] - 0s 536us/step - loss: 58.5908 - val_loss: 106.1538\n",
      "\n",
      "Epoch 00026: val_loss improved from 111.22165 to 106.15379, saving model to arrTemperature0_best_model_fold3_18_10_23.h5\n",
      "Epoch 27/40\n",
      "208/208 [==============================] - 0s 569us/step - loss: 55.9028 - val_loss: 101.8734\n",
      "\n",
      "Epoch 00027: val_loss improved from 106.15379 to 101.87343, saving model to arrTemperature0_best_model_fold3_18_10_23.h5\n",
      "Epoch 28/40\n",
      "208/208 [==============================] - 0s 585us/step - loss: 52.7717 - val_loss: 108.3053\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 101.87343\n",
      "Epoch 29/40\n",
      "208/208 [==============================] - 0s 584us/step - loss: 49.9751 - val_loss: 102.8359\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 101.87343\n",
      "Epoch 30/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 0s 576us/step - loss: 47.0262 - val_loss: 103.1443\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 101.87343\n",
      "Epoch 00030: early stopping\n",
      "104/104 [==============================] - 0s 1ms/step\n",
      "arrTemperature1\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 2273.3446 - val_loss: 2089.0007\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2089.00071, saving model to arrTemperature1_best_model_fold1_18_11_06.h5\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 0s 551us/step - loss: 2234.0167 - val_loss: 2009.9847\n",
      "\n",
      "Epoch 00002: val_loss improved from 2089.00071 to 2009.98473, saving model to arrTemperature1_best_model_fold1_18_11_06.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 0s 588us/step - loss: 2140.0529 - val_loss: 1855.1820\n",
      "\n",
      "Epoch 00003: val_loss improved from 2009.98473 to 1855.18204, saving model to arrTemperature1_best_model_fold1_18_11_06.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 0s 571us/step - loss: 1943.5086 - val_loss: 1624.7830\n",
      "\n",
      "Epoch 00004: val_loss improved from 1855.18204 to 1624.78303, saving model to arrTemperature1_best_model_fold1_18_11_06.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 0s 569us/step - loss: 1626.9478 - val_loss: 1245.6468\n",
      "\n",
      "Epoch 00005: val_loss improved from 1624.78303 to 1245.64681, saving model to arrTemperature1_best_model_fold1_18_11_06.h5\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 0s 581us/step - loss: 1222.8413 - val_loss: 727.0985\n",
      "\n",
      "Epoch 00006: val_loss improved from 1245.64681 to 727.09846, saving model to arrTemperature1_best_model_fold1_18_11_06.h5\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 0s 582us/step - loss: 736.9150 - val_loss: 347.5379\n",
      "\n",
      "Epoch 00007: val_loss improved from 727.09846 to 347.53787, saving model to arrTemperature1_best_model_fold1_18_11_06.h5\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 0s 574us/step - loss: 267.3040 - val_loss: 140.2665\n",
      "\n",
      "Epoch 00008: val_loss improved from 347.53787 to 140.26654, saving model to arrTemperature1_best_model_fold1_18_11_06.h5\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 0s 571us/step - loss: 176.2691 - val_loss: 161.1526\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 140.26654\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 0s 601us/step - loss: 227.9024 - val_loss: 300.9325\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 140.26654\n",
      "Epoch 11/40\n",
      "208/208 [==============================] - 0s 563us/step - loss: 323.8743 - val_loss: 316.1843\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 140.26654\n",
      "Epoch 00011: early stopping\n",
      "104/104 [==============================] - 0s 1ms/step\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 2195.8856 - val_loss: 2200.4796\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2200.47958, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 0s 589us/step - loss: 2106.9782 - val_loss: 2055.2110\n",
      "\n",
      "Epoch 00002: val_loss improved from 2200.47958 to 2055.21097, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 0s 610us/step - loss: 1895.2952 - val_loss: 1813.7270\n",
      "\n",
      "Epoch 00003: val_loss improved from 2055.21097 to 1813.72696, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 0s 585us/step - loss: 1642.6586 - val_loss: 1513.9085\n",
      "\n",
      "Epoch 00004: val_loss improved from 1813.72696 to 1513.90854, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 0s 616us/step - loss: 1376.9885 - val_loss: 1274.4150\n",
      "\n",
      "Epoch 00005: val_loss improved from 1513.90854 to 1274.41495, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 0s 583us/step - loss: 1214.1029 - val_loss: 1153.8690\n",
      "\n",
      "Epoch 00006: val_loss improved from 1274.41495 to 1153.86901, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 0s 593us/step - loss: 1057.8560 - val_loss: 968.8425\n",
      "\n",
      "Epoch 00007: val_loss improved from 1153.86901 to 968.84249, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 0s 584us/step - loss: 858.8807 - val_loss: 827.5485\n",
      "\n",
      "Epoch 00008: val_loss improved from 968.84249 to 827.54848, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 0s 616us/step - loss: 638.9272 - val_loss: 499.5239\n",
      "\n",
      "Epoch 00009: val_loss improved from 827.54848 to 499.52386, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 0s 639us/step - loss: 339.6614 - val_loss: 228.0038\n",
      "\n",
      "Epoch 00010: val_loss improved from 499.52386 to 228.00383, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 11/40\n",
      "208/208 [==============================] - 0s 551us/step - loss: 153.7210 - val_loss: 135.2342\n",
      "\n",
      "Epoch 00011: val_loss improved from 228.00383 to 135.23420, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 12/40\n",
      "208/208 [==============================] - 0s 651us/step - loss: 129.4085 - val_loss: 119.8963\n",
      "\n",
      "Epoch 00012: val_loss improved from 135.23420 to 119.89631, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 13/40\n",
      "208/208 [==============================] - 0s 589us/step - loss: 117.8845 - val_loss: 102.2392\n",
      "\n",
      "Epoch 00013: val_loss improved from 119.89631 to 102.23923, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 14/40\n",
      "208/208 [==============================] - 0s 558us/step - loss: 107.8808 - val_loss: 96.3069\n",
      "\n",
      "Epoch 00014: val_loss improved from 102.23923 to 96.30689, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 15/40\n",
      "208/208 [==============================] - 0s 563us/step - loss: 100.5316 - val_loss: 97.8719\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 96.30689\n",
      "Epoch 16/40\n",
      "208/208 [==============================] - 0s 551us/step - loss: 97.4764 - val_loss: 88.1224\n",
      "\n",
      "Epoch 00016: val_loss improved from 96.30689 to 88.12240, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 17/40\n",
      "208/208 [==============================] - 0s 616us/step - loss: 83.1975 - val_loss: 69.4028\n",
      "\n",
      "Epoch 00017: val_loss improved from 88.12240 to 69.40282, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 18/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 67.1850 - val_loss: 52.4873\n",
      "\n",
      "Epoch 00018: val_loss improved from 69.40282 to 52.48732, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 19/40\n",
      "208/208 [==============================] - 0s 559us/step - loss: 55.4271 - val_loss: 42.1966\n",
      "\n",
      "Epoch 00019: val_loss improved from 52.48732 to 42.19662, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 20/40\n",
      "208/208 [==============================] - 0s 579us/step - loss: 49.4808 - val_loss: 39.8671\n",
      "\n",
      "Epoch 00020: val_loss improved from 42.19662 to 39.86707, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 21/40\n",
      "208/208 [==============================] - 0s 670us/step - loss: 49.2351 - val_loss: 39.2367\n",
      "\n",
      "Epoch 00021: val_loss improved from 39.86707 to 39.23673, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 22/40\n",
      "208/208 [==============================] - 0s 600us/step - loss: 47.8760 - val_loss: 38.7989\n",
      "\n",
      "Epoch 00022: val_loss improved from 39.23673 to 38.79887, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 23/40\n",
      "208/208 [==============================] - 0s 568us/step - loss: 46.4643 - val_loss: 38.7933\n",
      "\n",
      "Epoch 00023: val_loss improved from 38.79887 to 38.79334, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 24/40\n",
      "208/208 [==============================] - 0s 580us/step - loss: 45.6391 - val_loss: 37.9529\n",
      "\n",
      "Epoch 00024: val_loss improved from 38.79334 to 37.95290, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 25/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 0s 577us/step - loss: 45.1271 - val_loss: 36.7346\n",
      "\n",
      "Epoch 00025: val_loss improved from 37.95290 to 36.73460, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 26/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 44.6011 - val_loss: 35.8132\n",
      "\n",
      "Epoch 00026: val_loss improved from 36.73460 to 35.81320, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 27/40\n",
      "208/208 [==============================] - 0s 542us/step - loss: 43.8630 - val_loss: 34.9976\n",
      "\n",
      "Epoch 00027: val_loss improved from 35.81320 to 34.99759, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 28/40\n",
      "208/208 [==============================] - 0s 578us/step - loss: 42.9719 - val_loss: 35.0327\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 34.99759\n",
      "Epoch 29/40\n",
      "208/208 [==============================] - 0s 542us/step - loss: 42.3289 - val_loss: 34.2907\n",
      "\n",
      "Epoch 00029: val_loss improved from 34.99759 to 34.29071, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 30/40\n",
      "208/208 [==============================] - 0s 532us/step - loss: 41.4747 - val_loss: 33.9907\n",
      "\n",
      "Epoch 00030: val_loss improved from 34.29071 to 33.99072, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 31/40\n",
      "208/208 [==============================] - 0s 565us/step - loss: 40.6176 - val_loss: 32.7010\n",
      "\n",
      "Epoch 00031: val_loss improved from 33.99072 to 32.70103, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 32/40\n",
      "208/208 [==============================] - 0s 553us/step - loss: 40.1841 - val_loss: 32.5752\n",
      "\n",
      "Epoch 00032: val_loss improved from 32.70103 to 32.57522, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 33/40\n",
      "208/208 [==============================] - 0s 580us/step - loss: 39.4727 - val_loss: 32.3054\n",
      "\n",
      "Epoch 00033: val_loss improved from 32.57522 to 32.30544, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 34/40\n",
      "208/208 [==============================] - 0s 543us/step - loss: 38.6085 - val_loss: 32.2585\n",
      "\n",
      "Epoch 00034: val_loss improved from 32.30544 to 32.25854, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 35/40\n",
      "208/208 [==============================] - 0s 563us/step - loss: 38.0069 - val_loss: 31.2507\n",
      "\n",
      "Epoch 00035: val_loss improved from 32.25854 to 31.25074, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 36/40\n",
      "208/208 [==============================] - 0s 558us/step - loss: 37.3199 - val_loss: 30.5776\n",
      "\n",
      "Epoch 00036: val_loss improved from 31.25074 to 30.57758, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 37/40\n",
      "208/208 [==============================] - 0s 547us/step - loss: 36.3372 - val_loss: 30.2901\n",
      "\n",
      "Epoch 00037: val_loss improved from 30.57758 to 30.29007, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 38/40\n",
      "208/208 [==============================] - 0s 555us/step - loss: 35.6743 - val_loss: 29.7201\n",
      "\n",
      "Epoch 00038: val_loss improved from 30.29007 to 29.72008, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 39/40\n",
      "208/208 [==============================] - 0s 566us/step - loss: 35.4013 - val_loss: 29.5210\n",
      "\n",
      "Epoch 00039: val_loss improved from 29.72008 to 29.52096, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "Epoch 40/40\n",
      "208/208 [==============================] - 0s 556us/step - loss: 34.4762 - val_loss: 28.8482\n",
      "\n",
      "Epoch 00040: val_loss improved from 29.52096 to 28.84824, saving model to arrTemperature1_best_model_fold2_18_11_22.h5\n",
      "104/104 [==============================] - 0s 1ms/step\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 2171.5719 - val_loss: 2265.9527\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2265.95267, saving model to arrTemperature1_best_model_fold3_18_11_44.h5\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 0s 601us/step - loss: 2082.0014 - val_loss: 2043.1123\n",
      "\n",
      "Epoch 00002: val_loss improved from 2265.95267 to 2043.11227, saving model to arrTemperature1_best_model_fold3_18_11_44.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 0s 565us/step - loss: 1761.8959 - val_loss: 1564.3701\n",
      "\n",
      "Epoch 00003: val_loss improved from 2043.11227 to 1564.37006, saving model to arrTemperature1_best_model_fold3_18_11_44.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 0s 577us/step - loss: 1271.9940 - val_loss: 994.8112\n",
      "\n",
      "Epoch 00004: val_loss improved from 1564.37006 to 994.81124, saving model to arrTemperature1_best_model_fold3_18_11_44.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 0s 572us/step - loss: 797.1468 - val_loss: 599.0616\n",
      "\n",
      "Epoch 00005: val_loss improved from 994.81124 to 599.06159, saving model to arrTemperature1_best_model_fold3_18_11_44.h5\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 0s 567us/step - loss: 590.1607 - val_loss: 522.2264\n",
      "\n",
      "Epoch 00006: val_loss improved from 599.06159 to 522.22638, saving model to arrTemperature1_best_model_fold3_18_11_44.h5\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 0s 575us/step - loss: 573.3144 - val_loss: 558.6278\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 522.22638\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 0s 556us/step - loss: 578.2778 - val_loss: 545.6109\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 522.22638\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 0s 574us/step - loss: 550.1732 - val_loss: 555.9869\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 522.22638\n",
      "Epoch 00009: early stopping\n",
      "104/104 [==============================] - 0s 1ms/step\n",
      "arrTemperature2\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 252.1070 - val_loss: 245.4258\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 245.42577, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 0s 560us/step - loss: 250.4491 - val_loss: 243.8849\n",
      "\n",
      "Epoch 00002: val_loss improved from 245.42577 to 243.88487, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 0s 573us/step - loss: 248.9840 - val_loss: 242.5340\n",
      "\n",
      "Epoch 00003: val_loss improved from 243.88487 to 242.53395, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 0s 601us/step - loss: 247.7051 - val_loss: 241.3621\n",
      "\n",
      "Epoch 00004: val_loss improved from 242.53395 to 241.36213, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 0s 565us/step - loss: 246.5995 - val_loss: 240.3541\n",
      "\n",
      "Epoch 00005: val_loss improved from 241.36213 to 240.35410, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 0s 593us/step - loss: 245.6509 - val_loss: 239.4926\n",
      "\n",
      "Epoch 00006: val_loss improved from 240.35410 to 239.49261, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 0s 571us/step - loss: 244.8418 - val_loss: 238.7601\n",
      "\n",
      "Epoch 00007: val_loss improved from 239.49261 to 238.76014, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 0s 538us/step - loss: 244.1551 - val_loss: 238.1400\n",
      "\n",
      "Epoch 00008: val_loss improved from 238.76014 to 238.13999, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 0s 566us/step - loss: 243.5746 - val_loss: 237.6170\n",
      "\n",
      "Epoch 00009: val_loss improved from 238.13999 to 237.61697, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 0s 580us/step - loss: 243.0857 - val_loss: 237.1774\n",
      "\n",
      "Epoch 00010: val_loss improved from 237.61697 to 237.17741, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 11/40\n",
      "208/208 [==============================] - 0s 588us/step - loss: 242.6753 - val_loss: 236.8092\n",
      "\n",
      "Epoch 00011: val_loss improved from 237.17741 to 236.80922, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 0s 560us/step - loss: 242.3320 - val_loss: 236.5019\n",
      "\n",
      "Epoch 00012: val_loss improved from 236.80922 to 236.50187, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 13/40\n",
      "208/208 [==============================] - 0s 587us/step - loss: 242.0458 - val_loss: 236.2462\n",
      "\n",
      "Epoch 00013: val_loss improved from 236.50187 to 236.24617, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 14/40\n",
      "208/208 [==============================] - 0s 585us/step - loss: 241.8080 - val_loss: 236.0342\n",
      "\n",
      "Epoch 00014: val_loss improved from 236.24617 to 236.03423, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 15/40\n",
      "208/208 [==============================] - 0s 620us/step - loss: 241.6112 - val_loss: 235.8591\n",
      "\n",
      "Epoch 00015: val_loss improved from 236.03423 to 235.85915, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 16/40\n",
      "208/208 [==============================] - 0s 592us/step - loss: 241.4486 - val_loss: 235.7145\n",
      "\n",
      "Epoch 00016: val_loss improved from 235.85915 to 235.71452, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 17/40\n",
      "208/208 [==============================] - 0s 564us/step - loss: 241.3147 - val_loss: 235.5961\n",
      "\n",
      "Epoch 00017: val_loss improved from 235.71452 to 235.59610, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 18/40\n",
      "208/208 [==============================] - 0s 570us/step - loss: 241.2053 - val_loss: 235.4995\n",
      "\n",
      "Epoch 00018: val_loss improved from 235.59610 to 235.49951, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 19/40\n",
      "208/208 [==============================] - 0s 580us/step - loss: 241.1162 - val_loss: 235.4211\n",
      "\n",
      "Epoch 00019: val_loss improved from 235.49951 to 235.42110, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 20/40\n",
      "208/208 [==============================] - 0s 552us/step - loss: 241.0439 - val_loss: 235.3577\n",
      "\n",
      "Epoch 00020: val_loss improved from 235.42110 to 235.35768, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 21/40\n",
      "208/208 [==============================] - 0s 569us/step - loss: 240.9856 - val_loss: 235.3066\n",
      "\n",
      "Epoch 00021: val_loss improved from 235.35768 to 235.30663, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 22/40\n",
      "208/208 [==============================] - 0s 579us/step - loss: 240.9387 - val_loss: 235.2657\n",
      "\n",
      "Epoch 00022: val_loss improved from 235.30663 to 235.26569, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 23/40\n",
      "208/208 [==============================] - 0s 576us/step - loss: 240.9012 - val_loss: 235.2330\n",
      "\n",
      "Epoch 00023: val_loss improved from 235.26569 to 235.23302, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 24/40\n",
      "208/208 [==============================] - 0s 570us/step - loss: 240.8713 - val_loss: 235.2071\n",
      "\n",
      "Epoch 00024: val_loss improved from 235.23302 to 235.20706, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 25/40\n",
      "208/208 [==============================] - 0s 564us/step - loss: 240.8476 - val_loss: 235.1865\n",
      "\n",
      "Epoch 00025: val_loss improved from 235.20706 to 235.18652, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 26/40\n",
      "208/208 [==============================] - 0s 536us/step - loss: 240.8288 - val_loss: 235.1703\n",
      "\n",
      "Epoch 00026: val_loss improved from 235.18652 to 235.17035, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 27/40\n",
      "208/208 [==============================] - 0s 556us/step - loss: 240.8141 - val_loss: 235.1577\n",
      "\n",
      "Epoch 00027: val_loss improved from 235.17035 to 235.15767, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 28/40\n",
      "208/208 [==============================] - 0s 574us/step - loss: 240.8026 - val_loss: 235.1478\n",
      "\n",
      "Epoch 00028: val_loss improved from 235.15767 to 235.14777, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 29/40\n",
      "208/208 [==============================] - 0s 553us/step - loss: 240.7936 - val_loss: 235.1401\n",
      "\n",
      "Epoch 00029: val_loss improved from 235.14777 to 235.14008, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 30/40\n",
      "208/208 [==============================] - 0s 542us/step - loss: 240.7866 - val_loss: 235.1341\n",
      "\n",
      "Epoch 00030: val_loss improved from 235.14008 to 235.13414, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 31/40\n",
      "208/208 [==============================] - 0s 543us/step - loss: 240.7813 - val_loss: 235.1296\n",
      "\n",
      "Epoch 00031: val_loss improved from 235.13414 to 235.12956, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 32/40\n",
      "208/208 [==============================] - 0s 558us/step - loss: 240.7771 - val_loss: 235.1261\n",
      "\n",
      "Epoch 00032: val_loss improved from 235.12956 to 235.12606, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 33/40\n",
      "208/208 [==============================] - 0s 565us/step - loss: 240.7740 - val_loss: 235.1234\n",
      "\n",
      "Epoch 00033: val_loss improved from 235.12606 to 235.12339, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 34/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 240.7716 - val_loss: 235.1214\n",
      "\n",
      "Epoch 00034: val_loss improved from 235.12339 to 235.12137, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 35/40\n",
      "208/208 [==============================] - 0s 557us/step - loss: 240.7697 - val_loss: 235.1198\n",
      "\n",
      "Epoch 00035: val_loss improved from 235.12137 to 235.11982, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 36/40\n",
      "208/208 [==============================] - 0s 544us/step - loss: 240.7684 - val_loss: 235.1187\n",
      "\n",
      "Epoch 00036: val_loss improved from 235.11982 to 235.11867, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 37/40\n",
      "208/208 [==============================] - 0s 556us/step - loss: 240.7673 - val_loss: 235.1178\n",
      "\n",
      "Epoch 00037: val_loss improved from 235.11867 to 235.11780, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 38/40\n",
      "208/208 [==============================] - 0s 546us/step - loss: 240.7666 - val_loss: 235.1172\n",
      "\n",
      "Epoch 00038: val_loss improved from 235.11780 to 235.11715, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 39/40\n",
      "208/208 [==============================] - 0s 568us/step - loss: 240.7660 - val_loss: 235.1167\n",
      "\n",
      "Epoch 00039: val_loss improved from 235.11715 to 235.11668, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "Epoch 40/40\n",
      "208/208 [==============================] - 0s 558us/step - loss: 240.7656 - val_loss: 235.1163\n",
      "\n",
      "Epoch 00040: val_loss improved from 235.11668 to 235.11633, saving model to arrTemperature2_best_model_fold1_18_12_25.h5\n",
      "104/104 [==============================] - 0s 1ms/step\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 232.3539 - val_loss: 217.2399\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 217.23988, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 0s 591us/step - loss: 177.0015 - val_loss: 147.0931\n",
      "\n",
      "Epoch 00002: val_loss improved from 217.23988 to 147.09308, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 0s 586us/step - loss: 96.8279 - val_loss: 68.6452\n",
      "\n",
      "Epoch 00003: val_loss improved from 147.09308 to 68.64522, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 0s 577us/step - loss: 44.7842 - val_loss: 29.6169\n",
      "\n",
      "Epoch 00004: val_loss improved from 68.64522 to 29.61685, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 0s 564us/step - loss: 26.7105 - val_loss: 33.5922\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 29.61685\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 0s 578us/step - loss: 24.5596 - val_loss: 22.6450\n",
      "\n",
      "Epoch 00006: val_loss improved from 29.61685 to 22.64501, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 0s 574us/step - loss: 19.4603 - val_loss: 22.2071\n",
      "\n",
      "Epoch 00007: val_loss improved from 22.64501 to 22.20709, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/40\n",
      "208/208 [==============================] - 0s 578us/step - loss: 18.3909 - val_loss: 19.2504\n",
      "\n",
      "Epoch 00008: val_loss improved from 22.20709 to 19.25045, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 0s 551us/step - loss: 16.2589 - val_loss: 17.8468\n",
      "\n",
      "Epoch 00009: val_loss improved from 19.25045 to 17.84683, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 0s 570us/step - loss: 15.2747 - val_loss: 16.2083\n",
      "\n",
      "Epoch 00010: val_loss improved from 17.84683 to 16.20827, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 11/40\n",
      "208/208 [==============================] - 0s 585us/step - loss: 13.5090 - val_loss: 14.7218\n",
      "\n",
      "Epoch 00011: val_loss improved from 16.20827 to 14.72179, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 12/40\n",
      "208/208 [==============================] - 0s 570us/step - loss: 12.0569 - val_loss: 13.4599\n",
      "\n",
      "Epoch 00012: val_loss improved from 14.72179 to 13.45994, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 13/40\n",
      "208/208 [==============================] - 0s 588us/step - loss: 10.9110 - val_loss: 12.4802\n",
      "\n",
      "Epoch 00013: val_loss improved from 13.45994 to 12.48022, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 14/40\n",
      "208/208 [==============================] - 0s 570us/step - loss: 10.0682 - val_loss: 11.6859\n",
      "\n",
      "Epoch 00014: val_loss improved from 12.48022 to 11.68589, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 15/40\n",
      "208/208 [==============================] - 0s 560us/step - loss: 9.5425 - val_loss: 11.0245\n",
      "\n",
      "Epoch 00015: val_loss improved from 11.68589 to 11.02454, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 16/40\n",
      "208/208 [==============================] - 0s 545us/step - loss: 9.0629 - val_loss: 10.5299\n",
      "\n",
      "Epoch 00016: val_loss improved from 11.02454 to 10.52991, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 17/40\n",
      "208/208 [==============================] - 0s 598us/step - loss: 8.7487 - val_loss: 10.1905\n",
      "\n",
      "Epoch 00017: val_loss improved from 10.52991 to 10.19050, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 18/40\n",
      "208/208 [==============================] - 0s 571us/step - loss: 8.3124 - val_loss: 9.7426\n",
      "\n",
      "Epoch 00018: val_loss improved from 10.19050 to 9.74264, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 19/40\n",
      "208/208 [==============================] - 0s 555us/step - loss: 7.9998 - val_loss: 9.4041\n",
      "\n",
      "Epoch 00019: val_loss improved from 9.74264 to 9.40407, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 20/40\n",
      "208/208 [==============================] - 0s 565us/step - loss: 7.7781 - val_loss: 9.1520\n",
      "\n",
      "Epoch 00020: val_loss improved from 9.40407 to 9.15202, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 21/40\n",
      "208/208 [==============================] - 0s 550us/step - loss: 7.3977 - val_loss: 8.8164\n",
      "\n",
      "Epoch 00021: val_loss improved from 9.15202 to 8.81638, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 22/40\n",
      "208/208 [==============================] - 0s 559us/step - loss: 7.0947 - val_loss: 8.6314\n",
      "\n",
      "Epoch 00022: val_loss improved from 8.81638 to 8.63144, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 23/40\n",
      "208/208 [==============================] - 0s 548us/step - loss: 6.8735 - val_loss: 8.3654\n",
      "\n",
      "Epoch 00023: val_loss improved from 8.63144 to 8.36543, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 24/40\n",
      "208/208 [==============================] - 0s 572us/step - loss: 6.5900 - val_loss: 8.0991\n",
      "\n",
      "Epoch 00024: val_loss improved from 8.36543 to 8.09912, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 25/40\n",
      "208/208 [==============================] - 0s 558us/step - loss: 6.3831 - val_loss: 7.9233\n",
      "\n",
      "Epoch 00025: val_loss improved from 8.09912 to 7.92334, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 26/40\n",
      "208/208 [==============================] - 0s 539us/step - loss: 6.1780 - val_loss: 7.7073\n",
      "\n",
      "Epoch 00026: val_loss improved from 7.92334 to 7.70729, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 27/40\n",
      "208/208 [==============================] - 0s 555us/step - loss: 5.9602 - val_loss: 7.5348\n",
      "\n",
      "Epoch 00027: val_loss improved from 7.70729 to 7.53475, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 28/40\n",
      "208/208 [==============================] - 0s 546us/step - loss: 5.8193 - val_loss: 7.3765\n",
      "\n",
      "Epoch 00028: val_loss improved from 7.53475 to 7.37648, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 29/40\n",
      "208/208 [==============================] - 0s 592us/step - loss: 5.6238 - val_loss: 7.2648\n",
      "\n",
      "Epoch 00029: val_loss improved from 7.37648 to 7.26485, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 30/40\n",
      "208/208 [==============================] - 0s 562us/step - loss: 5.4153 - val_loss: 7.2047\n",
      "\n",
      "Epoch 00030: val_loss improved from 7.26485 to 7.20474, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 31/40\n",
      "208/208 [==============================] - 0s 556us/step - loss: 5.3016 - val_loss: 6.8385\n",
      "\n",
      "Epoch 00031: val_loss improved from 7.20474 to 6.83847, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 32/40\n",
      "208/208 [==============================] - 0s 604us/step - loss: 5.0920 - val_loss: 6.8157\n",
      "\n",
      "Epoch 00032: val_loss improved from 6.83847 to 6.81569, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 33/40\n",
      "208/208 [==============================] - 0s 568us/step - loss: 4.9715 - val_loss: 6.6797\n",
      "\n",
      "Epoch 00033: val_loss improved from 6.81569 to 6.67972, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 34/40\n",
      "208/208 [==============================] - 0s 577us/step - loss: 4.9228 - val_loss: 6.6010\n",
      "\n",
      "Epoch 00034: val_loss improved from 6.67972 to 6.60104, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 35/40\n",
      "208/208 [==============================] - 0s 576us/step - loss: 4.7902 - val_loss: 6.4294\n",
      "\n",
      "Epoch 00035: val_loss improved from 6.60104 to 6.42940, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 36/40\n",
      "208/208 [==============================] - 0s 588us/step - loss: 4.6086 - val_loss: 6.3222\n",
      "\n",
      "Epoch 00036: val_loss improved from 6.42940 to 6.32220, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 37/40\n",
      "208/208 [==============================] - 0s 578us/step - loss: 4.4649 - val_loss: 6.2596\n",
      "\n",
      "Epoch 00037: val_loss improved from 6.32220 to 6.25962, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 38/40\n",
      "208/208 [==============================] - 0s 567us/step - loss: 4.3290 - val_loss: 6.1170\n",
      "\n",
      "Epoch 00038: val_loss improved from 6.25962 to 6.11704, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 39/40\n",
      "208/208 [==============================] - 0s 567us/step - loss: 4.1732 - val_loss: 6.0924\n",
      "\n",
      "Epoch 00039: val_loss improved from 6.11704 to 6.09240, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "Epoch 40/40\n",
      "208/208 [==============================] - 0s 552us/step - loss: 4.0970 - val_loss: 6.0170\n",
      "\n",
      "Epoch 00040: val_loss improved from 6.09240 to 6.01704, saving model to arrTemperature2_best_model_fold2_18_12_55.h5\n",
      "104/104 [==============================] - 0s 1ms/step\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 239.9331 - val_loss: 211.0706\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 211.07060, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 0s 594us/step - loss: 195.7712 - val_loss: 139.9263\n",
      "\n",
      "Epoch 00002: val_loss improved from 211.07060 to 139.92632, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 0s 563us/step - loss: 126.6460 - val_loss: 80.1145\n",
      "\n",
      "Epoch 00003: val_loss improved from 139.92632 to 80.11449, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 0s 562us/step - loss: 72.8398 - val_loss: 41.4376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00004: val_loss improved from 80.11449 to 41.43765, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 0s 564us/step - loss: 32.7786 - val_loss: 25.5393\n",
      "\n",
      "Epoch 00005: val_loss improved from 41.43765 to 25.53927, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 0s 550us/step - loss: 30.3484 - val_loss: 28.6910\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 25.53927\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 0s 555us/step - loss: 25.8925 - val_loss: 21.7387\n",
      "\n",
      "Epoch 00007: val_loss improved from 25.53927 to 21.73873, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 0s 549us/step - loss: 22.3758 - val_loss: 19.7790\n",
      "\n",
      "Epoch 00008: val_loss improved from 21.73873 to 19.77899, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 0s 580us/step - loss: 20.8011 - val_loss: 18.1005\n",
      "\n",
      "Epoch 00009: val_loss improved from 19.77899 to 18.10052, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 0s 581us/step - loss: 18.9118 - val_loss: 16.7736\n",
      "\n",
      "Epoch 00010: val_loss improved from 18.10052 to 16.77359, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 11/40\n",
      "208/208 [==============================] - 0s 569us/step - loss: 17.2756 - val_loss: 16.5557\n",
      "\n",
      "Epoch 00011: val_loss improved from 16.77359 to 16.55565, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 12/40\n",
      "208/208 [==============================] - 0s 587us/step - loss: 16.4335 - val_loss: 15.9237\n",
      "\n",
      "Epoch 00012: val_loss improved from 16.55565 to 15.92365, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 13/40\n",
      "208/208 [==============================] - 0s 549us/step - loss: 15.5281 - val_loss: 14.9543\n",
      "\n",
      "Epoch 00013: val_loss improved from 15.92365 to 14.95425, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 14/40\n",
      "208/208 [==============================] - 0s 609us/step - loss: 14.5731 - val_loss: 13.9408\n",
      "\n",
      "Epoch 00014: val_loss improved from 14.95425 to 13.94085, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 15/40\n",
      "208/208 [==============================] - 0s 560us/step - loss: 13.5163 - val_loss: 12.9981\n",
      "\n",
      "Epoch 00015: val_loss improved from 13.94085 to 12.99808, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 16/40\n",
      "208/208 [==============================] - 0s 587us/step - loss: 12.4755 - val_loss: 12.1242\n",
      "\n",
      "Epoch 00016: val_loss improved from 12.99808 to 12.12425, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 17/40\n",
      "208/208 [==============================] - 0s 532us/step - loss: 11.2225 - val_loss: 10.9171\n",
      "\n",
      "Epoch 00017: val_loss improved from 12.12425 to 10.91707, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 18/40\n",
      "208/208 [==============================] - 0s 559us/step - loss: 10.2711 - val_loss: 9.8694\n",
      "\n",
      "Epoch 00018: val_loss improved from 10.91707 to 9.86938, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 19/40\n",
      "208/208 [==============================] - 0s 550us/step - loss: 9.5727 - val_loss: 9.4851\n",
      "\n",
      "Epoch 00019: val_loss improved from 9.86938 to 9.48507, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 20/40\n",
      "208/208 [==============================] - 0s 564us/step - loss: 9.0163 - val_loss: 8.9533\n",
      "\n",
      "Epoch 00020: val_loss improved from 9.48507 to 8.95333, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 21/40\n",
      "208/208 [==============================] - 0s 571us/step - loss: 8.5116 - val_loss: 8.6644\n",
      "\n",
      "Epoch 00021: val_loss improved from 8.95333 to 8.66445, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 22/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 8.0267 - val_loss: 8.5232\n",
      "\n",
      "Epoch 00022: val_loss improved from 8.66445 to 8.52315, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 23/40\n",
      "208/208 [==============================] - 0s 557us/step - loss: 7.7395 - val_loss: 7.9997\n",
      "\n",
      "Epoch 00023: val_loss improved from 8.52315 to 7.99972, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 24/40\n",
      "208/208 [==============================] - 0s 567us/step - loss: 7.2763 - val_loss: 7.6037\n",
      "\n",
      "Epoch 00024: val_loss improved from 7.99972 to 7.60373, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 25/40\n",
      "208/208 [==============================] - 0s 546us/step - loss: 6.9804 - val_loss: 7.3124\n",
      "\n",
      "Epoch 00025: val_loss improved from 7.60373 to 7.31241, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 26/40\n",
      "208/208 [==============================] - 0s 577us/step - loss: 6.7477 - val_loss: 7.1045\n",
      "\n",
      "Epoch 00026: val_loss improved from 7.31241 to 7.10453, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 27/40\n",
      "208/208 [==============================] - 0s 562us/step - loss: 6.5442 - val_loss: 6.8376\n",
      "\n",
      "Epoch 00027: val_loss improved from 7.10453 to 6.83758, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 28/40\n",
      "208/208 [==============================] - 0s 554us/step - loss: 6.4305 - val_loss: 6.7714\n",
      "\n",
      "Epoch 00028: val_loss improved from 6.83758 to 6.77138, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 29/40\n",
      "208/208 [==============================] - 0s 546us/step - loss: 6.0992 - val_loss: 6.3999\n",
      "\n",
      "Epoch 00029: val_loss improved from 6.77138 to 6.39988, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 30/40\n",
      "208/208 [==============================] - 0s 618us/step - loss: 5.9831 - val_loss: 6.3234\n",
      "\n",
      "Epoch 00030: val_loss improved from 6.39988 to 6.32337, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 31/40\n",
      "208/208 [==============================] - 0s 592us/step - loss: 5.7441 - val_loss: 5.9560\n",
      "\n",
      "Epoch 00031: val_loss improved from 6.32337 to 5.95597, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 32/40\n",
      "208/208 [==============================] - 0s 540us/step - loss: 5.5715 - val_loss: 6.0614\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 5.95597\n",
      "Epoch 33/40\n",
      "208/208 [==============================] - 0s 555us/step - loss: 5.3130 - val_loss: 5.8546\n",
      "\n",
      "Epoch 00033: val_loss improved from 5.95597 to 5.85461, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 34/40\n",
      "208/208 [==============================] - 0s 533us/step - loss: 5.1920 - val_loss: 5.6252\n",
      "\n",
      "Epoch 00034: val_loss improved from 5.85461 to 5.62516, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 35/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 4.9757 - val_loss: 5.5045\n",
      "\n",
      "Epoch 00035: val_loss improved from 5.62516 to 5.50449, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 36/40\n",
      "208/208 [==============================] - 0s 641us/step - loss: 4.8793 - val_loss: 5.4898\n",
      "\n",
      "Epoch 00036: val_loss improved from 5.50449 to 5.48983, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 37/40\n",
      "208/208 [==============================] - 0s 571us/step - loss: 4.7326 - val_loss: 5.3711\n",
      "\n",
      "Epoch 00037: val_loss improved from 5.48983 to 5.37109, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 38/40\n",
      "208/208 [==============================] - 0s 570us/step - loss: 4.5989 - val_loss: 5.1912\n",
      "\n",
      "Epoch 00038: val_loss improved from 5.37109 to 5.19116, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "Epoch 39/40\n",
      "208/208 [==============================] - 0s 567us/step - loss: 4.4885 - val_loss: 5.1967\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 5.19116\n",
      "Epoch 40/40\n",
      "208/208 [==============================] - 0s 560us/step - loss: 4.3954 - val_loss: 4.9640\n",
      "\n",
      "Epoch 00040: val_loss improved from 5.19116 to 4.96401, saving model to arrTemperature2_best_model_fold3_18_13_18.h5\n",
      "104/104 [==============================] - 0s 1ms/step\n",
      "arrCPU_load0\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 12.9326 - val_loss: 11.2033\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 11.20326, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 10.9778 - val_loss: 9.5908\n",
      "\n",
      "Epoch 00002: val_loss improved from 11.20326 to 9.59076, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 0s 541us/step - loss: 9.0589 - val_loss: 8.1373\n",
      "\n",
      "Epoch 00003: val_loss improved from 9.59076 to 8.13726, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 0s 605us/step - loss: 7.4315 - val_loss: 7.1467\n",
      "\n",
      "Epoch 00004: val_loss improved from 8.13726 to 7.14673, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 0s 626us/step - loss: 6.4538 - val_loss: 6.0645\n",
      "\n",
      "Epoch 00005: val_loss improved from 7.14673 to 6.06452, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 0s 720us/step - loss: 5.3911 - val_loss: 5.1363\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.06452 to 5.13633, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 0s 593us/step - loss: 4.5884 - val_loss: 4.4298\n",
      "\n",
      "Epoch 00007: val_loss improved from 5.13633 to 4.42983, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 0s 564us/step - loss: 3.8758 - val_loss: 3.8434\n",
      "\n",
      "Epoch 00008: val_loss improved from 4.42983 to 3.84343, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 0s 563us/step - loss: 3.2810 - val_loss: 3.2841\n",
      "\n",
      "Epoch 00009: val_loss improved from 3.84343 to 3.28411, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 0s 566us/step - loss: 2.7705 - val_loss: 2.8099\n",
      "\n",
      "Epoch 00010: val_loss improved from 3.28411 to 2.80988, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 11/40\n",
      "208/208 [==============================] - 0s 563us/step - loss: 2.3415 - val_loss: 2.4156\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.80988 to 2.41560, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 12/40\n",
      "208/208 [==============================] - 0s 612us/step - loss: 1.9658 - val_loss: 2.0672\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.41560 to 2.06716, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 13/40\n",
      "208/208 [==============================] - 0s 543us/step - loss: 1.6672 - val_loss: 1.8173\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.06716 to 1.81731, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 14/40\n",
      "208/208 [==============================] - 0s 569us/step - loss: 1.4270 - val_loss: 1.6198\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.81731 to 1.61976, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 15/40\n",
      "208/208 [==============================] - 0s 563us/step - loss: 1.1887 - val_loss: 1.3701\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.61976 to 1.37007, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 16/40\n",
      "208/208 [==============================] - 0s 546us/step - loss: 1.0209 - val_loss: 1.2342\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.37007 to 1.23422, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 17/40\n",
      "208/208 [==============================] - 0s 586us/step - loss: 0.8483 - val_loss: 1.0821\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.23422 to 1.08213, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 18/40\n",
      "208/208 [==============================] - 0s 566us/step - loss: 0.7320 - val_loss: 0.9847\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.08213 to 0.98468, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 19/40\n",
      "208/208 [==============================] - 0s 559us/step - loss: 0.6000 - val_loss: 0.8667\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.98468 to 0.86673, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 20/40\n",
      "208/208 [==============================] - 0s 570us/step - loss: 0.5131 - val_loss: 0.8247\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.86673 to 0.82467, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 21/40\n",
      "208/208 [==============================] - 0s 569us/step - loss: 0.4499 - val_loss: 0.7379\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.82467 to 0.73786, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 22/40\n",
      "208/208 [==============================] - 0s 556us/step - loss: 0.3523 - val_loss: 0.6974\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.73786 to 0.69744, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 23/40\n",
      "208/208 [==============================] - 0s 560us/step - loss: 0.2964 - val_loss: 0.6424\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.69744 to 0.64244, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 24/40\n",
      "208/208 [==============================] - 0s 594us/step - loss: 0.2471 - val_loss: 0.6194\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.64244 to 0.61939, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 25/40\n",
      "208/208 [==============================] - 0s 555us/step - loss: 0.2129 - val_loss: 0.5683\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.61939 to 0.56834, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 26/40\n",
      "208/208 [==============================] - 0s 552us/step - loss: 0.1862 - val_loss: 0.5676\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.56834 to 0.56758, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 27/40\n",
      "208/208 [==============================] - 0s 565us/step - loss: 0.1573 - val_loss: 0.5325\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.56758 to 0.53254, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 28/40\n",
      "208/208 [==============================] - 0s 543us/step - loss: 0.1402 - val_loss: 0.5090\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.53254 to 0.50898, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 29/40\n",
      "208/208 [==============================] - 0s 549us/step - loss: 0.1198 - val_loss: 0.5183\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.50898\n",
      "Epoch 30/40\n",
      "208/208 [==============================] - 0s 538us/step - loss: 0.1045 - val_loss: 0.4786\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.50898 to 0.47856, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 31/40\n",
      "208/208 [==============================] - 0s 550us/step - loss: 0.0912 - val_loss: 0.4858\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.47856\n",
      "Epoch 32/40\n",
      "208/208 [==============================] - 0s 534us/step - loss: 0.0815 - val_loss: 0.4633\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.47856 to 0.46330, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 33/40\n",
      "208/208 [==============================] - 0s 542us/step - loss: 0.0830 - val_loss: 0.4881\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.46330\n",
      "Epoch 34/40\n",
      "208/208 [==============================] - 0s 549us/step - loss: 0.0845 - val_loss: 0.4515\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.46330 to 0.45152, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 35/40\n",
      "208/208 [==============================] - 0s 537us/step - loss: 0.0647 - val_loss: 0.4548\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.45152\n",
      "Epoch 36/40\n",
      "208/208 [==============================] - 0s 548us/step - loss: 0.0646 - val_loss: 0.4824\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.45152\n",
      "Epoch 37/40\n",
      "208/208 [==============================] - 0s 542us/step - loss: 0.0732 - val_loss: 0.4385\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.45152 to 0.43855, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 38/40\n",
      "208/208 [==============================] - 0s 554us/step - loss: 0.0513 - val_loss: 0.4467\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.43855\n",
      "Epoch 39/40\n",
      "208/208 [==============================] - 0s 557us/step - loss: 0.0475 - val_loss: 0.4346\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.43855 to 0.43463, saving model to arrCPU_load0_best_model_fold1_18_14_05.h5\n",
      "Epoch 40/40\n",
      "208/208 [==============================] - 0s 536us/step - loss: 0.0440 - val_loss: 0.4347\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.43463\n",
      "104/104 [==============================] - 0s 1ms/step\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 1s 4ms/step - loss: 12.5393 - val_loss: 10.8781\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 10.87811, saving model to arrCPU_load0_best_model_fold2_18_14_29.h5\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 0s 610us/step - loss: 10.2491 - val_loss: 9.1000\n",
      "\n",
      "Epoch 00002: val_loss improved from 10.87811 to 9.09995, saving model to arrCPU_load0_best_model_fold2_18_14_29.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 0s 577us/step - loss: 8.8664 - val_loss: 7.8012\n",
      "\n",
      "Epoch 00003: val_loss improved from 9.09995 to 7.80117, saving model to arrCPU_load0_best_model_fold2_18_14_29.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 0s 571us/step - loss: 7.5616 - val_loss: 6.7121\n",
      "\n",
      "Epoch 00004: val_loss improved from 7.80117 to 6.71207, saving model to arrCPU_load0_best_model_fold2_18_14_29.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 0s 572us/step - loss: 6.4963 - val_loss: 5.7498\n",
      "\n",
      "Epoch 00005: val_loss improved from 6.71207 to 5.74978, saving model to arrCPU_load0_best_model_fold2_18_14_29.h5\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 0s 560us/step - loss: 5.5721 - val_loss: 4.9270\n",
      "\n",
      "Epoch 00006: val_loss improved from 5.74978 to 4.92702, saving model to arrCPU_load0_best_model_fold2_18_14_29.h5\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 4.7402 - val_loss: 4.1685\n",
      "\n",
      "Epoch 00007: val_loss improved from 4.92702 to 4.16849, saving model to arrCPU_load0_best_model_fold2_18_14_29.h5\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 0s 603us/step - loss: 4.0522 - val_loss: 3.5492\n",
      "\n",
      "Epoch 00008: val_loss improved from 4.16849 to 3.54921, saving model to arrCPU_load0_best_model_fold2_18_14_29.h5\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 0s 650us/step - loss: 3.4558 - val_loss: 3.0141\n",
      "\n",
      "Epoch 00009: val_loss improved from 3.54921 to 3.01414, saving model to arrCPU_load0_best_model_fold2_18_14_29.h5\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 0s 559us/step - loss: 2.9495 - val_loss: 2.5612\n",
      "\n",
      "Epoch 00010: val_loss improved from 3.01414 to 2.56117, saving model to arrCPU_load0_best_model_fold2_18_14_29.h5\n",
      "Epoch 11/40\n",
      "208/208 [==============================] - 0s 573us/step - loss: 2.5144 - val_loss: 2.2596\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.56117 to 2.25957, saving model to arrCPU_load0_best_model_fold2_18_14_29.h5\n",
      "Epoch 12/40\n",
      "208/208 [==============================] - 0s 583us/step - loss: 2.2085 - val_loss: 1.8418\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.25957 to 1.84176, saving model to arrCPU_load0_best_model_fold2_18_14_29.h5\n",
      "Epoch 13/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 1.8696 - val_loss: 1.6136\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.84176 to 1.61363, saving model to arrCPU_load0_best_model_fold2_18_14_29.h5\n",
      "Epoch 14/40\n",
      "208/208 [==============================] - 0s 725us/step - loss: 1.6067 - val_loss: 1.3707\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.61363 to 1.37070, saving model to arrCPU_load0_best_model_fold2_18_14_29.h5\n",
      "Epoch 15/40\n",
      "208/208 [==============================] - 0s 557us/step - loss: 1.3789 - val_loss: 1.1766\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.37070 to 1.17664, saving model to arrCPU_load0_best_model_fold2_18_14_29.h5\n",
      "Epoch 16/40\n",
      "208/208 [==============================] - 0s 567us/step - loss: 1.2153 - val_loss: 1.0802\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.17664 to 1.08015, saving model to arrCPU_load0_best_model_fold2_18_14_29.h5\n",
      "Epoch 17/40\n",
      "208/208 [==============================] - 0s 573us/step - loss: 1.0534 - val_loss: 0.8938\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.08015 to 0.89383, saving model to arrCPU_load0_best_model_fold2_18_14_29.h5\n",
      "Epoch 18/40\n",
      "208/208 [==============================] - 0s 574us/step - loss: 0.9367 - val_loss: 0.7608\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.89383 to 0.76084, saving model to arrCPU_load0_best_model_fold2_18_14_29.h5\n",
      "Epoch 19/40\n",
      "208/208 [==============================] - 0s 582us/step - loss: 0.8024 - val_loss: 0.6946\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.76084 to 0.69461, saving model to arrCPU_load0_best_model_fold2_18_14_29.h5\n",
      "Epoch 20/40\n",
      "208/208 [==============================] - 0s 580us/step - loss: 0.7240 - val_loss: 0.5678\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.69461 to 0.56776, saving model to arrCPU_load0_best_model_fold2_18_14_29.h5\n",
      "Epoch 21/40\n",
      "208/208 [==============================] - 0s 573us/step - loss: 0.6398 - val_loss: 0.5242\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.56776 to 0.52419, saving model to arrCPU_load0_best_model_fold2_18_14_29.h5\n",
      "Epoch 22/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 0.5859 - val_loss: 0.4434\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.52419 to 0.44341, saving model to arrCPU_load0_best_model_fold2_18_14_29.h5\n",
      "Epoch 23/40\n",
      "208/208 [==============================] - 0s 599us/step - loss: 0.5293 - val_loss: 0.4434\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.44341\n",
      "Epoch 24/40\n",
      "208/208 [==============================] - 0s 553us/step - loss: 0.4889 - val_loss: 0.3497\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.44341 to 0.34972, saving model to arrCPU_load0_best_model_fold2_18_14_29.h5\n",
      "Epoch 25/40\n",
      "208/208 [==============================] - 0s 543us/step - loss: 0.4461 - val_loss: 0.3126\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.34972 to 0.31258, saving model to arrCPU_load0_best_model_fold2_18_14_29.h5\n",
      "Epoch 26/40\n",
      "208/208 [==============================] - 0s 564us/step - loss: 0.4136 - val_loss: 0.2954\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.31258 to 0.29538, saving model to arrCPU_load0_best_model_fold2_18_14_29.h5\n",
      "Epoch 27/40\n",
      "208/208 [==============================] - 0s 572us/step - loss: 0.3990 - val_loss: 0.2798\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.29538 to 0.27976, saving model to arrCPU_load0_best_model_fold2_18_14_29.h5\n",
      "Epoch 28/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 0.3744 - val_loss: 0.2234\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.27976 to 0.22338, saving model to arrCPU_load0_best_model_fold2_18_14_29.h5\n",
      "Epoch 29/40\n",
      "208/208 [==============================] - 0s 560us/step - loss: 0.3466 - val_loss: 0.2159\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.22338 to 0.21587, saving model to arrCPU_load0_best_model_fold2_18_14_29.h5\n",
      "Epoch 30/40\n",
      "208/208 [==============================] - 0s 553us/step - loss: 0.3343 - val_loss: 0.2519\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.21587\n",
      "Epoch 31/40\n",
      "208/208 [==============================] - 0s 557us/step - loss: 0.3264 - val_loss: 0.1868\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.21587 to 0.18680, saving model to arrCPU_load0_best_model_fold2_18_14_29.h5\n",
      "Epoch 32/40\n",
      "208/208 [==============================] - 0s 538us/step - loss: 0.3142 - val_loss: 0.2103\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.18680\n",
      "Epoch 33/40\n",
      "208/208 [==============================] - 0s 544us/step - loss: 0.3220 - val_loss: 0.1785\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.18680 to 0.17851, saving model to arrCPU_load0_best_model_fold2_18_14_29.h5\n",
      "Epoch 34/40\n",
      "208/208 [==============================] - 0s 592us/step - loss: 0.2916 - val_loss: 0.1501\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.17851 to 0.15008, saving model to arrCPU_load0_best_model_fold2_18_14_29.h5\n",
      "Epoch 35/40\n",
      "208/208 [==============================] - 0s 584us/step - loss: 0.2881 - val_loss: 0.1600\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.15008\n",
      "Epoch 36/40\n",
      "208/208 [==============================] - 0s 545us/step - loss: 0.2745 - val_loss: 0.1961\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.15008\n",
      "Epoch 37/40\n",
      "208/208 [==============================] - 0s 541us/step - loss: 0.3035 - val_loss: 0.1559\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.15008\n",
      "Epoch 00037: early stopping\n",
      "104/104 [==============================] - 0s 1ms/step\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 12.5834 - val_loss: 12.1488\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 12.14882, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 0s 607us/step - loss: 10.7757 - val_loss: 10.3416\n",
      "\n",
      "Epoch 00002: val_loss improved from 12.14882 to 10.34164, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 0s 580us/step - loss: 9.1834 - val_loss: 8.6454\n",
      "\n",
      "Epoch 00003: val_loss improved from 10.34164 to 8.64539, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 0s 564us/step - loss: 7.7010 - val_loss: 7.1151\n",
      "\n",
      "Epoch 00004: val_loss improved from 8.64539 to 7.11505, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 6.4384 - val_loss: 5.7921\n",
      "\n",
      "Epoch 00005: val_loss improved from 7.11505 to 5.79214, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 0s 562us/step - loss: 5.3887 - val_loss: 4.8232\n",
      "\n",
      "Epoch 00006: val_loss improved from 5.79214 to 4.82316, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 0s 568us/step - loss: 4.5406 - val_loss: 4.0620\n",
      "\n",
      "Epoch 00007: val_loss improved from 4.82316 to 4.06197, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 0s 587us/step - loss: 3.8133 - val_loss: 3.4210\n",
      "\n",
      "Epoch 00008: val_loss improved from 4.06197 to 3.42096, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 0s 552us/step - loss: 3.2228 - val_loss: 2.8831\n",
      "\n",
      "Epoch 00009: val_loss improved from 3.42096 to 2.88309, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 0s 579us/step - loss: 2.7172 - val_loss: 2.4482\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.88309 to 2.44824, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 11/40\n",
      "208/208 [==============================] - 0s 584us/step - loss: 2.2882 - val_loss: 2.0383\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.44824 to 2.03829, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 12/40\n",
      "208/208 [==============================] - 0s 565us/step - loss: 1.9683 - val_loss: 1.7553\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.03829 to 1.75529, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 13/40\n",
      "208/208 [==============================] - 0s 585us/step - loss: 1.6689 - val_loss: 1.4789\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.75529 to 1.47885, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 14/40\n",
      "208/208 [==============================] - 0s 559us/step - loss: 1.4216 - val_loss: 1.2622\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.47885 to 1.26221, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 15/40\n",
      "208/208 [==============================] - 0s 555us/step - loss: 1.2089 - val_loss: 1.0816\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.26221 to 1.08162, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 16/40\n",
      "208/208 [==============================] - 0s 566us/step - loss: 1.0410 - val_loss: 0.9233\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.08162 to 0.92331, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 17/40\n",
      "208/208 [==============================] - 0s 544us/step - loss: 0.8765 - val_loss: 0.8238\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.92331 to 0.82376, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 18/40\n",
      "208/208 [==============================] - 0s 571us/step - loss: 0.7635 - val_loss: 0.6914\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.82376 to 0.69142, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 19/40\n",
      "208/208 [==============================] - 0s 562us/step - loss: 0.6665 - val_loss: 0.6159\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.69142 to 0.61589, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 20/40\n",
      "208/208 [==============================] - 0s 560us/step - loss: 0.5890 - val_loss: 0.5321\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.61589 to 0.53208, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 21/40\n",
      "208/208 [==============================] - 0s 547us/step - loss: 0.5138 - val_loss: 0.4699\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.53208 to 0.46994, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 22/40\n",
      "208/208 [==============================] - 0s 556us/step - loss: 0.4616 - val_loss: 0.4219\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.46994 to 0.42186, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 23/40\n",
      "208/208 [==============================] - 0s 556us/step - loss: 0.4183 - val_loss: 0.3891\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.42186 to 0.38907, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 24/40\n",
      "208/208 [==============================] - 0s 547us/step - loss: 0.3785 - val_loss: 0.3585\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.38907 to 0.35854, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 25/40\n",
      "208/208 [==============================] - 0s 576us/step - loss: 0.3474 - val_loss: 0.3219\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.35854 to 0.32192, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 26/40\n",
      "208/208 [==============================] - 0s 555us/step - loss: 0.3255 - val_loss: 0.3207\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.32192 to 0.32067, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 27/40\n",
      "208/208 [==============================] - 0s 575us/step - loss: 0.3055 - val_loss: 0.2890\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.32067 to 0.28899, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 28/40\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.2955 - val_loss: 0.2729\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.28899 to 0.27292, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 29/40\n",
      "208/208 [==============================] - 0s 568us/step - loss: 0.2751 - val_loss: 0.2654\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.27292 to 0.26542, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 30/40\n",
      "208/208 [==============================] - 0s 569us/step - loss: 0.2684 - val_loss: 0.2624\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.26542 to 0.26236, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 31/40\n",
      "208/208 [==============================] - 0s 574us/step - loss: 0.2517 - val_loss: 0.2518\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.26236 to 0.25182, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 32/40\n",
      "208/208 [==============================] - 0s 570us/step - loss: 0.2582 - val_loss: 0.2924\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.25182\n",
      "Epoch 33/40\n",
      "208/208 [==============================] - 0s 552us/step - loss: 0.2626 - val_loss: 0.2421\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.25182 to 0.24214, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 34/40\n",
      "208/208 [==============================] - 0s 572us/step - loss: 0.2488 - val_loss: 0.2466\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.24214\n",
      "Epoch 35/40\n",
      "208/208 [==============================] - 0s 562us/step - loss: 0.2401 - val_loss: 0.2480\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.24214\n",
      "Epoch 36/40\n",
      "208/208 [==============================] - 0s 579us/step - loss: 0.2322 - val_loss: 0.2298\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.24214 to 0.22981, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 37/40\n",
      "208/208 [==============================] - 0s 547us/step - loss: 0.2457 - val_loss: 0.2353\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.22981\n",
      "Epoch 38/40\n",
      "208/208 [==============================] - 0s 550us/step - loss: 0.2336 - val_loss: 0.2292\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.22981 to 0.22922, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "Epoch 39/40\n",
      "208/208 [==============================] - 0s 531us/step - loss: 0.2233 - val_loss: 0.2332\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.22922\n",
      "Epoch 40/40\n",
      "208/208 [==============================] - 0s 543us/step - loss: 0.2242 - val_loss: 0.2234\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.22922 to 0.22341, saving model to arrCPU_load0_best_model_fold3_18_14_52.h5\n",
      "104/104 [==============================] - 0s 1ms/step\n",
      "arrMemory_usage0\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 501.7434 - val_loss: 579.3562\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 579.35624, saving model to arrMemory_usage0_best_model_fold1_18_15_40.h5\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 0s 597us/step - loss: 478.3305 - val_loss: 522.6629\n",
      "\n",
      "Epoch 00002: val_loss improved from 579.35624 to 522.66290, saving model to arrMemory_usage0_best_model_fold1_18_15_40.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 0s 576us/step - loss: 403.9031 - val_loss: 412.1137\n",
      "\n",
      "Epoch 00003: val_loss improved from 522.66290 to 412.11374, saving model to arrMemory_usage0_best_model_fold1_18_15_40.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 0s 570us/step - loss: 312.6926 - val_loss: 310.8547\n",
      "\n",
      "Epoch 00004: val_loss improved from 412.11374 to 310.85473, saving model to arrMemory_usage0_best_model_fold1_18_15_40.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 0s 570us/step - loss: 265.5086 - val_loss: 268.4833\n",
      "\n",
      "Epoch 00005: val_loss improved from 310.85473 to 268.48333, saving model to arrMemory_usage0_best_model_fold1_18_15_40.h5\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 0s 586us/step - loss: 214.1039 - val_loss: 205.5368\n",
      "\n",
      "Epoch 00006: val_loss improved from 268.48333 to 205.53675, saving model to arrMemory_usage0_best_model_fold1_18_15_40.h5\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 0s 568us/step - loss: 141.0404 - val_loss: 154.7467\n",
      "\n",
      "Epoch 00007: val_loss improved from 205.53675 to 154.74665, saving model to arrMemory_usage0_best_model_fold1_18_15_40.h5\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 0s 570us/step - loss: 85.7647 - val_loss: 108.8122\n",
      "\n",
      "Epoch 00008: val_loss improved from 154.74665 to 108.81220, saving model to arrMemory_usage0_best_model_fold1_18_15_40.h5\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 0s 559us/step - loss: 55.8968 - val_loss: 85.3930\n",
      "\n",
      "Epoch 00009: val_loss improved from 108.81220 to 85.39305, saving model to arrMemory_usage0_best_model_fold1_18_15_40.h5\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 0s 557us/step - loss: 41.4523 - val_loss: 60.6051\n",
      "\n",
      "Epoch 00010: val_loss improved from 85.39305 to 60.60514, saving model to arrMemory_usage0_best_model_fold1_18_15_40.h5\n",
      "Epoch 11/40\n",
      "208/208 [==============================] - 0s 568us/step - loss: 27.7738 - val_loss: 50.0659\n",
      "\n",
      "Epoch 00011: val_loss improved from 60.60514 to 50.06588, saving model to arrMemory_usage0_best_model_fold1_18_15_40.h5\n",
      "Epoch 12/40\n",
      "208/208 [==============================] - 0s 569us/step - loss: 20.9839 - val_loss: 39.4669\n",
      "\n",
      "Epoch 00012: val_loss improved from 50.06588 to 39.46688, saving model to arrMemory_usage0_best_model_fold1_18_15_40.h5\n",
      "Epoch 13/40\n",
      "208/208 [==============================] - 0s 559us/step - loss: 18.0201 - val_loss: 34.5707\n",
      "\n",
      "Epoch 00013: val_loss improved from 39.46688 to 34.57075, saving model to arrMemory_usage0_best_model_fold1_18_15_40.h5\n",
      "Epoch 14/40\n",
      "208/208 [==============================] - 0s 602us/step - loss: 16.0857 - val_loss: 32.2579\n",
      "\n",
      "Epoch 00014: val_loss improved from 34.57075 to 32.25787, saving model to arrMemory_usage0_best_model_fold1_18_15_40.h5\n",
      "Epoch 15/40\n",
      "208/208 [==============================] - 0s 563us/step - loss: 14.9280 - val_loss: 30.7213\n",
      "\n",
      "Epoch 00015: val_loss improved from 32.25787 to 30.72130, saving model to arrMemory_usage0_best_model_fold1_18_15_40.h5\n",
      "Epoch 16/40\n",
      "208/208 [==============================] - 0s 559us/step - loss: 13.8218 - val_loss: 29.5421\n",
      "\n",
      "Epoch 00016: val_loss improved from 30.72130 to 29.54212, saving model to arrMemory_usage0_best_model_fold1_18_15_40.h5\n",
      "Epoch 17/40\n",
      "208/208 [==============================] - 0s 563us/step - loss: 13.0041 - val_loss: 28.8118\n",
      "\n",
      "Epoch 00017: val_loss improved from 29.54212 to 28.81178, saving model to arrMemory_usage0_best_model_fold1_18_15_40.h5\n",
      "Epoch 18/40\n",
      "208/208 [==============================] - 0s 549us/step - loss: 12.6801 - val_loss: 28.4630\n",
      "\n",
      "Epoch 00018: val_loss improved from 28.81178 to 28.46305, saving model to arrMemory_usage0_best_model_fold1_18_15_40.h5\n",
      "Epoch 19/40\n",
      "208/208 [==============================] - 0s 554us/step - loss: 12.3494 - val_loss: 27.9218\n",
      "\n",
      "Epoch 00019: val_loss improved from 28.46305 to 27.92175, saving model to arrMemory_usage0_best_model_fold1_18_15_40.h5\n",
      "Epoch 20/40\n",
      "208/208 [==============================] - 0s 552us/step - loss: 11.9550 - val_loss: 27.2886\n",
      "\n",
      "Epoch 00020: val_loss improved from 27.92175 to 27.28857, saving model to arrMemory_usage0_best_model_fold1_18_15_40.h5\n",
      "Epoch 21/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 11.6226 - val_loss: 26.1546\n",
      "\n",
      "Epoch 00021: val_loss improved from 27.28857 to 26.15462, saving model to arrMemory_usage0_best_model_fold1_18_15_40.h5\n",
      "Epoch 22/40\n",
      "208/208 [==============================] - 0s 559us/step - loss: 11.3550 - val_loss: 26.7149\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 26.15462\n",
      "Epoch 23/40\n",
      "208/208 [==============================] - 0s 538us/step - loss: 11.5181 - val_loss: 26.6408\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 26.15462\n",
      "Epoch 24/40\n",
      "208/208 [==============================] - 0s 557us/step - loss: 10.8417 - val_loss: 26.5364\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 26.15462\n",
      "Epoch 00024: early stopping\n",
      "104/104 [==============================] - 0s 1ms/step\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 570.6361 - val_loss: 460.6451\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 460.64508, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 0s 651us/step - loss: 568.9700 - val_loss: 459.0963\n",
      "\n",
      "Epoch 00002: val_loss improved from 460.64508 to 459.09625, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 0s 606us/step - loss: 567.4972 - val_loss: 457.7385\n",
      "\n",
      "Epoch 00003: val_loss improved from 459.09625 to 457.73848, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 0s 592us/step - loss: 566.2119 - val_loss: 456.5587\n",
      "\n",
      "Epoch 00004: val_loss improved from 457.73848 to 456.55871, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 0s 605us/step - loss: 565.0972 - val_loss: 455.5437\n",
      "\n",
      "Epoch 00005: val_loss improved from 456.55871 to 455.54368, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 0s 873us/step - loss: 564.1433 - val_loss: 454.6775\n",
      "\n",
      "Epoch 00006: val_loss improved from 455.54368 to 454.67755, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 0s 644us/step - loss: 563.3298 - val_loss: 453.9408\n",
      "\n",
      "Epoch 00007: val_loss improved from 454.67755 to 453.94083, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 0s 604us/step - loss: 562.6386 - val_loss: 453.3160\n",
      "\n",
      "Epoch 00008: val_loss improved from 453.94083 to 453.31596, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 0s 577us/step - loss: 562.0502 - val_loss: 452.7535\n",
      "\n",
      "Epoch 00009: val_loss improved from 453.31596 to 452.75345, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 0s 568us/step - loss: 561.3199 - val_loss: 451.8237\n",
      "\n",
      "Epoch 00010: val_loss improved from 452.75345 to 451.82367, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 11/40\n",
      "208/208 [==============================] - 0s 550us/step - loss: 560.2846 - val_loss: 450.8624\n",
      "\n",
      "Epoch 00011: val_loss improved from 451.82367 to 450.86241, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 12/40\n",
      "208/208 [==============================] - 0s 593us/step - loss: 559.3377 - val_loss: 449.9398\n",
      "\n",
      "Epoch 00012: val_loss improved from 450.86241 to 449.93978, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 13/40\n",
      "208/208 [==============================] - 0s 578us/step - loss: 558.3482 - val_loss: 449.0721\n",
      "\n",
      "Epoch 00013: val_loss improved from 449.93978 to 449.07211, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 14/40\n",
      "208/208 [==============================] - 0s 589us/step - loss: 557.4102 - val_loss: 448.1245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00014: val_loss improved from 449.07211 to 448.12450, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 15/40\n",
      "208/208 [==============================] - 0s 594us/step - loss: 556.1393 - val_loss: 445.6807\n",
      "\n",
      "Epoch 00015: val_loss improved from 448.12450 to 445.68072, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 16/40\n",
      "208/208 [==============================] - 0s 604us/step - loss: 550.9942 - val_loss: 437.8221\n",
      "\n",
      "Epoch 00016: val_loss improved from 445.68072 to 437.82207, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 17/40\n",
      "208/208 [==============================] - 0s 560us/step - loss: 539.2941 - val_loss: 426.1903\n",
      "\n",
      "Epoch 00017: val_loss improved from 437.82207 to 426.19031, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 18/40\n",
      "208/208 [==============================] - 0s 590us/step - loss: 526.8527 - val_loss: 407.3795\n",
      "\n",
      "Epoch 00018: val_loss improved from 426.19031 to 407.37945, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 19/40\n",
      "208/208 [==============================] - 0s 654us/step - loss: 484.2531 - val_loss: 346.8602\n",
      "\n",
      "Epoch 00019: val_loss improved from 407.37945 to 346.86022, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 20/40\n",
      "208/208 [==============================] - 0s 550us/step - loss: 413.7349 - val_loss: 291.0468\n",
      "\n",
      "Epoch 00020: val_loss improved from 346.86022 to 291.04680, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 21/40\n",
      "208/208 [==============================] - 0s 581us/step - loss: 374.1271 - val_loss: 294.9400\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 291.04680\n",
      "Epoch 22/40\n",
      "208/208 [==============================] - 0s 607us/step - loss: 331.3932 - val_loss: 251.4102\n",
      "\n",
      "Epoch 00022: val_loss improved from 291.04680 to 251.41018, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 23/40\n",
      "208/208 [==============================] - 0s 616us/step - loss: 288.7827 - val_loss: 227.6390\n",
      "\n",
      "Epoch 00023: val_loss improved from 251.41018 to 227.63899, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 24/40\n",
      "208/208 [==============================] - 0s 570us/step - loss: 242.4381 - val_loss: 170.0417\n",
      "\n",
      "Epoch 00024: val_loss improved from 227.63899 to 170.04172, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 25/40\n",
      "208/208 [==============================] - 0s 570us/step - loss: 179.3782 - val_loss: 107.7791\n",
      "\n",
      "Epoch 00025: val_loss improved from 170.04172 to 107.77910, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 26/40\n",
      "208/208 [==============================] - 0s 582us/step - loss: 110.7408 - val_loss: 67.2698\n",
      "\n",
      "Epoch 00026: val_loss improved from 107.77910 to 67.26982, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 27/40\n",
      "208/208 [==============================] - 0s 558us/step - loss: 70.1287 - val_loss: 48.1074\n",
      "\n",
      "Epoch 00027: val_loss improved from 67.26982 to 48.10745, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 28/40\n",
      "208/208 [==============================] - 0s 582us/step - loss: 49.3231 - val_loss: 31.8930\n",
      "\n",
      "Epoch 00028: val_loss improved from 48.10745 to 31.89301, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 29/40\n",
      "208/208 [==============================] - 0s 586us/step - loss: 38.9830 - val_loss: 24.8974\n",
      "\n",
      "Epoch 00029: val_loss improved from 31.89301 to 24.89742, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 30/40\n",
      "208/208 [==============================] - 0s 576us/step - loss: 34.4016 - val_loss: 26.9784\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 24.89742\n",
      "Epoch 31/40\n",
      "208/208 [==============================] - 0s 534us/step - loss: 35.0351 - val_loss: 28.2794\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 24.89742\n",
      "Epoch 32/40\n",
      "208/208 [==============================] - 0s 557us/step - loss: 33.7707 - val_loss: 20.8039\n",
      "\n",
      "Epoch 00032: val_loss improved from 24.89742 to 20.80389, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 33/40\n",
      "208/208 [==============================] - 0s 557us/step - loss: 31.6769 - val_loss: 19.1749\n",
      "\n",
      "Epoch 00033: val_loss improved from 20.80389 to 19.17494, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 34/40\n",
      "208/208 [==============================] - 0s 598us/step - loss: 29.6024 - val_loss: 17.0707\n",
      "\n",
      "Epoch 00034: val_loss improved from 19.17494 to 17.07067, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 35/40\n",
      "208/208 [==============================] - 0s 593us/step - loss: 29.6315 - val_loss: 16.7179\n",
      "\n",
      "Epoch 00035: val_loss improved from 17.07067 to 16.71795, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 36/40\n",
      "208/208 [==============================] - 0s 588us/step - loss: 29.8819 - val_loss: 16.1521\n",
      "\n",
      "Epoch 00036: val_loss improved from 16.71795 to 16.15214, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 37/40\n",
      "208/208 [==============================] - 0s 588us/step - loss: 28.2708 - val_loss: 18.5603\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 16.15214\n",
      "Epoch 38/40\n",
      "208/208 [==============================] - 0s 586us/step - loss: 28.5525 - val_loss: 15.9726\n",
      "\n",
      "Epoch 00038: val_loss improved from 16.15214 to 15.97260, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 39/40\n",
      "208/208 [==============================] - 0s 572us/step - loss: 27.7325 - val_loss: 14.2695\n",
      "\n",
      "Epoch 00039: val_loss improved from 15.97260 to 14.26947, saving model to arrMemory_usage0_best_model_fold2_18_16_02.h5\n",
      "Epoch 40/40\n",
      "208/208 [==============================] - 0s 590us/step - loss: 27.6345 - val_loss: 16.4306\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 14.26947\n",
      "104/104 [==============================] - 0s 1ms/step\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 522.0497 - val_loss: 522.0303\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 522.03031, saving model to arrMemory_usage0_best_model_fold3_18_16_27.h5\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 0s 613us/step - loss: 486.0690 - val_loss: 457.5194\n",
      "\n",
      "Epoch 00002: val_loss improved from 522.03031 to 457.51941, saving model to arrMemory_usage0_best_model_fold3_18_16_27.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 0s 631us/step - loss: 399.3619 - val_loss: 348.1462\n",
      "\n",
      "Epoch 00003: val_loss improved from 457.51941 to 348.14622, saving model to arrMemory_usage0_best_model_fold3_18_16_27.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 0s 604us/step - loss: 303.1566 - val_loss: 254.2401\n",
      "\n",
      "Epoch 00004: val_loss improved from 348.14622 to 254.24010, saving model to arrMemory_usage0_best_model_fold3_18_16_27.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 0s 605us/step - loss: 236.2352 - val_loss: 178.6764\n",
      "\n",
      "Epoch 00005: val_loss improved from 254.24010 to 178.67637, saving model to arrMemory_usage0_best_model_fold3_18_16_27.h5\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 0s 630us/step - loss: 150.3092 - val_loss: 102.3722\n",
      "\n",
      "Epoch 00006: val_loss improved from 178.67637 to 102.37225, saving model to arrMemory_usage0_best_model_fold3_18_16_27.h5\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 0s 564us/step - loss: 88.8998 - val_loss: 60.8880\n",
      "\n",
      "Epoch 00007: val_loss improved from 102.37225 to 60.88803, saving model to arrMemory_usage0_best_model_fold3_18_16_27.h5\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 64.2868 - val_loss: 38.3667\n",
      "\n",
      "Epoch 00008: val_loss improved from 60.88803 to 38.36670, saving model to arrMemory_usage0_best_model_fold3_18_16_27.h5\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 0s 575us/step - loss: 42.2266 - val_loss: 30.0443\n",
      "\n",
      "Epoch 00009: val_loss improved from 38.36670 to 30.04431, saving model to arrMemory_usage0_best_model_fold3_18_16_27.h5\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 0s 550us/step - loss: 28.3874 - val_loss: 24.4732\n",
      "\n",
      "Epoch 00010: val_loss improved from 30.04431 to 24.47322, saving model to arrMemory_usage0_best_model_fold3_18_16_27.h5\n",
      "Epoch 11/40\n",
      "208/208 [==============================] - 0s 574us/step - loss: 24.5136 - val_loss: 24.0365\n",
      "\n",
      "Epoch 00011: val_loss improved from 24.47322 to 24.03648, saving model to arrMemory_usage0_best_model_fold3_18_16_27.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/40\n",
      "208/208 [==============================] - 0s 556us/step - loss: 21.3244 - val_loss: 20.3848\n",
      "\n",
      "Epoch 00012: val_loss improved from 24.03648 to 20.38485, saving model to arrMemory_usage0_best_model_fold3_18_16_27.h5\n",
      "Epoch 13/40\n",
      "208/208 [==============================] - 0s 593us/step - loss: 18.2316 - val_loss: 20.7573\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 20.38485\n",
      "Epoch 14/40\n",
      "208/208 [==============================] - 0s 554us/step - loss: 19.2691 - val_loss: 17.0703\n",
      "\n",
      "Epoch 00014: val_loss improved from 20.38485 to 17.07029, saving model to arrMemory_usage0_best_model_fold3_18_16_27.h5\n",
      "Epoch 15/40\n",
      "208/208 [==============================] - 0s 583us/step - loss: 16.8284 - val_loss: 16.3558\n",
      "\n",
      "Epoch 00015: val_loss improved from 17.07029 to 16.35581, saving model to arrMemory_usage0_best_model_fold3_18_16_27.h5\n",
      "Epoch 16/40\n",
      "208/208 [==============================] - 0s 544us/step - loss: 15.8527 - val_loss: 15.7123\n",
      "\n",
      "Epoch 00016: val_loss improved from 16.35581 to 15.71230, saving model to arrMemory_usage0_best_model_fold3_18_16_27.h5\n",
      "Epoch 17/40\n",
      "208/208 [==============================] - 0s 564us/step - loss: 15.0001 - val_loss: 15.7630\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 15.71230\n",
      "Epoch 18/40\n",
      "208/208 [==============================] - 0s 572us/step - loss: 14.4332 - val_loss: 15.3257\n",
      "\n",
      "Epoch 00018: val_loss improved from 15.71230 to 15.32575, saving model to arrMemory_usage0_best_model_fold3_18_16_27.h5\n",
      "Epoch 19/40\n",
      "208/208 [==============================] - 0s 571us/step - loss: 13.9352 - val_loss: 15.0912\n",
      "\n",
      "Epoch 00019: val_loss improved from 15.32575 to 15.09119, saving model to arrMemory_usage0_best_model_fold3_18_16_27.h5\n",
      "Epoch 20/40\n",
      "208/208 [==============================] - 0s 548us/step - loss: 13.7853 - val_loss: 14.3681\n",
      "\n",
      "Epoch 00020: val_loss improved from 15.09119 to 14.36814, saving model to arrMemory_usage0_best_model_fold3_18_16_27.h5\n",
      "Epoch 21/40\n",
      "208/208 [==============================] - 0s 690us/step - loss: 12.9444 - val_loss: 13.9093\n",
      "\n",
      "Epoch 00021: val_loss improved from 14.36814 to 13.90934, saving model to arrMemory_usage0_best_model_fold3_18_16_27.h5\n",
      "Epoch 22/40\n",
      "208/208 [==============================] - 0s 622us/step - loss: 12.3232 - val_loss: 13.6195\n",
      "\n",
      "Epoch 00022: val_loss improved from 13.90934 to 13.61953, saving model to arrMemory_usage0_best_model_fold3_18_16_27.h5\n",
      "Epoch 23/40\n",
      "208/208 [==============================] - 0s 543us/step - loss: 12.2194 - val_loss: 13.6195\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 13.61953\n",
      "Epoch 24/40\n",
      "208/208 [==============================] - 0s 556us/step - loss: 11.6299 - val_loss: 12.7876\n",
      "\n",
      "Epoch 00024: val_loss improved from 13.61953 to 12.78762, saving model to arrMemory_usage0_best_model_fold3_18_16_27.h5\n",
      "Epoch 25/40\n",
      "208/208 [==============================] - 0s 578us/step - loss: 11.3724 - val_loss: 12.7903\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 12.78762\n",
      "Epoch 26/40\n",
      "208/208 [==============================] - 0s 551us/step - loss: 11.1512 - val_loss: 12.4196\n",
      "\n",
      "Epoch 00026: val_loss improved from 12.78762 to 12.41962, saving model to arrMemory_usage0_best_model_fold3_18_16_27.h5\n",
      "Epoch 27/40\n",
      "208/208 [==============================] - 0s 557us/step - loss: 11.3208 - val_loss: 11.9552\n",
      "\n",
      "Epoch 00027: val_loss improved from 12.41962 to 11.95524, saving model to arrMemory_usage0_best_model_fold3_18_16_27.h5\n",
      "Epoch 28/40\n",
      "208/208 [==============================] - 0s 652us/step - loss: 10.7886 - val_loss: 11.2579\n",
      "\n",
      "Epoch 00028: val_loss improved from 11.95524 to 11.25785, saving model to arrMemory_usage0_best_model_fold3_18_16_27.h5\n",
      "Epoch 29/40\n",
      "208/208 [==============================] - 0s 774us/step - loss: 10.3229 - val_loss: 11.1706\n",
      "\n",
      "Epoch 00029: val_loss improved from 11.25785 to 11.17059, saving model to arrMemory_usage0_best_model_fold3_18_16_27.h5\n",
      "Epoch 30/40\n",
      "208/208 [==============================] - 0s 556us/step - loss: 9.9123 - val_loss: 11.1804\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 11.17059\n",
      "Epoch 31/40\n",
      "208/208 [==============================] - 0s 558us/step - loss: 9.6868 - val_loss: 10.9667\n",
      "\n",
      "Epoch 00031: val_loss improved from 11.17059 to 10.96674, saving model to arrMemory_usage0_best_model_fold3_18_16_27.h5\n",
      "Epoch 32/40\n",
      "208/208 [==============================] - 0s 580us/step - loss: 9.4927 - val_loss: 10.8706\n",
      "\n",
      "Epoch 00032: val_loss improved from 10.96674 to 10.87061, saving model to arrMemory_usage0_best_model_fold3_18_16_27.h5\n",
      "Epoch 33/40\n",
      "208/208 [==============================] - 0s 545us/step - loss: 9.4680 - val_loss: 10.5399\n",
      "\n",
      "Epoch 00033: val_loss improved from 10.87061 to 10.53989, saving model to arrMemory_usage0_best_model_fold3_18_16_27.h5\n",
      "Epoch 34/40\n",
      "208/208 [==============================] - 0s 558us/step - loss: 9.4339 - val_loss: 10.7936\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 10.53989\n",
      "Epoch 35/40\n",
      "208/208 [==============================] - 0s 533us/step - loss: 8.9850 - val_loss: 10.4268\n",
      "\n",
      "Epoch 00035: val_loss improved from 10.53989 to 10.42676, saving model to arrMemory_usage0_best_model_fold3_18_16_27.h5\n",
      "Epoch 36/40\n",
      "208/208 [==============================] - 0s 570us/step - loss: 8.8495 - val_loss: 10.0766\n",
      "\n",
      "Epoch 00036: val_loss improved from 10.42676 to 10.07663, saving model to arrMemory_usage0_best_model_fold3_18_16_27.h5\n",
      "Epoch 37/40\n",
      "208/208 [==============================] - 0s 910us/step - loss: 8.8205 - val_loss: 10.6378\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 10.07663\n",
      "Epoch 38/40\n",
      "208/208 [==============================] - 0s 842us/step - loss: 9.1112 - val_loss: 10.7406\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 10.07663\n",
      "Epoch 39/40\n",
      "208/208 [==============================] - 0s 866us/step - loss: 9.0478 - val_loss: 10.8717\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 10.07663\n",
      "Epoch 00039: early stopping\n",
      "104/104 [==============================] - 0s 2ms/step\n",
      "arrFans_health0\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 86565790.7692 - val_loss: 87366258.4615\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 87366258.46154, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 0s 603us/step - loss: 86543545.2308 - val_loss: 87323061.5385\n",
      "\n",
      "Epoch 00002: val_loss improved from 87366258.46154 to 87323061.53846, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 0s 604us/step - loss: 86478108.3077 - val_loss: 87225329.8462\n",
      "\n",
      "Epoch 00003: val_loss improved from 87323061.53846 to 87225329.84615, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 0s 563us/step - loss: 86354081.8462 - val_loss: 87083705.8462\n",
      "\n",
      "Epoch 00004: val_loss improved from 87225329.84615 to 87083705.84615, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 86182369.8462 - val_loss: 86900817.8462\n",
      "\n",
      "Epoch 00005: val_loss improved from 87083705.84615 to 86900817.84615, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 0s 549us/step - loss: 85954072.6154 - val_loss: 86666638.1538\n",
      "\n",
      "Epoch 00006: val_loss improved from 86900817.84615 to 86666638.15385, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 85671940.9231 - val_loss: 86333924.9231\n",
      "\n",
      "Epoch 00007: val_loss improved from 86666638.15385 to 86333924.92308, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 0s 571us/step - loss: 85312658.4615 - val_loss: 85980587.0769\n",
      "\n",
      "Epoch 00008: val_loss improved from 86333924.92308 to 85980587.07692, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 0s 555us/step - loss: 84896025.8462 - val_loss: 85556249.8462\n",
      "\n",
      "Epoch 00009: val_loss improved from 85980587.07692 to 85556249.84615, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 0s 564us/step - loss: 84409577.8462 - val_loss: 85076111.3846\n",
      "\n",
      "Epoch 00010: val_loss improved from 85556249.84615 to 85076111.38462, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/40\n",
      "208/208 [==============================] - 0s 570us/step - loss: 83863131.0769 - val_loss: 84504462.1538\n",
      "\n",
      "Epoch 00011: val_loss improved from 85076111.38462 to 84504462.15385, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 12/40\n",
      "208/208 [==============================] - 0s 602us/step - loss: 83247414.1538 - val_loss: 83925635.6923\n",
      "\n",
      "Epoch 00012: val_loss improved from 84504462.15385 to 83925635.69231, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 13/40\n",
      "208/208 [==============================] - 0s 556us/step - loss: 82593208.6154 - val_loss: 83259707.0769\n",
      "\n",
      "Epoch 00013: val_loss improved from 83925635.69231 to 83259707.07692, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 14/40\n",
      "208/208 [==============================] - 0s 556us/step - loss: 81880230.1538 - val_loss: 82529192.6154\n",
      "\n",
      "Epoch 00014: val_loss improved from 83259707.07692 to 82529192.61538, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 15/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 81118666.4615 - val_loss: 81810610.4615\n",
      "\n",
      "Epoch 00015: val_loss improved from 82529192.61538 to 81810610.46154, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 16/40\n",
      "208/208 [==============================] - 0s 551us/step - loss: 80309900.3077 - val_loss: 80940014.7692\n",
      "\n",
      "Epoch 00016: val_loss improved from 81810610.46154 to 80940014.76923, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 17/40\n",
      "208/208 [==============================] - 0s 570us/step - loss: 79441084.9231 - val_loss: 80009897.8462\n",
      "\n",
      "Epoch 00017: val_loss improved from 80940014.76923 to 80009897.84615, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 18/40\n",
      "208/208 [==============================] - 0s 563us/step - loss: 78510772.3077 - val_loss: 79035854.1538\n",
      "\n",
      "Epoch 00018: val_loss improved from 80009897.84615 to 79035854.15385, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 19/40\n",
      "208/208 [==============================] - 0s 548us/step - loss: 77555029.5385 - val_loss: 78066668.3077\n",
      "\n",
      "Epoch 00019: val_loss improved from 79035854.15385 to 78066668.30769, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 20/40\n",
      "208/208 [==============================] - 0s 540us/step - loss: 76544060.3077 - val_loss: 77013430.7692\n",
      "\n",
      "Epoch 00020: val_loss improved from 78066668.30769 to 77013430.76923, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 21/40\n",
      "208/208 [==============================] - 0s 534us/step - loss: 75473187.0769 - val_loss: 75925182.7692\n",
      "\n",
      "Epoch 00021: val_loss improved from 77013430.76923 to 75925182.76923, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 22/40\n",
      "208/208 [==============================] - 0s 524us/step - loss: 74356473.8462 - val_loss: 74805317.5385\n",
      "\n",
      "Epoch 00022: val_loss improved from 75925182.76923 to 74805317.53846, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 23/40\n",
      "208/208 [==============================] - 0s 519us/step - loss: 73197990.1538 - val_loss: 73650989.5385\n",
      "\n",
      "Epoch 00023: val_loss improved from 74805317.53846 to 73650989.53846, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 24/40\n",
      "208/208 [==============================] - 0s 558us/step - loss: 71986494.7692 - val_loss: 72364582.1538\n",
      "\n",
      "Epoch 00024: val_loss improved from 73650989.53846 to 72364582.15385, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 25/40\n",
      "208/208 [==============================] - 0s 577us/step - loss: 70737846.7692 - val_loss: 71085817.2308\n",
      "\n",
      "Epoch 00025: val_loss improved from 72364582.15385 to 71085817.23077, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 26/40\n",
      "208/208 [==============================] - 0s 577us/step - loss: 69419423.3846 - val_loss: 69728580.9231\n",
      "\n",
      "Epoch 00026: val_loss improved from 71085817.23077 to 69728580.92308, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 27/40\n",
      "208/208 [==============================] - 0s 582us/step - loss: 68010215.6923 - val_loss: 68221553.5385\n",
      "\n",
      "Epoch 00027: val_loss improved from 69728580.92308 to 68221553.53846, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 28/40\n",
      "208/208 [==============================] - 0s 608us/step - loss: 66611702.7692 - val_loss: 66826345.5385\n",
      "\n",
      "Epoch 00028: val_loss improved from 68221553.53846 to 66826345.53846, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 29/40\n",
      "208/208 [==============================] - 0s 619us/step - loss: 65112483.3846 - val_loss: 65371915.3846\n",
      "\n",
      "Epoch 00029: val_loss improved from 66826345.53846 to 65371915.38462, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 30/40\n",
      "208/208 [==============================] - 0s 567us/step - loss: 63620213.2308 - val_loss: 63862570.7692\n",
      "\n",
      "Epoch 00030: val_loss improved from 65371915.38462 to 63862570.76923, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 31/40\n",
      "208/208 [==============================] - 0s 603us/step - loss: 62069587.6923 - val_loss: 62492499.3846\n",
      "\n",
      "Epoch 00031: val_loss improved from 63862570.76923 to 62492499.38462, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 32/40\n",
      "208/208 [==============================] - 0s 641us/step - loss: 60643547.6923 - val_loss: 61113399.3846\n",
      "\n",
      "Epoch 00032: val_loss improved from 62492499.38462 to 61113399.38462, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 33/40\n",
      "208/208 [==============================] - 0s 591us/step - loss: 59049115.6923 - val_loss: 59547341.8462\n",
      "\n",
      "Epoch 00033: val_loss improved from 61113399.38462 to 59547341.84615, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 34/40\n",
      "208/208 [==============================] - 0s 570us/step - loss: 57424618.1538 - val_loss: 57874501.2308\n",
      "\n",
      "Epoch 00034: val_loss improved from 59547341.84615 to 57874501.23077, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 35/40\n",
      "208/208 [==============================] - 0s 586us/step - loss: 55713273.5385 - val_loss: 56176520.0000\n",
      "\n",
      "Epoch 00035: val_loss improved from 57874501.23077 to 56176520.00000, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 36/40\n",
      "208/208 [==============================] - 0s 564us/step - loss: 53986146.1538 - val_loss: 54446528.6154\n",
      "\n",
      "Epoch 00036: val_loss improved from 56176520.00000 to 54446528.61538, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 37/40\n",
      "208/208 [==============================] - 0s 591us/step - loss: 52226166.4615 - val_loss: 52687980.6154\n",
      "\n",
      "Epoch 00037: val_loss improved from 54446528.61538 to 52687980.61538, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 38/40\n",
      "208/208 [==============================] - 0s 580us/step - loss: 50430516.9231 - val_loss: 50918338.4615\n",
      "\n",
      "Epoch 00038: val_loss improved from 52687980.61538 to 50918338.46154, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 39/40\n",
      "208/208 [==============================] - 0s 577us/step - loss: 48619444.3077 - val_loss: 49120339.6923\n",
      "\n",
      "Epoch 00039: val_loss improved from 50918338.46154 to 49120339.69231, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "Epoch 40/40\n",
      "208/208 [==============================] - 0s 590us/step - loss: 46798408.0000 - val_loss: 47304582.1538\n",
      "\n",
      "Epoch 00040: val_loss improved from 49120339.69231 to 47304582.15385, saving model to arrFans_health0_best_model_fold1_18_17_29.h5\n",
      "104/104 [==============================] - 0s 1ms/step\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 88059391.3846 - val_loss: 84392068.3077\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 84392068.30769, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 0s 596us/step - loss: 88045023.3846 - val_loss: 84365118.1538\n",
      "\n",
      "Epoch 00002: val_loss improved from 84392068.30769 to 84365118.15385, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 0s 566us/step - loss: 88004064.6154 - val_loss: 84306659.6923\n",
      "\n",
      "Epoch 00003: val_loss improved from 84365118.15385 to 84306659.69231, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/40\n",
      "208/208 [==============================] - 0s 568us/step - loss: 87931016.6154 - val_loss: 84219596.3077\n",
      "\n",
      "Epoch 00004: val_loss improved from 84306659.69231 to 84219596.30769, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 0s 574us/step - loss: 87826369.8462 - val_loss: 84096227.0769\n",
      "\n",
      "Epoch 00005: val_loss improved from 84219596.30769 to 84096227.07692, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 0s 553us/step - loss: 87682273.8462 - val_loss: 83931879.3846\n",
      "\n",
      "Epoch 00006: val_loss improved from 84096227.07692 to 83931879.38462, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 0s 599us/step - loss: 87488016.0000 - val_loss: 83721659.0769\n",
      "\n",
      "Epoch 00007: val_loss improved from 83931879.38462 to 83721659.07692, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 0s 557us/step - loss: 87247759.3846 - val_loss: 83459537.8462\n",
      "\n",
      "Epoch 00008: val_loss improved from 83721659.07692 to 83459537.84615, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 0s 542us/step - loss: 86951132.9231 - val_loss: 83127143.3846\n",
      "\n",
      "Epoch 00009: val_loss improved from 83459537.84615 to 83127143.38462, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 0s 556us/step - loss: 86586898.4615 - val_loss: 82739109.5385\n",
      "\n",
      "Epoch 00010: val_loss improved from 83127143.38462 to 82739109.53846, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 11/40\n",
      "208/208 [==============================] - 0s 574us/step - loss: 86154561.2308 - val_loss: 82296818.1538\n",
      "\n",
      "Epoch 00011: val_loss improved from 82739109.53846 to 82296818.15385, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 12/40\n",
      "208/208 [==============================] - 0s 585us/step - loss: 85665521.2308 - val_loss: 81783468.9231\n",
      "\n",
      "Epoch 00012: val_loss improved from 82296818.15385 to 81783468.92308, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 13/40\n",
      "208/208 [==============================] - 0s 576us/step - loss: 85098856.6154 - val_loss: 81191502.1538\n",
      "\n",
      "Epoch 00013: val_loss improved from 81783468.92308 to 81191502.15385, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 14/40\n",
      "208/208 [==============================] - 0s 565us/step - loss: 84476324.9231 - val_loss: 80559769.8462\n",
      "\n",
      "Epoch 00014: val_loss improved from 81191502.15385 to 80559769.84615, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 15/40\n",
      "208/208 [==============================] - 0s 557us/step - loss: 83811499.6923 - val_loss: 79863940.0000\n",
      "\n",
      "Epoch 00015: val_loss improved from 80559769.84615 to 79863940.00000, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 16/40\n",
      "208/208 [==============================] - 0s 559us/step - loss: 83067064.0000 - val_loss: 79114801.8462\n",
      "\n",
      "Epoch 00016: val_loss improved from 79863940.00000 to 79114801.84615, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 17/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 82264407.0769 - val_loss: 78310793.2308\n",
      "\n",
      "Epoch 00017: val_loss improved from 79114801.84615 to 78310793.23077, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 18/40\n",
      "208/208 [==============================] - 0s 556us/step - loss: 81408401.2308 - val_loss: 77440279.6923\n",
      "\n",
      "Epoch 00018: val_loss improved from 78310793.23077 to 77440279.69231, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 19/40\n",
      "208/208 [==============================] - 0s 562us/step - loss: 80474537.2308 - val_loss: 76497800.9231\n",
      "\n",
      "Epoch 00019: val_loss improved from 77440279.69231 to 76497800.92308, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 20/40\n",
      "208/208 [==============================] - 0s 551us/step - loss: 79467166.1538 - val_loss: 75483226.4615\n",
      "\n",
      "Epoch 00020: val_loss improved from 76497800.92308 to 75483226.46154, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 21/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 78389041.2308 - val_loss: 74384156.6154\n",
      "\n",
      "Epoch 00021: val_loss improved from 75483226.46154 to 74384156.61538, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 22/40\n",
      "208/208 [==============================] - 0s 556us/step - loss: 77213397.2308 - val_loss: 73204593.2308\n",
      "\n",
      "Epoch 00022: val_loss improved from 74384156.61538 to 73204593.23077, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 23/40\n",
      "208/208 [==============================] - 0s 590us/step - loss: 75956400.0000 - val_loss: 71966460.6154\n",
      "\n",
      "Epoch 00023: val_loss improved from 73204593.23077 to 71966460.61538, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 24/40\n",
      "208/208 [==============================] - 0s 556us/step - loss: 74648971.0769 - val_loss: 70658514.4615\n",
      "\n",
      "Epoch 00024: val_loss improved from 71966460.61538 to 70658514.46154, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 25/40\n",
      "208/208 [==============================] - 0s 545us/step - loss: 73250488.6154 - val_loss: 69289735.0769\n",
      "\n",
      "Epoch 00025: val_loss improved from 70658514.46154 to 69289735.07692, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 26/40\n",
      "208/208 [==============================] - 0s 569us/step - loss: 71827596.3077 - val_loss: 67832368.0000\n",
      "\n",
      "Epoch 00026: val_loss improved from 69289735.07692 to 67832368.00000, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 27/40\n",
      "208/208 [==============================] - 0s 574us/step - loss: 70275756.9231 - val_loss: 66296835.0769\n",
      "\n",
      "Epoch 00027: val_loss improved from 67832368.00000 to 66296835.07692, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 28/40\n",
      "208/208 [==============================] - 0s 559us/step - loss: 68665185.5385 - val_loss: 64712381.2308\n",
      "\n",
      "Epoch 00028: val_loss improved from 66296835.07692 to 64712381.23077, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 29/40\n",
      "208/208 [==============================] - 0s 548us/step - loss: 66978856.9231 - val_loss: 63078886.4615\n",
      "\n",
      "Epoch 00029: val_loss improved from 64712381.23077 to 63078886.46154, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 30/40\n",
      "208/208 [==============================] - 0s 563us/step - loss: 65258590.7692 - val_loss: 61388968.6154\n",
      "\n",
      "Epoch 00030: val_loss improved from 63078886.46154 to 61388968.61538, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 31/40\n",
      "208/208 [==============================] - 0s 581us/step - loss: 63491300.6154 - val_loss: 59665975.0769\n",
      "\n",
      "Epoch 00031: val_loss improved from 61388968.61538 to 59665975.07692, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 32/40\n",
      "208/208 [==============================] - 0s 542us/step - loss: 61684606.4615 - val_loss: 57884167.6923\n",
      "\n",
      "Epoch 00032: val_loss improved from 59665975.07692 to 57884167.69231, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 33/40\n",
      "208/208 [==============================] - 0s 558us/step - loss: 59805024.6154 - val_loss: 56061764.9231\n",
      "\n",
      "Epoch 00033: val_loss improved from 57884167.69231 to 56061764.92308, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 34/40\n",
      "208/208 [==============================] - 0s 569us/step - loss: 57880196.0000 - val_loss: 54210664.3077\n",
      "\n",
      "Epoch 00034: val_loss improved from 56061764.92308 to 54210664.30769, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 35/40\n",
      "208/208 [==============================] - 0s 544us/step - loss: 55927200.3077 - val_loss: 52308875.0769\n",
      "\n",
      "Epoch 00035: val_loss improved from 54210664.30769 to 52308875.07692, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 36/40\n",
      "208/208 [==============================] - 0s 568us/step - loss: 53955077.8462 - val_loss: 50363288.3077\n",
      "\n",
      "Epoch 00036: val_loss improved from 52308875.07692 to 50363288.30769, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/40\n",
      "208/208 [==============================] - 0s 547us/step - loss: 51920270.1538 - val_loss: 48402139.6923\n",
      "\n",
      "Epoch 00037: val_loss improved from 50363288.30769 to 48402139.69231, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 38/40\n",
      "208/208 [==============================] - 0s 573us/step - loss: 49885569.2308 - val_loss: 46445473.5385\n",
      "\n",
      "Epoch 00038: val_loss improved from 48402139.69231 to 46445473.53846, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 39/40\n",
      "208/208 [==============================] - 0s 562us/step - loss: 47854072.6154 - val_loss: 44491378.1538\n",
      "\n",
      "Epoch 00039: val_loss improved from 46445473.53846 to 44491378.15385, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "Epoch 40/40\n",
      "208/208 [==============================] - 0s 538us/step - loss: 45797670.1538 - val_loss: 42558458.7692\n",
      "\n",
      "Epoch 00040: val_loss improved from 44491378.15385 to 42558458.76923, saving model to arrFans_health0_best_model_fold2_18_17_55.h5\n",
      "104/104 [==============================] - 0s 1ms/step\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 85888270.1538 - val_loss: 88733288.0000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 88733288.00000, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 0s 601us/step - loss: 85876060.9231 - val_loss: 88710044.9231\n",
      "\n",
      "Epoch 00002: val_loss improved from 88733288.00000 to 88710044.92308, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 0s 570us/step - loss: 85841617.2308 - val_loss: 88656620.3077\n",
      "\n",
      "Epoch 00003: val_loss improved from 88710044.92308 to 88656620.30769, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 0s 589us/step - loss: 85774816.6154 - val_loss: 88569135.3846\n",
      "\n",
      "Epoch 00004: val_loss improved from 88656620.30769 to 88569135.38462, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 85675398.7692 - val_loss: 88449502.7692\n",
      "\n",
      "Epoch 00005: val_loss improved from 88569135.38462 to 88449502.76923, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 0s 573us/step - loss: 85544368.6154 - val_loss: 88299243.6923\n",
      "\n",
      "Epoch 00006: val_loss improved from 88449502.76923 to 88299243.69231, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 0s 588us/step - loss: 85379572.9231 - val_loss: 88100285.5385\n",
      "\n",
      "Epoch 00007: val_loss improved from 88299243.69231 to 88100285.53846, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 0s 582us/step - loss: 85185824.0000 - val_loss: 87860098.4615\n",
      "\n",
      "Epoch 00008: val_loss improved from 88100285.53846 to 87860098.46154, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 0s 572us/step - loss: 84956769.2308 - val_loss: 87595240.0000\n",
      "\n",
      "Epoch 00009: val_loss improved from 87860098.46154 to 87595240.00000, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 0s 575us/step - loss: 84693191.3846 - val_loss: 87301559.3846\n",
      "\n",
      "Epoch 00010: val_loss improved from 87595240.00000 to 87301559.38462, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 11/40\n",
      "208/208 [==============================] - 0s 567us/step - loss: 84386872.0000 - val_loss: 86974056.6154\n",
      "\n",
      "Epoch 00011: val_loss improved from 87301559.38462 to 86974056.61538, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 12/40\n",
      "208/208 [==============================] - 0s 568us/step - loss: 84042107.0769 - val_loss: 86589200.0000\n",
      "\n",
      "Epoch 00012: val_loss improved from 86974056.61538 to 86589200.00000, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 13/40\n",
      "208/208 [==============================] - 0s 567us/step - loss: 83669396.9231 - val_loss: 86174311.3846\n",
      "\n",
      "Epoch 00013: val_loss improved from 86589200.00000 to 86174311.38462, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 14/40\n",
      "208/208 [==============================] - 0s 563us/step - loss: 83257420.3077 - val_loss: 85732945.8462\n",
      "\n",
      "Epoch 00014: val_loss improved from 86174311.38462 to 85732945.84615, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 15/40\n",
      "208/208 [==============================] - 0s 543us/step - loss: 82820001.8462 - val_loss: 85284196.3077\n",
      "\n",
      "Epoch 00015: val_loss improved from 85732945.84615 to 85284196.30769, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 16/40\n",
      "208/208 [==============================] - 0s 539us/step - loss: 82349739.0769 - val_loss: 84775255.3846\n",
      "\n",
      "Epoch 00016: val_loss improved from 85284196.30769 to 84775255.38462, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 17/40\n",
      "208/208 [==============================] - 0s 564us/step - loss: 81847964.9231 - val_loss: 84216662.1538\n",
      "\n",
      "Epoch 00017: val_loss improved from 84775255.38462 to 84216662.15385, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 18/40\n",
      "208/208 [==============================] - 0s 570us/step - loss: 81315800.6154 - val_loss: 83644940.9231\n",
      "\n",
      "Epoch 00018: val_loss improved from 84216662.15385 to 83644940.92308, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 19/40\n",
      "208/208 [==============================] - 0s 572us/step - loss: 80723285.5385 - val_loss: 83047812.3077\n",
      "\n",
      "Epoch 00019: val_loss improved from 83644940.92308 to 83047812.30769, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 20/40\n",
      "208/208 [==============================] - 0s 546us/step - loss: 80108035.0769 - val_loss: 82334616.0000\n",
      "\n",
      "Epoch 00020: val_loss improved from 83047812.30769 to 82334616.00000, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 21/40\n",
      "208/208 [==============================] - 0s 558us/step - loss: 79456499.0769 - val_loss: 81617873.2308\n",
      "\n",
      "Epoch 00021: val_loss improved from 82334616.00000 to 81617873.23077, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 22/40\n",
      "208/208 [==============================] - 0s 573us/step - loss: 78757345.8462 - val_loss: 80868172.3077\n",
      "\n",
      "Epoch 00022: val_loss improved from 81617873.23077 to 80868172.30769, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 23/40\n",
      "208/208 [==============================] - 0s 551us/step - loss: 78020124.9231 - val_loss: 80086738.4615\n",
      "\n",
      "Epoch 00023: val_loss improved from 80868172.30769 to 80086738.46154, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 24/40\n",
      "208/208 [==============================] - 0s 560us/step - loss: 77255102.7692 - val_loss: 79260145.8462\n",
      "\n",
      "Epoch 00024: val_loss improved from 80086738.46154 to 79260145.84615, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 25/40\n",
      "208/208 [==============================] - 0s 567us/step - loss: 76452089.2308 - val_loss: 78389802.4615\n",
      "\n",
      "Epoch 00025: val_loss improved from 79260145.84615 to 78389802.46154, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 26/40\n",
      "208/208 [==============================] - 0s 580us/step - loss: 75599102.7692 - val_loss: 77484236.0000\n",
      "\n",
      "Epoch 00026: val_loss improved from 78389802.46154 to 77484236.00000, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 27/40\n",
      "208/208 [==============================] - 0s 541us/step - loss: 74715526.1538 - val_loss: 76532361.5385\n",
      "\n",
      "Epoch 00027: val_loss improved from 77484236.00000 to 76532361.53846, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 28/40\n",
      "208/208 [==============================] - 0s 565us/step - loss: 73780389.5385 - val_loss: 75542524.0000\n",
      "\n",
      "Epoch 00028: val_loss improved from 76532361.53846 to 75542524.00000, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 29/40\n",
      "208/208 [==============================] - 0s 577us/step - loss: 72820411.6923 - val_loss: 74508237.8462\n",
      "\n",
      "Epoch 00029: val_loss improved from 75542524.00000 to 74508237.84615, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/40\n",
      "208/208 [==============================] - 0s 559us/step - loss: 71754083.0769 - val_loss: 73496354.4615\n",
      "\n",
      "Epoch 00030: val_loss improved from 74508237.84615 to 73496354.46154, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 31/40\n",
      "208/208 [==============================] - 0s 553us/step - loss: 70610229.2308 - val_loss: 72315521.2308\n",
      "\n",
      "Epoch 00031: val_loss improved from 73496354.46154 to 72315521.23077, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 32/40\n",
      "208/208 [==============================] - 0s 590us/step - loss: 69541148.9231 - val_loss: 71127202.4615\n",
      "\n",
      "Epoch 00032: val_loss improved from 72315521.23077 to 71127202.46154, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 33/40\n",
      "208/208 [==============================] - 0s 616us/step - loss: 68357841.2308 - val_loss: 69901248.3077\n",
      "\n",
      "Epoch 00033: val_loss improved from 71127202.46154 to 69901248.30769, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 34/40\n",
      "208/208 [==============================] - 0s 559us/step - loss: 67163178.4615 - val_loss: 68617332.3077\n",
      "\n",
      "Epoch 00034: val_loss improved from 69901248.30769 to 68617332.30769, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 35/40\n",
      "208/208 [==============================] - 0s 555us/step - loss: 65900950.1538 - val_loss: 67290985.5385\n",
      "\n",
      "Epoch 00035: val_loss improved from 68617332.30769 to 67290985.53846, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 36/40\n",
      "208/208 [==============================] - 0s 541us/step - loss: 64598780.9231 - val_loss: 65904289.8462\n",
      "\n",
      "Epoch 00036: val_loss improved from 67290985.53846 to 65904289.84615, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 37/40\n",
      "208/208 [==============================] - 0s 540us/step - loss: 63233130.1538 - val_loss: 64458522.1538\n",
      "\n",
      "Epoch 00037: val_loss improved from 65904289.84615 to 64458522.15385, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 38/40\n",
      "208/208 [==============================] - 0s 595us/step - loss: 61808531.3846 - val_loss: 62954366.1538\n",
      "\n",
      "Epoch 00038: val_loss improved from 64458522.15385 to 62954366.15385, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 39/40\n",
      "208/208 [==============================] - 0s 546us/step - loss: 60329705.5385 - val_loss: 61362764.0000\n",
      "\n",
      "Epoch 00039: val_loss improved from 62954366.15385 to 61362764.00000, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "Epoch 40/40\n",
      "208/208 [==============================] - 0s 562us/step - loss: 58746829.2308 - val_loss: 59683991.0769\n",
      "\n",
      "Epoch 00040: val_loss improved from 61362764.00000 to 59683991.07692, saving model to arrFans_health0_best_model_fold3_18_18_20.h5\n",
      "104/104 [==============================] - 0s 1ms/step\n",
      "arrFans_health1\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 80787845.5385 - val_loss: 84984748.9231\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 84984748.92308, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 0s 570us/step - loss: 80751955.0769 - val_loss: 84909638.1538\n",
      "\n",
      "Epoch 00002: val_loss improved from 84984748.92308 to 84909638.15385, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 0s 555us/step - loss: 80651333.5385 - val_loss: 84748266.4615\n",
      "\n",
      "Epoch 00003: val_loss improved from 84909638.15385 to 84748266.46154, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 0s 593us/step - loss: 80473823.3846 - val_loss: 84522616.0000\n",
      "\n",
      "Epoch 00004: val_loss improved from 84748266.46154 to 84522616.00000, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 0s 578us/step - loss: 80234022.1538 - val_loss: 84247067.0769\n",
      "\n",
      "Epoch 00005: val_loss improved from 84522616.00000 to 84247067.07692, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 0s 591us/step - loss: 79964787.0769 - val_loss: 83941850.4615\n",
      "\n",
      "Epoch 00006: val_loss improved from 84247067.07692 to 83941850.46154, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 0s 575us/step - loss: 79667835.6923 - val_loss: 83591293.5385\n",
      "\n",
      "Epoch 00007: val_loss improved from 83941850.46154 to 83591293.53846, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 0s 582us/step - loss: 79334732.3077 - val_loss: 83228714.4615\n",
      "\n",
      "Epoch 00008: val_loss improved from 83591293.53846 to 83228714.46154, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 0s 580us/step - loss: 78962593.2308 - val_loss: 82807329.8462\n",
      "\n",
      "Epoch 00009: val_loss improved from 83228714.46154 to 82807329.84615, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 0s 565us/step - loss: 78534503.3846 - val_loss: 82338819.0769\n",
      "\n",
      "Epoch 00010: val_loss improved from 82807329.84615 to 82338819.07692, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 11/40\n",
      "208/208 [==============================] - 0s 568us/step - loss: 78084385.2308 - val_loss: 81803872.6154\n",
      "\n",
      "Epoch 00011: val_loss improved from 82338819.07692 to 81803872.61538, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 12/40\n",
      "208/208 [==============================] - 0s 578us/step - loss: 77549406.7692 - val_loss: 81214148.9231\n",
      "\n",
      "Epoch 00012: val_loss improved from 81803872.61538 to 81214148.92308, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 13/40\n",
      "208/208 [==============================] - 0s 585us/step - loss: 76954500.9231 - val_loss: 80556353.5385\n",
      "\n",
      "Epoch 00013: val_loss improved from 81214148.92308 to 80556353.53846, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 14/40\n",
      "208/208 [==============================] - 0s 586us/step - loss: 76310536.6154 - val_loss: 79814268.6154\n",
      "\n",
      "Epoch 00014: val_loss improved from 80556353.53846 to 79814268.61538, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 15/40\n",
      "208/208 [==============================] - 0s 568us/step - loss: 75571059.6923 - val_loss: 78984056.3077\n",
      "\n",
      "Epoch 00015: val_loss improved from 79814268.61538 to 78984056.30769, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 16/40\n",
      "208/208 [==============================] - 0s 578us/step - loss: 74654500.3077 - val_loss: 77842132.3077\n",
      "\n",
      "Epoch 00016: val_loss improved from 78984056.30769 to 77842132.30769, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 17/40\n",
      "208/208 [==============================] - 0s 550us/step - loss: 73568986.4615 - val_loss: 76697342.4615\n",
      "\n",
      "Epoch 00017: val_loss improved from 77842132.30769 to 76697342.46154, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 18/40\n",
      "208/208 [==============================] - 0s 592us/step - loss: 72393438.1538 - val_loss: 75365987.3846\n",
      "\n",
      "Epoch 00018: val_loss improved from 76697342.46154 to 75365987.38462, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 19/40\n",
      "208/208 [==============================] - 0s 566us/step - loss: 70997844.9231 - val_loss: 73775031.3846\n",
      "\n",
      "Epoch 00019: val_loss improved from 75365987.38462 to 73775031.38462, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 20/40\n",
      "208/208 [==============================] - 0s 570us/step - loss: 69383107.0769 - val_loss: 72010740.3077\n",
      "\n",
      "Epoch 00020: val_loss improved from 73775031.38462 to 72010740.30769, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 21/40\n",
      "208/208 [==============================] - 0s 572us/step - loss: 67618382.7692 - val_loss: 70186357.2308\n",
      "\n",
      "Epoch 00021: val_loss improved from 72010740.30769 to 70186357.23077, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 22/40\n",
      "208/208 [==============================] - 0s 571us/step - loss: 65842922.1538 - val_loss: 68310234.1538\n",
      "\n",
      "Epoch 00022: val_loss improved from 70186357.23077 to 68310234.15385, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/40\n",
      "208/208 [==============================] - 0s 557us/step - loss: 64007245.5385 - val_loss: 66350343.6923\n",
      "\n",
      "Epoch 00023: val_loss improved from 68310234.15385 to 66350343.69231, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 24/40\n",
      "208/208 [==============================] - 0s 577us/step - loss: 62094660.0000 - val_loss: 64334430.1538\n",
      "\n",
      "Epoch 00024: val_loss improved from 66350343.69231 to 64334430.15385, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 25/40\n",
      "208/208 [==============================] - 0s 545us/step - loss: 60089696.9231 - val_loss: 62215346.4615\n",
      "\n",
      "Epoch 00025: val_loss improved from 64334430.15385 to 62215346.46154, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 26/40\n",
      "208/208 [==============================] - 0s 536us/step - loss: 58019488.9231 - val_loss: 60046199.6923\n",
      "\n",
      "Epoch 00026: val_loss improved from 62215346.46154 to 60046199.69231, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 27/40\n",
      "208/208 [==============================] - 0s 592us/step - loss: 55894427.6923 - val_loss: 57795384.0000\n",
      "\n",
      "Epoch 00027: val_loss improved from 60046199.69231 to 57795384.00000, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 28/40\n",
      "208/208 [==============================] - 0s 543us/step - loss: 53695276.6154 - val_loss: 55431109.2308\n",
      "\n",
      "Epoch 00028: val_loss improved from 57795384.00000 to 55431109.23077, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 29/40\n",
      "208/208 [==============================] - 0s 558us/step - loss: 51432695.3846 - val_loss: 53048250.1538\n",
      "\n",
      "Epoch 00029: val_loss improved from 55431109.23077 to 53048250.15385, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 30/40\n",
      "208/208 [==============================] - 0s 548us/step - loss: 49114112.6154 - val_loss: 50671395.0769\n",
      "\n",
      "Epoch 00030: val_loss improved from 53048250.15385 to 50671395.07692, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 31/40\n",
      "208/208 [==============================] - 0s 563us/step - loss: 46741026.7692 - val_loss: 48278653.8462\n",
      "\n",
      "Epoch 00031: val_loss improved from 50671395.07692 to 48278653.84615, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 32/40\n",
      "208/208 [==============================] - 0s 542us/step - loss: 44386252.3077 - val_loss: 45634768.3077\n",
      "\n",
      "Epoch 00032: val_loss improved from 48278653.84615 to 45634768.30769, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 33/40\n",
      "208/208 [==============================] - 0s 575us/step - loss: 42110717.8462 - val_loss: 43288751.6923\n",
      "\n",
      "Epoch 00033: val_loss improved from 45634768.30769 to 43288751.69231, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 34/40\n",
      "208/208 [==============================] - 0s 562us/step - loss: 39529468.9231 - val_loss: 40914284.6154\n",
      "\n",
      "Epoch 00034: val_loss improved from 43288751.69231 to 40914284.61538, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 35/40\n",
      "208/208 [==============================] - 0s 555us/step - loss: 37204246.3077 - val_loss: 38123530.0000\n",
      "\n",
      "Epoch 00035: val_loss improved from 40914284.61538 to 38123530.00000, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 36/40\n",
      "208/208 [==============================] - 0s 566us/step - loss: 34743107.3846 - val_loss: 35807953.2308\n",
      "\n",
      "Epoch 00036: val_loss improved from 38123530.00000 to 35807953.23077, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 37/40\n",
      "208/208 [==============================] - 0s 573us/step - loss: 32600645.8462 - val_loss: 33563343.2308\n",
      "\n",
      "Epoch 00037: val_loss improved from 35807953.23077 to 33563343.23077, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 38/40\n",
      "208/208 [==============================] - 0s 550us/step - loss: 30263443.2308 - val_loss: 31155579.0769\n",
      "\n",
      "Epoch 00038: val_loss improved from 33563343.23077 to 31155579.07692, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 39/40\n",
      "208/208 [==============================] - 0s 574us/step - loss: 27883910.6154 - val_loss: 28771306.6154\n",
      "\n",
      "Epoch 00039: val_loss improved from 31155579.07692 to 28771306.61538, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "Epoch 40/40\n",
      "208/208 [==============================] - 0s 544us/step - loss: 25627848.6154 - val_loss: 26312916.6154\n",
      "\n",
      "Epoch 00040: val_loss improved from 28771306.61538 to 26312916.61538, saving model to arrFans_health1_best_model_fold1_18_19_13.h5\n",
      "104/104 [==============================] - 0s 1ms/step\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 82803012.3077 - val_loss: 80970224.6154\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 80970224.61538, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 0s 638us/step - loss: 82785329.2308 - val_loss: 80938620.9231\n",
      "\n",
      "Epoch 00002: val_loss improved from 80970224.61538 to 80938620.92308, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 0s 603us/step - loss: 82736195.6923 - val_loss: 80867709.5385\n",
      "\n",
      "Epoch 00003: val_loss improved from 80938620.92308 to 80867709.53846, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 82650909.5385 - val_loss: 80756849.2308\n",
      "\n",
      "Epoch 00004: val_loss improved from 80867709.53846 to 80756849.23077, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 0s 585us/step - loss: 82532123.6923 - val_loss: 80610203.6923\n",
      "\n",
      "Epoch 00005: val_loss improved from 80756849.23077 to 80610203.69231, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 0s 573us/step - loss: 82373823.3846 - val_loss: 80422686.7692\n",
      "\n",
      "Epoch 00006: val_loss improved from 80610203.69231 to 80422686.76923, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 0s 566us/step - loss: 82168487.3846 - val_loss: 80184740.3077\n",
      "\n",
      "Epoch 00007: val_loss improved from 80422686.76923 to 80184740.30769, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 0s 571us/step - loss: 81918061.5385 - val_loss: 79903810.4615\n",
      "\n",
      "Epoch 00008: val_loss improved from 80184740.30769 to 79903810.46154, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 0s 583us/step - loss: 81626796.3077 - val_loss: 79595175.3846\n",
      "\n",
      "Epoch 00009: val_loss improved from 79903810.46154 to 79595175.38462, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 0s 572us/step - loss: 81309364.9231 - val_loss: 79258981.8462\n",
      "\n",
      "Epoch 00010: val_loss improved from 79595175.38462 to 79258981.84615, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 11/40\n",
      "208/208 [==============================] - 0s 558us/step - loss: 80954408.6154 - val_loss: 78878103.0769\n",
      "\n",
      "Epoch 00011: val_loss improved from 79258981.84615 to 78878103.07692, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 12/40\n",
      "208/208 [==============================] - 0s 568us/step - loss: 80573872.0000 - val_loss: 78463117.5385\n",
      "\n",
      "Epoch 00012: val_loss improved from 78878103.07692 to 78463117.53846, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 13/40\n",
      "208/208 [==============================] - 0s 580us/step - loss: 80147475.6923 - val_loss: 78011127.3846\n",
      "\n",
      "Epoch 00013: val_loss improved from 78463117.53846 to 78011127.38462, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 14/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 79689099.0769 - val_loss: 77529474.7692\n",
      "\n",
      "Epoch 00014: val_loss improved from 78011127.38462 to 77529474.76923, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 15/40\n",
      "208/208 [==============================] - 0s 572us/step - loss: 79196395.0769 - val_loss: 77021702.7692\n",
      "\n",
      "Epoch 00015: val_loss improved from 77529474.76923 to 77021702.76923, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/40\n",
      "208/208 [==============================] - 0s 549us/step - loss: 78679470.1538 - val_loss: 76474464.3077\n",
      "\n",
      "Epoch 00016: val_loss improved from 77021702.76923 to 76474464.30769, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 17/40\n",
      "208/208 [==============================] - 0s 550us/step - loss: 78120960.0000 - val_loss: 75895023.6923\n",
      "\n",
      "Epoch 00017: val_loss improved from 76474464.30769 to 75895023.69231, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 18/40\n",
      "208/208 [==============================] - 0s 554us/step - loss: 77526692.3077 - val_loss: 75281315.3846\n",
      "\n",
      "Epoch 00018: val_loss improved from 75895023.69231 to 75281315.38462, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 19/40\n",
      "208/208 [==============================] - 0s 558us/step - loss: 76905398.1538 - val_loss: 74631416.6154\n",
      "\n",
      "Epoch 00019: val_loss improved from 75281315.38462 to 74631416.61538, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 20/40\n",
      "208/208 [==============================] - 0s 559us/step - loss: 76242122.4615 - val_loss: 73947518.7692\n",
      "\n",
      "Epoch 00020: val_loss improved from 74631416.61538 to 73947518.76923, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 21/40\n",
      "208/208 [==============================] - 0s 563us/step - loss: 75541668.3077 - val_loss: 73228247.0769\n",
      "\n",
      "Epoch 00021: val_loss improved from 73947518.76923 to 73228247.07692, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 22/40\n",
      "208/208 [==============================] - 0s 575us/step - loss: 74816234.4615 - val_loss: 72461956.3077\n",
      "\n",
      "Epoch 00022: val_loss improved from 73228247.07692 to 72461956.30769, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 23/40\n",
      "208/208 [==============================] - 0s 541us/step - loss: 74033235.6923 - val_loss: 71660111.3846\n",
      "\n",
      "Epoch 00023: val_loss improved from 72461956.30769 to 71660111.38462, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 24/40\n",
      "208/208 [==============================] - 0s 556us/step - loss: 73221600.0000 - val_loss: 70805601.5385\n",
      "\n",
      "Epoch 00024: val_loss improved from 71660111.38462 to 70805601.53846, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 25/40\n",
      "208/208 [==============================] - 0s 546us/step - loss: 72350155.0769 - val_loss: 69911623.3846\n",
      "\n",
      "Epoch 00025: val_loss improved from 70805601.53846 to 69911623.38462, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 26/40\n",
      "208/208 [==============================] - 0s 552us/step - loss: 71434030.1538 - val_loss: 68976489.8462\n",
      "\n",
      "Epoch 00026: val_loss improved from 69911623.38462 to 68976489.84615, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 27/40\n",
      "208/208 [==============================] - 0s 564us/step - loss: 70478693.5385 - val_loss: 67993130.1538\n",
      "\n",
      "Epoch 00027: val_loss improved from 68976489.84615 to 67993130.15385, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 28/40\n",
      "208/208 [==============================] - 0s 553us/step - loss: 69480774.7692 - val_loss: 66957096.9231\n",
      "\n",
      "Epoch 00028: val_loss improved from 67993130.15385 to 66957096.92308, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 29/40\n",
      "208/208 [==============================] - 0s 550us/step - loss: 68427263.0769 - val_loss: 65876037.2308\n",
      "\n",
      "Epoch 00029: val_loss improved from 66957096.92308 to 65876037.23077, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 30/40\n",
      "208/208 [==============================] - 0s 569us/step - loss: 67320007.3846 - val_loss: 64754013.5385\n",
      "\n",
      "Epoch 00030: val_loss improved from 65876037.23077 to 64754013.53846, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 31/40\n",
      "208/208 [==============================] - 0s 558us/step - loss: 66183007.6923 - val_loss: 63583418.1538\n",
      "\n",
      "Epoch 00031: val_loss improved from 64754013.53846 to 63583418.15385, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 32/40\n",
      "208/208 [==============================] - 0s 560us/step - loss: 64993452.3077 - val_loss: 62382319.3846\n",
      "\n",
      "Epoch 00032: val_loss improved from 63583418.15385 to 62382319.38462, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 33/40\n",
      "208/208 [==============================] - 0s 566us/step - loss: 63767764.6154 - val_loss: 61129004.6154\n",
      "\n",
      "Epoch 00033: val_loss improved from 62382319.38462 to 61129004.61538, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 34/40\n",
      "208/208 [==============================] - 0s 579us/step - loss: 62494464.9231 - val_loss: 59813773.2308\n",
      "\n",
      "Epoch 00034: val_loss improved from 61129004.61538 to 59813773.23077, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 35/40\n",
      "208/208 [==============================] - 0s 588us/step - loss: 61131301.8462 - val_loss: 58426303.3846\n",
      "\n",
      "Epoch 00035: val_loss improved from 59813773.23077 to 58426303.38462, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 36/40\n",
      "208/208 [==============================] - 0s 550us/step - loss: 59712207.3846 - val_loss: 56970301.5385\n",
      "\n",
      "Epoch 00036: val_loss improved from 58426303.38462 to 56970301.53846, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 37/40\n",
      "208/208 [==============================] - 0s 552us/step - loss: 58227444.3077 - val_loss: 55454306.7692\n",
      "\n",
      "Epoch 00037: val_loss improved from 56970301.53846 to 55454306.76923, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 38/40\n",
      "208/208 [==============================] - 0s 575us/step - loss: 56670278.7692 - val_loss: 53896309.2308\n",
      "\n",
      "Epoch 00038: val_loss improved from 55454306.76923 to 53896309.23077, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 39/40\n",
      "208/208 [==============================] - 0s 557us/step - loss: 55087076.0000 - val_loss: 52294780.6154\n",
      "\n",
      "Epoch 00039: val_loss improved from 53896309.23077 to 52294780.61538, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "Epoch 40/40\n",
      "208/208 [==============================] - 0s 556us/step - loss: 53452751.6923 - val_loss: 50661761.5385\n",
      "\n",
      "Epoch 00040: val_loss improved from 52294780.61538 to 50661761.53846, saving model to arrFans_health1_best_model_fold2_18_19_38.h5\n",
      "104/104 [==============================] - 0s 1ms/step\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 82986457.2308 - val_loss: 80590911.3846\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 80590911.38462, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 0s 633us/step - loss: 82962075.6923 - val_loss: 80542521.2308\n",
      "\n",
      "Epoch 00002: val_loss improved from 80590911.38462 to 80542521.23077, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 0s 603us/step - loss: 82893891.0769 - val_loss: 80435653.5385\n",
      "\n",
      "Epoch 00003: val_loss improved from 80542521.23077 to 80435653.53846, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 0s 577us/step - loss: 82761198.1538 - val_loss: 80263480.6154\n",
      "\n",
      "Epoch 00004: val_loss improved from 80435653.53846 to 80263480.61538, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 0s 584us/step - loss: 82541009.2308 - val_loss: 80008044.3077\n",
      "\n",
      "Epoch 00005: val_loss improved from 80263480.61538 to 80008044.30769, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 0s 553us/step - loss: 82237208.6154 - val_loss: 79637797.5385\n",
      "\n",
      "Epoch 00006: val_loss improved from 80008044.30769 to 79637797.53846, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 0s 526us/step - loss: 81822704.6154 - val_loss: 79151964.3077\n",
      "\n",
      "Epoch 00007: val_loss improved from 79637797.53846 to 79151964.30769, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 0s 586us/step - loss: 81306936.6154 - val_loss: 78656585.8462\n",
      "\n",
      "Epoch 00008: val_loss improved from 79151964.30769 to 78656585.84615, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 80779328.0000 - val_loss: 78119516.3077\n",
      "\n",
      "Epoch 00009: val_loss improved from 78656585.84615 to 78119516.30769, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 0s 578us/step - loss: 80207705.8462 - val_loss: 77515739.0769\n",
      "\n",
      "Epoch 00010: val_loss improved from 78119516.30769 to 77515739.07692, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 11/40\n",
      "208/208 [==============================] - 0s 577us/step - loss: 79587123.6923 - val_loss: 76881871.3846\n",
      "\n",
      "Epoch 00011: val_loss improved from 77515739.07692 to 76881871.38462, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 12/40\n",
      "208/208 [==============================] - 0s 613us/step - loss: 78917926.7692 - val_loss: 76190045.5385\n",
      "\n",
      "Epoch 00012: val_loss improved from 76881871.38462 to 76190045.53846, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 13/40\n",
      "208/208 [==============================] - 0s 557us/step - loss: 78186491.0769 - val_loss: 75436468.9231\n",
      "\n",
      "Epoch 00013: val_loss improved from 76190045.53846 to 75436468.92308, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 14/40\n",
      "208/208 [==============================] - 0s 567us/step - loss: 77391532.9231 - val_loss: 74613627.6923\n",
      "\n",
      "Epoch 00014: val_loss improved from 75436468.92308 to 74613627.69231, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 15/40\n",
      "208/208 [==============================] - 0s 578us/step - loss: 76525606.1538 - val_loss: 73721913.8462\n",
      "\n",
      "Epoch 00015: val_loss improved from 74613627.69231 to 73721913.84615, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 16/40\n",
      "208/208 [==============================] - 0s 558us/step - loss: 75591240.6154 - val_loss: 72756570.1538\n",
      "\n",
      "Epoch 00016: val_loss improved from 73721913.84615 to 72756570.15385, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 17/40\n",
      "208/208 [==============================] - 0s 565us/step - loss: 74569876.3077 - val_loss: 71722957.5385\n",
      "\n",
      "Epoch 00017: val_loss improved from 72756570.15385 to 71722957.53846, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 18/40\n",
      "208/208 [==============================] - 0s 569us/step - loss: 73488516.9231 - val_loss: 70608116.6154\n",
      "\n",
      "Epoch 00018: val_loss improved from 71722957.53846 to 70608116.61538, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 19/40\n",
      "208/208 [==============================] - 0s 564us/step - loss: 72316755.6923 - val_loss: 69415864.3077\n",
      "\n",
      "Epoch 00019: val_loss improved from 70608116.61538 to 69415864.30769, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 20/40\n",
      "208/208 [==============================] - 0s 547us/step - loss: 71070816.6154 - val_loss: 68141161.5385\n",
      "\n",
      "Epoch 00020: val_loss improved from 69415864.30769 to 68141161.53846, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 21/40\n",
      "208/208 [==============================] - 0s 556us/step - loss: 69731519.3846 - val_loss: 66789344.0000\n",
      "\n",
      "Epoch 00021: val_loss improved from 68141161.53846 to 66789344.00000, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 22/40\n",
      "208/208 [==============================] - 0s 546us/step - loss: 68320416.0000 - val_loss: 65358581.8462\n",
      "\n",
      "Epoch 00022: val_loss improved from 66789344.00000 to 65358581.84615, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 23/40\n",
      "208/208 [==============================] - 0s 563us/step - loss: 66818414.7692 - val_loss: 63854702.4615\n",
      "\n",
      "Epoch 00023: val_loss improved from 65358581.84615 to 63854702.46154, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 24/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 65254240.6154 - val_loss: 62268163.6923\n",
      "\n",
      "Epoch 00024: val_loss improved from 63854702.46154 to 62268163.69231, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 25/40\n",
      "208/208 [==============================] - 0s 546us/step - loss: 63598579.6923 - val_loss: 60609899.6923\n",
      "\n",
      "Epoch 00025: val_loss improved from 62268163.69231 to 60609899.69231, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 26/40\n",
      "208/208 [==============================] - 0s 544us/step - loss: 61880889.5385 - val_loss: 58873272.0000\n",
      "\n",
      "Epoch 00026: val_loss improved from 60609899.69231 to 58873272.00000, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 27/40\n",
      "208/208 [==============================] - 0s 564us/step - loss: 60077359.0769 - val_loss: 57073378.4615\n",
      "\n",
      "Epoch 00027: val_loss improved from 58873272.00000 to 57073378.46154, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 28/40\n",
      "208/208 [==============================] - 0s 549us/step - loss: 58210999.6923 - val_loss: 55211170.7692\n",
      "\n",
      "Epoch 00028: val_loss improved from 57073378.46154 to 55211170.76923, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 29/40\n",
      "208/208 [==============================] - 0s 577us/step - loss: 56279584.0000 - val_loss: 53290373.5385\n",
      "\n",
      "Epoch 00029: val_loss improved from 55211170.76923 to 53290373.53846, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 30/40\n",
      "208/208 [==============================] - 0s 545us/step - loss: 54288060.9231 - val_loss: 51316660.3077\n",
      "\n",
      "Epoch 00030: val_loss improved from 53290373.53846 to 51316660.30769, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 31/40\n",
      "208/208 [==============================] - 0s 556us/step - loss: 52240868.6154 - val_loss: 49298984.3077\n",
      "\n",
      "Epoch 00031: val_loss improved from 51316660.30769 to 49298984.30769, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 32/40\n",
      "208/208 [==============================] - 0s 622us/step - loss: 50162028.6154 - val_loss: 47230294.1538\n",
      "\n",
      "Epoch 00032: val_loss improved from 49298984.30769 to 47230294.15385, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 33/40\n",
      "208/208 [==============================] - 0s 670us/step - loss: 48024776.6154 - val_loss: 45133928.6154\n",
      "\n",
      "Epoch 00033: val_loss improved from 47230294.15385 to 45133928.61538, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 34/40\n",
      "208/208 [==============================] - 0s 555us/step - loss: 45864779.0769 - val_loss: 43014479.3846\n",
      "\n",
      "Epoch 00034: val_loss improved from 45133928.61538 to 43014479.38462, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 35/40\n",
      "208/208 [==============================] - 0s 547us/step - loss: 43680967.0769 - val_loss: 40874132.3077\n",
      "\n",
      "Epoch 00035: val_loss improved from 43014479.38462 to 40874132.30769, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 36/40\n",
      "208/208 [==============================] - 0s 549us/step - loss: 41470053.2308 - val_loss: 38725215.8462\n",
      "\n",
      "Epoch 00036: val_loss improved from 40874132.30769 to 38725215.84615, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 37/40\n",
      "208/208 [==============================] - 0s 548us/step - loss: 39268706.4615 - val_loss: 36572417.0769\n",
      "\n",
      "Epoch 00037: val_loss improved from 38725215.84615 to 36572417.07692, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 38/40\n",
      "208/208 [==============================] - 0s 553us/step - loss: 37049750.7692 - val_loss: 34430642.4615\n",
      "\n",
      "Epoch 00038: val_loss improved from 36572417.07692 to 34430642.46154, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 39/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 34858019.3846 - val_loss: 32298288.6154\n",
      "\n",
      "Epoch 00039: val_loss improved from 34430642.46154 to 32298288.61538, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "Epoch 40/40\n",
      "208/208 [==============================] - 0s 567us/step - loss: 32670989.8462 - val_loss: 30200038.7692\n",
      "\n",
      "Epoch 00040: val_loss improved from 32298288.61538 to 30200038.76923, saving model to arrFans_health1_best_model_fold3_18_20_04.h5\n",
      "104/104 [==============================] - 0s 1ms/step\n",
      "arrFans_health2\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 81256842.4615 - val_loss: 86420529.2308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 86420529.23077, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 0s 559us/step - loss: 81233601.8462 - val_loss: 86369331.6923\n",
      "\n",
      "Epoch 00002: val_loss improved from 86420529.23077 to 86369331.69231, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 0s 571us/step - loss: 81168980.3077 - val_loss: 86256310.7692\n",
      "\n",
      "Epoch 00003: val_loss improved from 86369331.69231 to 86256310.76923, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 0s 560us/step - loss: 81060937.8462 - val_loss: 86092844.9231\n",
      "\n",
      "Epoch 00004: val_loss improved from 86256310.76923 to 86092844.92308, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 0s 565us/step - loss: 80912566.7692 - val_loss: 85897002.4615\n",
      "\n",
      "Epoch 00005: val_loss improved from 86092844.92308 to 85897002.46154, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 0s 603us/step - loss: 80743605.5385 - val_loss: 85687488.6154\n",
      "\n",
      "Epoch 00006: val_loss improved from 85897002.46154 to 85687488.61538, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 0s 594us/step - loss: 80542641.8462 - val_loss: 85432822.1538\n",
      "\n",
      "Epoch 00007: val_loss improved from 85687488.61538 to 85432822.15385, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 0s 582us/step - loss: 80299251.6923 - val_loss: 85147524.9231\n",
      "\n",
      "Epoch 00008: val_loss improved from 85432822.15385 to 85147524.92308, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 0s 563us/step - loss: 80042187.0769 - val_loss: 84840758.1538\n",
      "\n",
      "Epoch 00009: val_loss improved from 85147524.92308 to 84840758.15385, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 0s 574us/step - loss: 79725488.0000 - val_loss: 84450833.2308\n",
      "\n",
      "Epoch 00010: val_loss improved from 84840758.15385 to 84450833.23077, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 11/40\n",
      "208/208 [==============================] - 0s 563us/step - loss: 79259273.8462 - val_loss: 84019058.4615\n",
      "\n",
      "Epoch 00011: val_loss improved from 84450833.23077 to 84019058.46154, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 12/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 78770827.6923 - val_loss: 83515617.2308\n",
      "\n",
      "Epoch 00012: val_loss improved from 84019058.46154 to 83515617.23077, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 13/40\n",
      "208/208 [==============================] - 0s 552us/step - loss: 78235363.0769 - val_loss: 82899329.8462\n",
      "\n",
      "Epoch 00013: val_loss improved from 83515617.23077 to 82899329.84615, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 14/40\n",
      "208/208 [==============================] - 0s 574us/step - loss: 77665256.6154 - val_loss: 82252848.0000\n",
      "\n",
      "Epoch 00014: val_loss improved from 82899329.84615 to 82252848.00000, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 15/40\n",
      "208/208 [==============================] - 0s 560us/step - loss: 77035338.4615 - val_loss: 81515480.6154\n",
      "\n",
      "Epoch 00015: val_loss improved from 82252848.00000 to 81515480.61538, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 16/40\n",
      "208/208 [==============================] - 0s 549us/step - loss: 76349521.8462 - val_loss: 80694089.8462\n",
      "\n",
      "Epoch 00016: val_loss improved from 81515480.61538 to 80694089.84615, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 17/40\n",
      "208/208 [==============================] - 0s 553us/step - loss: 75587250.4615 - val_loss: 79847497.8462\n",
      "\n",
      "Epoch 00017: val_loss improved from 80694089.84615 to 79847497.84615, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 18/40\n",
      "208/208 [==============================] - 0s 549us/step - loss: 74742876.3077 - val_loss: 78899182.1538\n",
      "\n",
      "Epoch 00018: val_loss improved from 79847497.84615 to 78899182.15385, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 19/40\n",
      "208/208 [==============================] - 0s 580us/step - loss: 73815437.5385 - val_loss: 77864660.3077\n",
      "\n",
      "Epoch 00019: val_loss improved from 78899182.15385 to 77864660.30769, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 20/40\n",
      "208/208 [==============================] - 0s 571us/step - loss: 72771682.4615 - val_loss: 76400864.0000\n",
      "\n",
      "Epoch 00020: val_loss improved from 77864660.30769 to 76400864.00000, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 21/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 71083164.0000 - val_loss: 75079268.3077\n",
      "\n",
      "Epoch 00021: val_loss improved from 76400864.00000 to 75079268.30769, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 22/40\n",
      "208/208 [==============================] - 0s 544us/step - loss: 69768010.4615 - val_loss: 73697686.4615\n",
      "\n",
      "Epoch 00022: val_loss improved from 75079268.30769 to 73697686.46154, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 23/40\n",
      "208/208 [==============================] - 0s 557us/step - loss: 68404507.6923 - val_loss: 72223511.0769\n",
      "\n",
      "Epoch 00023: val_loss improved from 73697686.46154 to 72223511.07692, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 24/40\n",
      "208/208 [==============================] - 0s 557us/step - loss: 66934675.6923 - val_loss: 70673495.0769\n",
      "\n",
      "Epoch 00024: val_loss improved from 72223511.07692 to 70673495.07692, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 25/40\n",
      "208/208 [==============================] - 0s 585us/step - loss: 65406348.9231 - val_loss: 69029185.5385\n",
      "\n",
      "Epoch 00025: val_loss improved from 70673495.07692 to 69029185.53846, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 26/40\n",
      "208/208 [==============================] - 0s 565us/step - loss: 63783174.4615 - val_loss: 67300751.6923\n",
      "\n",
      "Epoch 00026: val_loss improved from 69029185.53846 to 67300751.69231, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 27/40\n",
      "208/208 [==============================] - 0s 572us/step - loss: 62085783.3846 - val_loss: 65491848.0000\n",
      "\n",
      "Epoch 00027: val_loss improved from 67300751.69231 to 65491848.00000, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 28/40\n",
      "208/208 [==============================] - 0s 553us/step - loss: 60307804.3077 - val_loss: 63608404.9231\n",
      "\n",
      "Epoch 00028: val_loss improved from 65491848.00000 to 63608404.92308, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 29/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 58463782.7692 - val_loss: 61644607.3846\n",
      "\n",
      "Epoch 00029: val_loss improved from 63608404.92308 to 61644607.38462, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 30/40\n",
      "208/208 [==============================] - 0s 555us/step - loss: 56553694.4615 - val_loss: 59614693.2308\n",
      "\n",
      "Epoch 00030: val_loss improved from 61644607.38462 to 59614693.23077, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 31/40\n",
      "208/208 [==============================] - 0s 549us/step - loss: 54580865.5385 - val_loss: 57525546.1538\n",
      "\n",
      "Epoch 00031: val_loss improved from 59614693.23077 to 57525546.15385, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 32/40\n",
      "208/208 [==============================] - 0s 558us/step - loss: 52543750.7692 - val_loss: 55388312.6154\n",
      "\n",
      "Epoch 00032: val_loss improved from 57525546.15385 to 55388312.61538, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 33/40\n",
      "208/208 [==============================] - 0s 557us/step - loss: 50476105.5385 - val_loss: 53190867.3846\n",
      "\n",
      "Epoch 00033: val_loss improved from 55388312.61538 to 53190867.38462, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 34/40\n",
      "208/208 [==============================] - 0s 537us/step - loss: 48327985.2308 - val_loss: 50957081.2308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00034: val_loss improved from 53190867.38462 to 50957081.23077, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 35/40\n",
      "208/208 [==============================] - 0s 568us/step - loss: 46185615.3846 - val_loss: 48664241.2308\n",
      "\n",
      "Epoch 00035: val_loss improved from 50957081.23077 to 48664241.23077, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 36/40\n",
      "208/208 [==============================] - 0s 549us/step - loss: 43981991.6923 - val_loss: 46348721.5385\n",
      "\n",
      "Epoch 00036: val_loss improved from 48664241.23077 to 46348721.53846, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 37/40\n",
      "208/208 [==============================] - 0s 557us/step - loss: 41732777.2308 - val_loss: 44031084.6154\n",
      "\n",
      "Epoch 00037: val_loss improved from 46348721.53846 to 44031084.61538, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 38/40\n",
      "208/208 [==============================] - 0s 566us/step - loss: 39520967.6923 - val_loss: 41680265.8462\n",
      "\n",
      "Epoch 00038: val_loss improved from 44031084.61538 to 41680265.84615, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 39/40\n",
      "208/208 [==============================] - 0s 557us/step - loss: 37294006.3077 - val_loss: 39319055.0769\n",
      "\n",
      "Epoch 00039: val_loss improved from 41680265.84615 to 39319055.07692, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "Epoch 40/40\n",
      "208/208 [==============================] - 0s 555us/step - loss: 35031710.1538 - val_loss: 36989994.0000\n",
      "\n",
      "Epoch 00040: val_loss improved from 39319055.07692 to 36989994.00000, saving model to arrFans_health2_best_model_fold1_18_20_55.h5\n",
      "104/104 [==============================] - 0s 1ms/step\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 84057422.1538 - val_loss: 80809435.6923\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 80809435.69231, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 0s 587us/step - loss: 84025120.0000 - val_loss: 80744683.6923\n",
      "\n",
      "Epoch 00002: val_loss improved from 80809435.69231 to 80744683.69231, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 0s 601us/step - loss: 83937595.0769 - val_loss: 80618349.5385\n",
      "\n",
      "Epoch 00003: val_loss improved from 80744683.69231 to 80618349.53846, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 0s 580us/step - loss: 83783651.0769 - val_loss: 80435481.2308\n",
      "\n",
      "Epoch 00004: val_loss improved from 80618349.53846 to 80435481.23077, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 0s 578us/step - loss: 83571566.7692 - val_loss: 80204012.3077\n",
      "\n",
      "Epoch 00005: val_loss improved from 80435481.23077 to 80204012.30769, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 0s 570us/step - loss: 83304353.8462 - val_loss: 79912092.9231\n",
      "\n",
      "Epoch 00006: val_loss improved from 80204012.30769 to 79912092.92308, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 0s 594us/step - loss: 82996800.0000 - val_loss: 79567615.3846\n",
      "\n",
      "Epoch 00007: val_loss improved from 79912092.92308 to 79567615.38462, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 0s 580us/step - loss: 82617896.6154 - val_loss: 79151761.8462\n",
      "\n",
      "Epoch 00008: val_loss improved from 79567615.38462 to 79151761.84615, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 0s 577us/step - loss: 82114480.0000 - val_loss: 78643452.3077\n",
      "\n",
      "Epoch 00009: val_loss improved from 79151761.84615 to 78643452.30769, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 0s 584us/step - loss: 81537037.5385 - val_loss: 78049645.5385\n",
      "\n",
      "Epoch 00010: val_loss improved from 78643452.30769 to 78049645.53846, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 11/40\n",
      "208/208 [==============================] - 0s 572us/step - loss: 80877590.1538 - val_loss: 77366736.0000\n",
      "\n",
      "Epoch 00011: val_loss improved from 78049645.53846 to 77366736.00000, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 12/40\n",
      "208/208 [==============================] - 0s 585us/step - loss: 80125980.3077 - val_loss: 76615500.3077\n",
      "\n",
      "Epoch 00012: val_loss improved from 77366736.00000 to 76615500.30769, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 13/40\n",
      "208/208 [==============================] - 0s 619us/step - loss: 79312522.4615 - val_loss: 75758585.8462\n",
      "\n",
      "Epoch 00013: val_loss improved from 76615500.30769 to 75758585.84615, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 14/40\n",
      "208/208 [==============================] - 0s 550us/step - loss: 78412325.5385 - val_loss: 74847960.6154\n",
      "\n",
      "Epoch 00014: val_loss improved from 75758585.84615 to 74847960.61538, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 15/40\n",
      "208/208 [==============================] - 0s 560us/step - loss: 77405081.8462 - val_loss: 73792780.3077\n",
      "\n",
      "Epoch 00015: val_loss improved from 74847960.61538 to 73792780.30769, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 16/40\n",
      "208/208 [==============================] - 0s 555us/step - loss: 76285314.4615 - val_loss: 72687430.1538\n",
      "\n",
      "Epoch 00016: val_loss improved from 73792780.30769 to 72687430.15385, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 17/40\n",
      "208/208 [==============================] - 0s 603us/step - loss: 75145204.3077 - val_loss: 71500312.0000\n",
      "\n",
      "Epoch 00017: val_loss improved from 72687430.15385 to 71500312.00000, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 18/40\n",
      "208/208 [==============================] - 0s 552us/step - loss: 73855485.5385 - val_loss: 69967731.0769\n",
      "\n",
      "Epoch 00018: val_loss improved from 71500312.00000 to 69967731.07692, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 19/40\n",
      "208/208 [==============================] - 0s 547us/step - loss: 72357121.8462 - val_loss: 68574728.0000\n",
      "\n",
      "Epoch 00019: val_loss improved from 69967731.07692 to 68574728.00000, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 20/40\n",
      "208/208 [==============================] - 0s 568us/step - loss: 70926746.4615 - val_loss: 67145355.6923\n",
      "\n",
      "Epoch 00020: val_loss improved from 68574728.00000 to 67145355.69231, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 21/40\n",
      "208/208 [==============================] - 0s 559us/step - loss: 69435955.0769 - val_loss: 65654225.8462\n",
      "\n",
      "Epoch 00021: val_loss improved from 67145355.69231 to 65654225.84615, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 22/40\n",
      "208/208 [==============================] - 0s 558us/step - loss: 67880787.0769 - val_loss: 64098976.6154\n",
      "\n",
      "Epoch 00022: val_loss improved from 65654225.84615 to 64098976.61538, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 23/40\n",
      "208/208 [==============================] - 0s 565us/step - loss: 66265892.9231 - val_loss: 62478428.3077\n",
      "\n",
      "Epoch 00023: val_loss improved from 64098976.61538 to 62478428.30769, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 24/40\n",
      "208/208 [==============================] - 0s 549us/step - loss: 64573245.8462 - val_loss: 60797657.8462\n",
      "\n",
      "Epoch 00024: val_loss improved from 62478428.30769 to 60797657.84615, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 25/40\n",
      "208/208 [==============================] - 0s 572us/step - loss: 62827653.8462 - val_loss: 59044272.6154\n",
      "\n",
      "Epoch 00025: val_loss improved from 60797657.84615 to 59044272.61538, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 26/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 60986321.5385 - val_loss: 57190788.3077\n",
      "\n",
      "Epoch 00026: val_loss improved from 59044272.61538 to 57190788.30769, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 27/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 0s 560us/step - loss: 59049802.1538 - val_loss: 55280272.6154\n",
      "\n",
      "Epoch 00027: val_loss improved from 57190788.30769 to 55280272.61538, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 28/40\n",
      "208/208 [==============================] - 0s 535us/step - loss: 57073224.6154 - val_loss: 53345236.6154\n",
      "\n",
      "Epoch 00028: val_loss improved from 55280272.61538 to 53345236.61538, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 29/40\n",
      "208/208 [==============================] - 0s 570us/step - loss: 55063548.9231 - val_loss: 51356453.5385\n",
      "\n",
      "Epoch 00029: val_loss improved from 53345236.61538 to 51356453.53846, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 30/40\n",
      "208/208 [==============================] - 0s 550us/step - loss: 52982358.1538 - val_loss: 49294131.3846\n",
      "\n",
      "Epoch 00030: val_loss improved from 51356453.53846 to 49294131.38462, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 31/40\n",
      "208/208 [==============================] - 0s 563us/step - loss: 50832616.9231 - val_loss: 47180449.8462\n",
      "\n",
      "Epoch 00031: val_loss improved from 49294131.38462 to 47180449.84615, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 32/40\n",
      "208/208 [==============================] - 0s 578us/step - loss: 48640175.6923 - val_loss: 45063281.2308\n",
      "\n",
      "Epoch 00032: val_loss improved from 47180449.84615 to 45063281.23077, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 33/40\n",
      "208/208 [==============================] - 0s 538us/step - loss: 46448178.7692 - val_loss: 42929291.3846\n",
      "\n",
      "Epoch 00033: val_loss improved from 45063281.23077 to 42929291.38462, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 34/40\n",
      "208/208 [==============================] - 0s 536us/step - loss: 44243339.3846 - val_loss: 40773227.3846\n",
      "\n",
      "Epoch 00034: val_loss improved from 42929291.38462 to 40773227.38462, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 35/40\n",
      "208/208 [==============================] - 0s 567us/step - loss: 42009708.3077 - val_loss: 38618925.8462\n",
      "\n",
      "Epoch 00035: val_loss improved from 40773227.38462 to 38618925.84615, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 36/40\n",
      "208/208 [==============================] - 0s 559us/step - loss: 39801684.9231 - val_loss: 36456152.3077\n",
      "\n",
      "Epoch 00036: val_loss improved from 38618925.84615 to 36456152.30769, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 37/40\n",
      "208/208 [==============================] - 0s 564us/step - loss: 37558938.7692 - val_loss: 34318745.2308\n",
      "\n",
      "Epoch 00037: val_loss improved from 36456152.30769 to 34318745.23077, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 38/40\n",
      "208/208 [==============================] - 0s 568us/step - loss: 35349907.6923 - val_loss: 32201536.6154\n",
      "\n",
      "Epoch 00038: val_loss improved from 34318745.23077 to 32201536.61538, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 39/40\n",
      "208/208 [==============================] - 0s 544us/step - loss: 33157200.9231 - val_loss: 30111673.2308\n",
      "\n",
      "Epoch 00039: val_loss improved from 32201536.61538 to 30111673.23077, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "Epoch 40/40\n",
      "208/208 [==============================] - 0s 538us/step - loss: 31004419.0769 - val_loss: 28051005.2308\n",
      "\n",
      "Epoch 00040: val_loss improved from 30111673.23077 to 28051005.23077, saving model to arrFans_health2_best_model_fold2_18_21_22.h5\n",
      "104/104 [==============================] - 0s 1ms/step\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 83626412.9231 - val_loss: 81673200.6154\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 81673200.61538, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 0s 620us/step - loss: 83589894.1538 - val_loss: 81605690.4615\n",
      "\n",
      "Epoch 00002: val_loss improved from 81673200.61538 to 81605690.46154, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 0s 578us/step - loss: 83470099.0769 - val_loss: 81445160.6154\n",
      "\n",
      "Epoch 00003: val_loss improved from 81605690.46154 to 81445160.61538, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 0s 583us/step - loss: 83234542.7692 - val_loss: 81193790.7692\n",
      "\n",
      "Epoch 00004: val_loss improved from 81445160.61538 to 81193790.76923, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 0s 563us/step - loss: 82901005.5385 - val_loss: 80860687.3846\n",
      "\n",
      "Epoch 00005: val_loss improved from 81193790.76923 to 80860687.38462, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 0s 593us/step - loss: 82478999.3846 - val_loss: 80453504.6154\n",
      "\n",
      "Epoch 00006: val_loss improved from 80860687.38462 to 80453504.61538, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 0s 566us/step - loss: 82017166.1538 - val_loss: 80010390.1538\n",
      "\n",
      "Epoch 00007: val_loss improved from 80453504.61538 to 80010390.15385, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 0s 567us/step - loss: 81523481.8462 - val_loss: 79527182.7692\n",
      "\n",
      "Epoch 00008: val_loss improved from 80010390.15385 to 79527182.76923, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 0s 612us/step - loss: 80962158.1538 - val_loss: 78970345.8462\n",
      "\n",
      "Epoch 00009: val_loss improved from 79527182.76923 to 78970345.84615, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 0s 560us/step - loss: 80356969.2308 - val_loss: 78219160.3077\n",
      "\n",
      "Epoch 00010: val_loss improved from 78970345.84615 to 78219160.30769, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 11/40\n",
      "208/208 [==============================] - 0s 584us/step - loss: 79642844.3077 - val_loss: 77385923.3846\n",
      "\n",
      "Epoch 00011: val_loss improved from 78219160.30769 to 77385923.38462, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 12/40\n",
      "208/208 [==============================] - 0s 564us/step - loss: 78752892.3077 - val_loss: 76436129.5385\n",
      "\n",
      "Epoch 00012: val_loss improved from 77385923.38462 to 76436129.53846, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 13/40\n",
      "208/208 [==============================] - 0s 583us/step - loss: 77718372.9231 - val_loss: 75376874.7692\n",
      "\n",
      "Epoch 00013: val_loss improved from 76436129.53846 to 75376874.76923, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 14/40\n",
      "208/208 [==============================] - 0s 562us/step - loss: 76587601.2308 - val_loss: 74264636.0000\n",
      "\n",
      "Epoch 00014: val_loss improved from 75376874.76923 to 74264636.00000, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 15/40\n",
      "208/208 [==============================] - 0s 559us/step - loss: 75280143.3846 - val_loss: 72686780.3077\n",
      "\n",
      "Epoch 00015: val_loss improved from 74264636.00000 to 72686780.30769, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 16/40\n",
      "208/208 [==============================] - 0s 577us/step - loss: 73754468.9231 - val_loss: 70746057.8462\n",
      "\n",
      "Epoch 00016: val_loss improved from 72686780.30769 to 70746057.84615, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 17/40\n",
      "208/208 [==============================] - 0s 580us/step - loss: 71867118.4615 - val_loss: 68784873.2308\n",
      "\n",
      "Epoch 00017: val_loss improved from 70746057.84615 to 68784873.23077, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 18/40\n",
      "208/208 [==============================] - 0s 564us/step - loss: 69694099.3846 - val_loss: 65831774.1538\n",
      "\n",
      "Epoch 00018: val_loss improved from 68784873.23077 to 65831774.15385, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 19/40\n",
      "208/208 [==============================] - 0s 565us/step - loss: 66752509.8462 - val_loss: 63725954.7692\n",
      "\n",
      "Epoch 00019: val_loss improved from 65831774.15385 to 63725954.76923, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/40\n",
      "208/208 [==============================] - 0s 550us/step - loss: 64589194.7692 - val_loss: 61536909.8462\n",
      "\n",
      "Epoch 00020: val_loss improved from 63725954.76923 to 61536909.84615, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 21/40\n",
      "208/208 [==============================] - 0s 566us/step - loss: 62326042.4615 - val_loss: 59231056.9231\n",
      "\n",
      "Epoch 00021: val_loss improved from 61536909.84615 to 59231056.92308, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 22/40\n",
      "208/208 [==============================] - 0s 557us/step - loss: 59952679.0769 - val_loss: 56823920.0000\n",
      "\n",
      "Epoch 00022: val_loss improved from 59231056.92308 to 56823920.00000, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 23/40\n",
      "208/208 [==============================] - 0s 553us/step - loss: 57485052.3077 - val_loss: 54325556.9231\n",
      "\n",
      "Epoch 00023: val_loss improved from 56823920.00000 to 54325556.92308, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 24/40\n",
      "208/208 [==============================] - 0s 541us/step - loss: 54914529.2308 - val_loss: 51747957.5385\n",
      "\n",
      "Epoch 00024: val_loss improved from 54325556.92308 to 51747957.53846, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 25/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 52282611.3846 - val_loss: 49089130.1538\n",
      "\n",
      "Epoch 00025: val_loss improved from 51747957.53846 to 49089130.15385, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 26/40\n",
      "208/208 [==============================] - 0s 558us/step - loss: 49554160.3077 - val_loss: 46371581.8462\n",
      "\n",
      "Epoch 00026: val_loss improved from 49089130.15385 to 46371581.84615, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 27/40\n",
      "208/208 [==============================] - 0s 572us/step - loss: 46767777.2308 - val_loss: 43592996.0000\n",
      "\n",
      "Epoch 00027: val_loss improved from 46371581.84615 to 43592996.00000, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 28/40\n",
      "208/208 [==============================] - 0s 569us/step - loss: 43934860.0000 - val_loss: 40782730.0000\n",
      "\n",
      "Epoch 00028: val_loss improved from 43592996.00000 to 40782730.00000, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 29/40\n",
      "208/208 [==============================] - 0s 570us/step - loss: 41070429.2308 - val_loss: 37956806.0000\n",
      "\n",
      "Epoch 00029: val_loss improved from 40782730.00000 to 37956806.00000, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 30/40\n",
      "208/208 [==============================] - 0s 556us/step - loss: 38200548.0000 - val_loss: 35131137.2308\n",
      "\n",
      "Epoch 00030: val_loss improved from 37956806.00000 to 35131137.23077, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 31/40\n",
      "208/208 [==============================] - 0s 555us/step - loss: 35338867.3846 - val_loss: 32327095.8462\n",
      "\n",
      "Epoch 00031: val_loss improved from 35131137.23077 to 32327095.84615, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 32/40\n",
      "208/208 [==============================] - 0s 566us/step - loss: 32505038.9231 - val_loss: 29567632.9231\n",
      "\n",
      "Epoch 00032: val_loss improved from 32327095.84615 to 29567632.92308, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 33/40\n",
      "208/208 [==============================] - 0s 586us/step - loss: 29714304.9231 - val_loss: 26867508.1538\n",
      "\n",
      "Epoch 00033: val_loss improved from 29567632.92308 to 26867508.15385, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 34/40\n",
      "208/208 [==============================] - 0s 557us/step - loss: 27000314.7692 - val_loss: 24235657.0769\n",
      "\n",
      "Epoch 00034: val_loss improved from 26867508.15385 to 24235657.07692, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 35/40\n",
      "208/208 [==============================] - 0s 582us/step - loss: 24396793.0769 - val_loss: 21702545.6923\n",
      "\n",
      "Epoch 00035: val_loss improved from 24235657.07692 to 21702545.69231, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 36/40\n",
      "208/208 [==============================] - 0s 575us/step - loss: 21862758.4615 - val_loss: 19311244.0000\n",
      "\n",
      "Epoch 00036: val_loss improved from 21702545.69231 to 19311244.00000, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 37/40\n",
      "208/208 [==============================] - 0s 571us/step - loss: 19476135.3846 - val_loss: 17056407.3077\n",
      "\n",
      "Epoch 00037: val_loss improved from 19311244.00000 to 17056407.30769, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 38/40\n",
      "208/208 [==============================] - 0s 559us/step - loss: 17213967.3846 - val_loss: 14962004.0769\n",
      "\n",
      "Epoch 00038: val_loss improved from 17056407.30769 to 14962004.07692, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 39/40\n",
      "208/208 [==============================] - 0s 563us/step - loss: 15137506.8462 - val_loss: 13002998.3077\n",
      "\n",
      "Epoch 00039: val_loss improved from 14962004.07692 to 13002998.30769, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "Epoch 40/40\n",
      "208/208 [==============================] - 0s 539us/step - loss: 13194804.6923 - val_loss: 11202964.4231\n",
      "\n",
      "Epoch 00040: val_loss improved from 13002998.30769 to 11202964.42308, saving model to arrFans_health2_best_model_fold3_18_21_51.h5\n",
      "104/104 [==============================] - 0s 1ms/step\n",
      "arrFans_health3\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 85596617.2308 - val_loss: 83633320.0000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 83633320.00000, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 0s 611us/step - loss: 85572424.0000 - val_loss: 83586326.7692\n",
      "\n",
      "Epoch 00002: val_loss improved from 83633320.00000 to 83586326.76923, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 0s 555us/step - loss: 85505265.2308 - val_loss: 83502327.3846\n",
      "\n",
      "Epoch 00003: val_loss improved from 83586326.76923 to 83502327.38462, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 0s 551us/step - loss: 85399624.0000 - val_loss: 83389215.3846\n",
      "\n",
      "Epoch 00004: val_loss improved from 83502327.38462 to 83389215.38462, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 0s 609us/step - loss: 85261285.5385 - val_loss: 83253049.2308\n",
      "\n",
      "Epoch 00005: val_loss improved from 83389215.38462 to 83253049.23077, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 0s 555us/step - loss: 85104429.5385 - val_loss: 83103229.5385\n",
      "\n",
      "Epoch 00006: val_loss improved from 83253049.23077 to 83103229.53846, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 0s 586us/step - loss: 84931942.1538 - val_loss: 82938999.3846\n",
      "\n",
      "Epoch 00007: val_loss improved from 83103229.53846 to 82938999.38462, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 0s 590us/step - loss: 84741020.3077 - val_loss: 82759201.2308\n",
      "\n",
      "Epoch 00008: val_loss improved from 82938999.38462 to 82759201.23077, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 0s 579us/step - loss: 84533265.2308 - val_loss: 82554866.4615\n",
      "\n",
      "Epoch 00009: val_loss improved from 82759201.23077 to 82554866.46154, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 0s 562us/step - loss: 84300098.4615 - val_loss: 82322121.8462\n",
      "\n",
      "Epoch 00010: val_loss improved from 82554866.46154 to 82322121.84615, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 11/40\n",
      "208/208 [==============================] - 0s 552us/step - loss: 84032952.6154 - val_loss: 82053175.3846\n",
      "\n",
      "Epoch 00011: val_loss improved from 82322121.84615 to 82053175.38462, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 12/40\n",
      "208/208 [==============================] - 0s 565us/step - loss: 83727616.0000 - val_loss: 81737040.6154\n",
      "\n",
      "Epoch 00012: val_loss improved from 82053175.38462 to 81737040.61538, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/40\n",
      "208/208 [==============================] - 0s 557us/step - loss: 83373092.3077 - val_loss: 81361096.6154\n",
      "\n",
      "Epoch 00013: val_loss improved from 81737040.61538 to 81361096.61538, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 14/40\n",
      "208/208 [==============================] - 0s 571us/step - loss: 82947675.0769 - val_loss: 80883248.0000\n",
      "\n",
      "Epoch 00014: val_loss improved from 81361096.61538 to 80883248.00000, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 15/40\n",
      "208/208 [==============================] - 0s 567us/step - loss: 82429964.3077 - val_loss: 80288816.6154\n",
      "\n",
      "Epoch 00015: val_loss improved from 80883248.00000 to 80288816.61538, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 16/40\n",
      "208/208 [==============================] - 0s 557us/step - loss: 81815322.4615 - val_loss: 79620872.6154\n",
      "\n",
      "Epoch 00016: val_loss improved from 80288816.61538 to 79620872.61538, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 17/40\n",
      "208/208 [==============================] - 0s 552us/step - loss: 81127824.6154 - val_loss: 78934282.4615\n",
      "\n",
      "Epoch 00017: val_loss improved from 79620872.61538 to 78934282.46154, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 18/40\n",
      "208/208 [==============================] - 0s 570us/step - loss: 80440872.0000 - val_loss: 78254050.4615\n",
      "\n",
      "Epoch 00018: val_loss improved from 78934282.46154 to 78254050.46154, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 19/40\n",
      "208/208 [==============================] - 0s 565us/step - loss: 79745536.0000 - val_loss: 77550511.3846\n",
      "\n",
      "Epoch 00019: val_loss improved from 78254050.46154 to 77550511.38462, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 20/40\n",
      "208/208 [==============================] - 0s 553us/step - loss: 79020564.9231 - val_loss: 76824268.9231\n",
      "\n",
      "Epoch 00020: val_loss improved from 77550511.38462 to 76824268.92308, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 21/40\n",
      "208/208 [==============================] - 0s 576us/step - loss: 78266271.3846 - val_loss: 76070640.6154\n",
      "\n",
      "Epoch 00021: val_loss improved from 76824268.92308 to 76070640.61538, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 22/40\n",
      "208/208 [==============================] - 0s 584us/step - loss: 77474355.6923 - val_loss: 75283251.0769\n",
      "\n",
      "Epoch 00022: val_loss improved from 76070640.61538 to 75283251.07692, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 23/40\n",
      "208/208 [==============================] - 0s 627us/step - loss: 76653395.0769 - val_loss: 74457907.6923\n",
      "\n",
      "Epoch 00023: val_loss improved from 75283251.07692 to 74457907.69231, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 24/40\n",
      "208/208 [==============================] - 0s 572us/step - loss: 75782979.6923 - val_loss: 73602991.3846\n",
      "\n",
      "Epoch 00024: val_loss improved from 74457907.69231 to 73602991.38462, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 25/40\n",
      "208/208 [==============================] - 0s 615us/step - loss: 74881640.6154 - val_loss: 72695845.5385\n",
      "\n",
      "Epoch 00025: val_loss improved from 73602991.38462 to 72695845.53846, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 26/40\n",
      "208/208 [==============================] - 0s 603us/step - loss: 73928327.3846 - val_loss: 71759845.5385\n",
      "\n",
      "Epoch 00026: val_loss improved from 72695845.53846 to 71759845.53846, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 27/40\n",
      "208/208 [==============================] - 0s 602us/step - loss: 72947700.3077 - val_loss: 70774544.9231\n",
      "\n",
      "Epoch 00027: val_loss improved from 71759845.53846 to 70774544.92308, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 28/40\n",
      "208/208 [==============================] - 0s 632us/step - loss: 71901539.0769 - val_loss: 69762726.7692\n",
      "\n",
      "Epoch 00028: val_loss improved from 70774544.92308 to 69762726.76923, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 29/40\n",
      "208/208 [==============================] - 0s 635us/step - loss: 70829441.2308 - val_loss: 68707713.8462\n",
      "\n",
      "Epoch 00029: val_loss improved from 69762726.76923 to 68707713.84615, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 30/40\n",
      "208/208 [==============================] - 0s 604us/step - loss: 69717966.7692 - val_loss: 67618278.4615\n",
      "\n",
      "Epoch 00030: val_loss improved from 68707713.84615 to 67618278.46154, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 31/40\n",
      "208/208 [==============================] - 0s 619us/step - loss: 68561803.3846 - val_loss: 66486835.0769\n",
      "\n",
      "Epoch 00031: val_loss improved from 67618278.46154 to 66486835.07692, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 32/40\n",
      "208/208 [==============================] - 0s 604us/step - loss: 67362886.1538 - val_loss: 65313772.0000\n",
      "\n",
      "Epoch 00032: val_loss improved from 66486835.07692 to 65313772.00000, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 33/40\n",
      "208/208 [==============================] - 0s 584us/step - loss: 66130896.6154 - val_loss: 64078492.3077\n",
      "\n",
      "Epoch 00033: val_loss improved from 65313772.00000 to 64078492.30769, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 34/40\n",
      "208/208 [==============================] - 0s 603us/step - loss: 64871980.6154 - val_loss: 62798889.5385\n",
      "\n",
      "Epoch 00034: val_loss improved from 64078492.30769 to 62798889.53846, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 35/40\n",
      "208/208 [==============================] - 0s 602us/step - loss: 63551139.3846 - val_loss: 61508021.8462\n",
      "\n",
      "Epoch 00035: val_loss improved from 62798889.53846 to 61508021.84615, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 36/40\n",
      "208/208 [==============================] - 0s 608us/step - loss: 62199490.4615 - val_loss: 60186129.5385\n",
      "\n",
      "Epoch 00036: val_loss improved from 61508021.84615 to 60186129.53846, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 37/40\n",
      "208/208 [==============================] - 0s 588us/step - loss: 60825441.8462 - val_loss: 58854654.1538\n",
      "\n",
      "Epoch 00037: val_loss improved from 60186129.53846 to 58854654.15385, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 38/40\n",
      "208/208 [==============================] - 0s 596us/step - loss: 59394802.4615 - val_loss: 57469712.3077\n",
      "\n",
      "Epoch 00038: val_loss improved from 58854654.15385 to 57469712.30769, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 39/40\n",
      "208/208 [==============================] - 0s 584us/step - loss: 57963065.2308 - val_loss: 56055067.6923\n",
      "\n",
      "Epoch 00039: val_loss improved from 57469712.30769 to 56055067.69231, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "Epoch 40/40\n",
      "208/208 [==============================] - 0s 597us/step - loss: 56484080.9231 - val_loss: 54618265.8462\n",
      "\n",
      "Epoch 00040: val_loss improved from 56055067.69231 to 54618265.84615, saving model to arrFans_health3_best_model_fold1_18_22_45.h5\n",
      "104/104 [==============================] - 0s 1ms/step\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 85832613.5385 - val_loss: 83166421.5385\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 83166421.53846, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 0s 624us/step - loss: 85813606.1538 - val_loss: 83130503.3846\n",
      "\n",
      "Epoch 00002: val_loss improved from 83166421.53846 to 83130503.38462, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 85748720.6154 - val_loss: 83037230.7692\n",
      "\n",
      "Epoch 00003: val_loss improved from 83130503.38462 to 83037230.76923, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 0s 580us/step - loss: 85610886.1538 - val_loss: 82861349.5385\n",
      "\n",
      "Epoch 00004: val_loss improved from 83037230.76923 to 82861349.53846, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 0s 574us/step - loss: 85376528.6154 - val_loss: 82569239.3846\n",
      "\n",
      "Epoch 00005: val_loss improved from 82861349.53846 to 82569239.38462, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/40\n",
      "208/208 [==============================] - 0s 586us/step - loss: 85002731.0769 - val_loss: 82037986.4615\n",
      "\n",
      "Epoch 00006: val_loss improved from 82569239.38462 to 82037986.46154, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 0s 570us/step - loss: 84399792.6154 - val_loss: 81255847.3846\n",
      "\n",
      "Epoch 00007: val_loss improved from 82037986.46154 to 81255847.38462, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 0s 579us/step - loss: 83629728.6154 - val_loss: 80413300.9231\n",
      "\n",
      "Epoch 00008: val_loss improved from 81255847.38462 to 80413300.92308, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 0s 572us/step - loss: 82686128.0000 - val_loss: 79483338.4615\n",
      "\n",
      "Epoch 00009: val_loss improved from 80413300.92308 to 79483338.46154, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 0s 564us/step - loss: 81717289.8462 - val_loss: 78488507.6923\n",
      "\n",
      "Epoch 00010: val_loss improved from 79483338.46154 to 78488507.69231, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 11/40\n",
      "208/208 [==============================] - 0s 551us/step - loss: 80668111.3846 - val_loss: 77399692.9231\n",
      "\n",
      "Epoch 00011: val_loss improved from 78488507.69231 to 77399692.92308, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 12/40\n",
      "208/208 [==============================] - 0s 560us/step - loss: 79525475.6923 - val_loss: 76221220.9231\n",
      "\n",
      "Epoch 00012: val_loss improved from 77399692.92308 to 76221220.92308, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 13/40\n",
      "208/208 [==============================] - 0s 555us/step - loss: 78294907.6923 - val_loss: 74946967.3846\n",
      "\n",
      "Epoch 00013: val_loss improved from 76221220.92308 to 74946967.38462, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 14/40\n",
      "208/208 [==============================] - 0s 583us/step - loss: 76963990.7692 - val_loss: 73575797.5385\n",
      "\n",
      "Epoch 00014: val_loss improved from 74946967.38462 to 73575797.53846, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 15/40\n",
      "208/208 [==============================] - 0s 558us/step - loss: 75527164.3077 - val_loss: 72103214.1538\n",
      "\n",
      "Epoch 00015: val_loss improved from 73575797.53846 to 72103214.15385, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 16/40\n",
      "208/208 [==============================] - 0s 573us/step - loss: 73995593.8462 - val_loss: 70541903.3846\n",
      "\n",
      "Epoch 00016: val_loss improved from 72103214.15385 to 70541903.38462, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 17/40\n",
      "208/208 [==============================] - 0s 555us/step - loss: 72393398.1538 - val_loss: 68929244.9231\n",
      "\n",
      "Epoch 00017: val_loss improved from 70541903.38462 to 68929244.92308, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 18/40\n",
      "208/208 [==============================] - 0s 551us/step - loss: 70721144.0000 - val_loss: 67225840.6154\n",
      "\n",
      "Epoch 00018: val_loss improved from 68929244.92308 to 67225840.61538, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 19/40\n",
      "208/208 [==============================] - 0s 557us/step - loss: 68967380.9231 - val_loss: 65433679.3846\n",
      "\n",
      "Epoch 00019: val_loss improved from 67225840.61538 to 65433679.38462, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 20/40\n",
      "208/208 [==============================] - 0s 556us/step - loss: 67106073.8462 - val_loss: 63572035.0769\n",
      "\n",
      "Epoch 00020: val_loss improved from 65433679.38462 to 63572035.07692, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 21/40\n",
      "208/208 [==============================] - 0s 558us/step - loss: 65190920.6154 - val_loss: 61626881.8462\n",
      "\n",
      "Epoch 00021: val_loss improved from 63572035.07692 to 61626881.84615, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 22/40\n",
      "208/208 [==============================] - 0s 535us/step - loss: 63191065.8462 - val_loss: 59610219.6923\n",
      "\n",
      "Epoch 00022: val_loss improved from 61626881.84615 to 59610219.69231, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 23/40\n",
      "208/208 [==============================] - 0s 572us/step - loss: 61120218.7692 - val_loss: 57527553.5385\n",
      "\n",
      "Epoch 00023: val_loss improved from 59610219.69231 to 57527553.53846, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 24/40\n",
      "208/208 [==============================] - 0s 543us/step - loss: 58974764.9231 - val_loss: 55388249.8462\n",
      "\n",
      "Epoch 00024: val_loss improved from 57527553.53846 to 55388249.84615, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 25/40\n",
      "208/208 [==============================] - 0s 560us/step - loss: 56769863.3846 - val_loss: 53192675.0769\n",
      "\n",
      "Epoch 00025: val_loss improved from 55388249.84615 to 53192675.07692, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 26/40\n",
      "208/208 [==============================] - 0s 567us/step - loss: 54530117.5385 - val_loss: 50936215.0769\n",
      "\n",
      "Epoch 00026: val_loss improved from 53192675.07692 to 50936215.07692, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 27/40\n",
      "208/208 [==============================] - 0s 562us/step - loss: 52214186.4615 - val_loss: 48640933.5385\n",
      "\n",
      "Epoch 00027: val_loss improved from 50936215.07692 to 48640933.53846, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 28/40\n",
      "208/208 [==============================] - 0s 569us/step - loss: 49858420.6154 - val_loss: 46305037.5385\n",
      "\n",
      "Epoch 00028: val_loss improved from 48640933.53846 to 46305037.53846, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 29/40\n",
      "208/208 [==============================] - 0s 534us/step - loss: 47480994.7692 - val_loss: 43930857.2308\n",
      "\n",
      "Epoch 00029: val_loss improved from 46305037.53846 to 43930857.23077, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 30/40\n",
      "208/208 [==============================] - 0s 568us/step - loss: 45055705.5385 - val_loss: 41544079.6923\n",
      "\n",
      "Epoch 00030: val_loss improved from 43930857.23077 to 41544079.69231, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 31/40\n",
      "208/208 [==============================] - 0s 539us/step - loss: 42639683.3846 - val_loss: 39141351.0769\n",
      "\n",
      "Epoch 00031: val_loss improved from 41544079.69231 to 39141351.07692, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 32/40\n",
      "208/208 [==============================] - 0s 551us/step - loss: 40195647.6923 - val_loss: 36753504.6154\n",
      "\n",
      "Epoch 00032: val_loss improved from 39141351.07692 to 36753504.61538, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 33/40\n",
      "208/208 [==============================] - 0s 550us/step - loss: 37790153.8462 - val_loss: 34366608.6154\n",
      "\n",
      "Epoch 00033: val_loss improved from 36753504.61538 to 34366608.61538, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 34/40\n",
      "208/208 [==============================] - 0s 545us/step - loss: 35353501.5385 - val_loss: 32019153.8462\n",
      "\n",
      "Epoch 00034: val_loss improved from 34366608.61538 to 32019153.84615, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 35/40\n",
      "208/208 [==============================] - 0s 570us/step - loss: 32983986.1538 - val_loss: 29689123.3846\n",
      "\n",
      "Epoch 00035: val_loss improved from 32019153.84615 to 29689123.38462, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 36/40\n",
      "208/208 [==============================] - 0s 609us/step - loss: 30657128.1538 - val_loss: 27402426.3077\n",
      "\n",
      "Epoch 00036: val_loss improved from 29689123.38462 to 27402426.30769, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 37/40\n",
      "208/208 [==============================] - 0s 551us/step - loss: 28346666.6154 - val_loss: 25198596.9231\n",
      "\n",
      "Epoch 00037: val_loss improved from 27402426.30769 to 25198596.92308, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 38/40\n",
      "208/208 [==============================] - 0s 550us/step - loss: 26147348.3077 - val_loss: 23052345.3846\n",
      "\n",
      "Epoch 00038: val_loss improved from 25198596.92308 to 23052345.38462, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/40\n",
      "208/208 [==============================] - 0s 548us/step - loss: 23982864.4615 - val_loss: 21004889.8462\n",
      "\n",
      "Epoch 00039: val_loss improved from 23052345.38462 to 21004889.84615, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "Epoch 40/40\n",
      "208/208 [==============================] - 0s 543us/step - loss: 21927004.0000 - val_loss: 19041209.2308\n",
      "\n",
      "Epoch 00040: val_loss improved from 21004889.84615 to 19041209.23077, saving model to arrFans_health3_best_model_fold2_18_23_34.h5\n",
      "104/104 [==============================] - 0s 1ms/step\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 83406982.7692 - val_loss: 88009845.5385\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 88009845.53846, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 0s 560us/step - loss: 83382498.4615 - val_loss: 87966393.2308\n",
      "\n",
      "Epoch 00002: val_loss improved from 88009845.53846 to 87966393.23077, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 0s 584us/step - loss: 83325564.9231 - val_loss: 87882420.3077\n",
      "\n",
      "Epoch 00003: val_loss improved from 87966393.23077 to 87882420.30769, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 0s 564us/step - loss: 83227846.1538 - val_loss: 87763542.7692\n",
      "\n",
      "Epoch 00004: val_loss improved from 87882420.30769 to 87763542.76923, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 0s 585us/step - loss: 83092043.6923 - val_loss: 87618154.4615\n",
      "\n",
      "Epoch 00005: val_loss improved from 87763542.76923 to 87618154.46154, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 0s 580us/step - loss: 82910946.4615 - val_loss: 87447837.5385\n",
      "\n",
      "Epoch 00006: val_loss improved from 87618154.46154 to 87447837.53846, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 0s 604us/step - loss: 82705891.6923 - val_loss: 87215907.0769\n",
      "\n",
      "Epoch 00007: val_loss improved from 87447837.53846 to 87215907.07692, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 0s 563us/step - loss: 82445495.3846 - val_loss: 86950819.0769\n",
      "\n",
      "Epoch 00008: val_loss improved from 87215907.07692 to 86950819.07692, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 0s 557us/step - loss: 82149617.2308 - val_loss: 86657382.1538\n",
      "\n",
      "Epoch 00009: val_loss improved from 86950819.07692 to 86657382.15385, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 0s 579us/step - loss: 81772045.5385 - val_loss: 86278932.9231\n",
      "\n",
      "Epoch 00010: val_loss improved from 86657382.15385 to 86278932.92308, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 11/40\n",
      "208/208 [==============================] - 0s 577us/step - loss: 81318662.7692 - val_loss: 85810146.4615\n",
      "\n",
      "Epoch 00011: val_loss improved from 86278932.92308 to 85810146.46154, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 12/40\n",
      "208/208 [==============================] - 0s 582us/step - loss: 80848924.3077 - val_loss: 85267990.1538\n",
      "\n",
      "Epoch 00012: val_loss improved from 85810146.46154 to 85267990.15385, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 13/40\n",
      "208/208 [==============================] - 0s 574us/step - loss: 80370436.9231 - val_loss: 84746097.2308\n",
      "\n",
      "Epoch 00013: val_loss improved from 85267990.15385 to 84746097.23077, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 14/40\n",
      "208/208 [==============================] - 0s 572us/step - loss: 79833472.0000 - val_loss: 84202936.0000\n",
      "\n",
      "Epoch 00014: val_loss improved from 84746097.23077 to 84202936.00000, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 15/40\n",
      "208/208 [==============================] - 0s 560us/step - loss: 79209507.0769 - val_loss: 83568646.1538\n",
      "\n",
      "Epoch 00015: val_loss improved from 84202936.00000 to 83568646.15385, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 16/40\n",
      "208/208 [==============================] - 0s 537us/step - loss: 78517585.8462 - val_loss: 82802214.7692\n",
      "\n",
      "Epoch 00016: val_loss improved from 83568646.15385 to 82802214.76923, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 17/40\n",
      "208/208 [==============================] - 0s 558us/step - loss: 77647926.1538 - val_loss: 81902832.0000\n",
      "\n",
      "Epoch 00017: val_loss improved from 82802214.76923 to 81902832.00000, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 18/40\n",
      "208/208 [==============================] - 0s 586us/step - loss: 76734238.1538 - val_loss: 80829431.3846\n",
      "\n",
      "Epoch 00018: val_loss improved from 81902832.00000 to 80829431.38462, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 19/40\n",
      "208/208 [==============================] - 0s 546us/step - loss: 75660879.3846 - val_loss: 79553676.3077\n",
      "\n",
      "Epoch 00019: val_loss improved from 80829431.38462 to 79553676.30769, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 20/40\n",
      "208/208 [==============================] - 0s 554us/step - loss: 74488867.6923 - val_loss: 78312249.5385\n",
      "\n",
      "Epoch 00020: val_loss improved from 79553676.30769 to 78312249.53846, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 21/40\n",
      "208/208 [==============================] - 0s 554us/step - loss: 73215387.6923 - val_loss: 76887452.9231\n",
      "\n",
      "Epoch 00021: val_loss improved from 78312249.53846 to 76887452.92308, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 22/40\n",
      "208/208 [==============================] - 0s 569us/step - loss: 71947639.3846 - val_loss: 75544458.4615\n",
      "\n",
      "Epoch 00022: val_loss improved from 76887452.92308 to 75544458.46154, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 23/40\n",
      "208/208 [==============================] - 0s 557us/step - loss: 70675482.7692 - val_loss: 74195922.4615\n",
      "\n",
      "Epoch 00023: val_loss improved from 75544458.46154 to 74195922.46154, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 24/40\n",
      "208/208 [==============================] - 0s 553us/step - loss: 69354796.9231 - val_loss: 72787496.9231\n",
      "\n",
      "Epoch 00024: val_loss improved from 74195922.46154 to 72787496.92308, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 25/40\n",
      "208/208 [==============================] - 0s 555us/step - loss: 67960989.5385 - val_loss: 71317688.3077\n",
      "\n",
      "Epoch 00025: val_loss improved from 72787496.92308 to 71317688.30769, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 26/40\n",
      "208/208 [==============================] - 0s 564us/step - loss: 66510033.2308 - val_loss: 69786262.7692\n",
      "\n",
      "Epoch 00026: val_loss improved from 71317688.30769 to 69786262.76923, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 27/40\n",
      "208/208 [==============================] - 0s 552us/step - loss: 64987643.0769 - val_loss: 68197922.7692\n",
      "\n",
      "Epoch 00027: val_loss improved from 69786262.76923 to 68197922.76923, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 28/40\n",
      "208/208 [==============================] - 0s 582us/step - loss: 63424057.5385 - val_loss: 66544883.3846\n",
      "\n",
      "Epoch 00028: val_loss improved from 68197922.76923 to 66544883.38462, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 29/40\n",
      "208/208 [==============================] - 0s 558us/step - loss: 61807523.6923 - val_loss: 64834658.1538\n",
      "\n",
      "Epoch 00029: val_loss improved from 66544883.38462 to 64834658.15385, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 30/40\n",
      "208/208 [==============================] - 0s 554us/step - loss: 60130409.5385 - val_loss: 63069878.4615\n",
      "\n",
      "Epoch 00030: val_loss improved from 64834658.15385 to 63069878.46154, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 31/40\n",
      "208/208 [==============================] - 0s 574us/step - loss: 58398388.3077 - val_loss: 61259349.5385\n",
      "\n",
      "Epoch 00031: val_loss improved from 63069878.46154 to 61259349.53846, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/40\n",
      "208/208 [==============================] - 0s 556us/step - loss: 56620977.8462 - val_loss: 59404836.0000\n",
      "\n",
      "Epoch 00032: val_loss improved from 61259349.53846 to 59404836.00000, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 33/40\n",
      "208/208 [==============================] - 0s 553us/step - loss: 54808047.6923 - val_loss: 57489641.8462\n",
      "\n",
      "Epoch 00033: val_loss improved from 59404836.00000 to 57489641.84615, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 34/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 52908994.1538 - val_loss: 55512439.3846\n",
      "\n",
      "Epoch 00034: val_loss improved from 57489641.84615 to 55512439.38462, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 35/40\n",
      "208/208 [==============================] - 0s 544us/step - loss: 51000654.7692 - val_loss: 53493613.2308\n",
      "\n",
      "Epoch 00035: val_loss improved from 55512439.38462 to 53493613.23077, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 36/40\n",
      "208/208 [==============================] - 0s 553us/step - loss: 49018369.2308 - val_loss: 51456780.6154\n",
      "\n",
      "Epoch 00036: val_loss improved from 53493613.23077 to 51456780.61538, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 37/40\n",
      "208/208 [==============================] - 0s 548us/step - loss: 47042957.2308 - val_loss: 49371703.6923\n",
      "\n",
      "Epoch 00037: val_loss improved from 51456780.61538 to 49371703.69231, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 38/40\n",
      "208/208 [==============================] - 0s 573us/step - loss: 45009087.0769 - val_loss: 47259586.1538\n",
      "\n",
      "Epoch 00038: val_loss improved from 49371703.69231 to 47259586.15385, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 39/40\n",
      "208/208 [==============================] - 0s 558us/step - loss: 42958626.4615 - val_loss: 45094143.6923\n",
      "\n",
      "Epoch 00039: val_loss improved from 47259586.15385 to 45094143.69231, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "Epoch 40/40\n",
      "208/208 [==============================] - 0s 570us/step - loss: 40886107.0769 - val_loss: 42965034.7692\n",
      "\n",
      "Epoch 00040: val_loss improved from 45094143.69231 to 42965034.76923, saving model to arrFans_health3_best_model_fold3_18_24_04.h5\n",
      "104/104 [==============================] - 0s 1ms/step\n",
      "arrPower_usage0\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 5491.7713 - val_loss: 5987.3560\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5987.35603, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 0s 615us/step - loss: 5394.3651 - val_loss: 5810.6016\n",
      "\n",
      "Epoch 00002: val_loss improved from 5987.35603 to 5810.60164, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 0s 566us/step - loss: 5076.0812 - val_loss: 5357.9814\n",
      "\n",
      "Epoch 00003: val_loss improved from 5810.60164 to 5357.98137, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 0s 580us/step - loss: 4446.0763 - val_loss: 4491.2340\n",
      "\n",
      "Epoch 00004: val_loss improved from 5357.98137 to 4491.23396, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 0s 584us/step - loss: 3616.8986 - val_loss: 3436.7654\n",
      "\n",
      "Epoch 00005: val_loss improved from 4491.23396 to 3436.76540, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 0s 552us/step - loss: 2687.5824 - val_loss: 2272.4316\n",
      "\n",
      "Epoch 00006: val_loss improved from 3436.76540 to 2272.43162, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 0s 554us/step - loss: 1955.2596 - val_loss: 1464.0056\n",
      "\n",
      "Epoch 00007: val_loss improved from 2272.43162 to 1464.00558, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 0s 557us/step - loss: 1157.6987 - val_loss: 1177.3248\n",
      "\n",
      "Epoch 00008: val_loss improved from 1464.00558 to 1177.32485, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 0s 543us/step - loss: 891.1343 - val_loss: 875.4457\n",
      "\n",
      "Epoch 00009: val_loss improved from 1177.32485 to 875.44567, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 0s 589us/step - loss: 651.2209 - val_loss: 746.6331\n",
      "\n",
      "Epoch 00010: val_loss improved from 875.44567 to 746.63313, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 11/40\n",
      "208/208 [==============================] - 0s 567us/step - loss: 607.0372 - val_loss: 601.8294\n",
      "\n",
      "Epoch 00011: val_loss improved from 746.63313 to 601.82937, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 12/40\n",
      "208/208 [==============================] - 0s 588us/step - loss: 571.5436 - val_loss: 554.4482\n",
      "\n",
      "Epoch 00012: val_loss improved from 601.82937 to 554.44818, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 13/40\n",
      "208/208 [==============================] - 0s 538us/step - loss: 516.3580 - val_loss: 481.1233\n",
      "\n",
      "Epoch 00013: val_loss improved from 554.44818 to 481.12333, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 14/40\n",
      "208/208 [==============================] - 0s 563us/step - loss: 439.6693 - val_loss: 402.9541\n",
      "\n",
      "Epoch 00014: val_loss improved from 481.12333 to 402.95411, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 15/40\n",
      "208/208 [==============================] - 0s 565us/step - loss: 367.0968 - val_loss: 330.1393\n",
      "\n",
      "Epoch 00015: val_loss improved from 402.95411 to 330.13934, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 16/40\n",
      "208/208 [==============================] - 0s 545us/step - loss: 295.3848 - val_loss: 263.9487\n",
      "\n",
      "Epoch 00016: val_loss improved from 330.13934 to 263.94872, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 17/40\n",
      "208/208 [==============================] - 0s 544us/step - loss: 237.8570 - val_loss: 233.3678\n",
      "\n",
      "Epoch 00017: val_loss improved from 263.94872 to 233.36782, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 18/40\n",
      "208/208 [==============================] - 0s 560us/step - loss: 214.5038 - val_loss: 210.3585\n",
      "\n",
      "Epoch 00018: val_loss improved from 233.36782 to 210.35845, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 19/40\n",
      "208/208 [==============================] - 0s 565us/step - loss: 195.7345 - val_loss: 192.7958\n",
      "\n",
      "Epoch 00019: val_loss improved from 210.35845 to 192.79582, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 20/40\n",
      "208/208 [==============================] - 0s 581us/step - loss: 183.6062 - val_loss: 179.1013\n",
      "\n",
      "Epoch 00020: val_loss improved from 192.79582 to 179.10127, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 21/40\n",
      "208/208 [==============================] - 0s 562us/step - loss: 171.9316 - val_loss: 168.7702\n",
      "\n",
      "Epoch 00021: val_loss improved from 179.10127 to 168.77023, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 22/40\n",
      "208/208 [==============================] - 0s 540us/step - loss: 165.1685 - val_loss: 158.6117\n",
      "\n",
      "Epoch 00022: val_loss improved from 168.77023 to 158.61167, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 23/40\n",
      "208/208 [==============================] - 0s 551us/step - loss: 157.8963 - val_loss: 151.8598\n",
      "\n",
      "Epoch 00023: val_loss improved from 158.61167 to 151.85985, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 24/40\n",
      "208/208 [==============================] - 0s 577us/step - loss: 152.4230 - val_loss: 146.3401\n",
      "\n",
      "Epoch 00024: val_loss improved from 151.85985 to 146.34009, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 25/40\n",
      "208/208 [==============================] - 0s 562us/step - loss: 149.5586 - val_loss: 143.1697\n",
      "\n",
      "Epoch 00025: val_loss improved from 146.34009 to 143.16973, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 26/40\n",
      "208/208 [==============================] - 0s 563us/step - loss: 144.6925 - val_loss: 139.6132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00026: val_loss improved from 143.16973 to 139.61322, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 27/40\n",
      "208/208 [==============================] - 0s 551us/step - loss: 142.7188 - val_loss: 135.4741\n",
      "\n",
      "Epoch 00027: val_loss improved from 139.61322 to 135.47414, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 28/40\n",
      "208/208 [==============================] - 0s 555us/step - loss: 139.6511 - val_loss: 134.6700\n",
      "\n",
      "Epoch 00028: val_loss improved from 135.47414 to 134.67005, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 29/40\n",
      "208/208 [==============================] - 0s 563us/step - loss: 137.9491 - val_loss: 132.3700\n",
      "\n",
      "Epoch 00029: val_loss improved from 134.67005 to 132.36998, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 30/40\n",
      "208/208 [==============================] - 0s 560us/step - loss: 134.0435 - val_loss: 130.9986\n",
      "\n",
      "Epoch 00030: val_loss improved from 132.36998 to 130.99862, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 31/40\n",
      "208/208 [==============================] - 0s 572us/step - loss: 131.9328 - val_loss: 128.5012\n",
      "\n",
      "Epoch 00031: val_loss improved from 130.99862 to 128.50121, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 32/40\n",
      "208/208 [==============================] - 0s 565us/step - loss: 130.1247 - val_loss: 127.6750\n",
      "\n",
      "Epoch 00032: val_loss improved from 128.50121 to 127.67497, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 33/40\n",
      "208/208 [==============================] - 0s 554us/step - loss: 126.7052 - val_loss: 125.5221\n",
      "\n",
      "Epoch 00033: val_loss improved from 127.67497 to 125.52211, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 34/40\n",
      "208/208 [==============================] - 0s 596us/step - loss: 125.8873 - val_loss: 123.6203\n",
      "\n",
      "Epoch 00034: val_loss improved from 125.52211 to 123.62028, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 35/40\n",
      "208/208 [==============================] - 0s 563us/step - loss: 124.1956 - val_loss: 124.1437\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 123.62028\n",
      "Epoch 36/40\n",
      "208/208 [==============================] - 0s 577us/step - loss: 117.9072 - val_loss: 120.9231\n",
      "\n",
      "Epoch 00036: val_loss improved from 123.62028 to 120.92312, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 37/40\n",
      "208/208 [==============================] - 0s 583us/step - loss: 122.7596 - val_loss: 120.5240\n",
      "\n",
      "Epoch 00037: val_loss improved from 120.92312 to 120.52404, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 38/40\n",
      "208/208 [==============================] - 0s 547us/step - loss: 117.8772 - val_loss: 121.5901\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 120.52404\n",
      "Epoch 39/40\n",
      "208/208 [==============================] - 0s 577us/step - loss: 120.6255 - val_loss: 119.6130\n",
      "\n",
      "Epoch 00039: val_loss improved from 120.52404 to 119.61305, saving model to arrPower_usage0_best_model_fold1_18_24_57.h5\n",
      "Epoch 40/40\n",
      "208/208 [==============================] - 0s 581us/step - loss: 119.8081 - val_loss: 124.0132\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 119.61305\n",
      "104/104 [==============================] - 0s 1ms/step\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 5713.7295 - val_loss: 5244.0151\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5244.01506, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 0s 587us/step - loss: 5364.8781 - val_loss: 4638.0704\n",
      "\n",
      "Epoch 00002: val_loss improved from 5244.01506 to 4638.07035, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 0s 611us/step - loss: 4327.4381 - val_loss: 3206.5455\n",
      "\n",
      "Epoch 00003: val_loss improved from 4638.07035 to 3206.54552, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 0s 620us/step - loss: 2585.5707 - val_loss: 1516.3768\n",
      "\n",
      "Epoch 00004: val_loss improved from 3206.54552 to 1516.37685, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 0s 605us/step - loss: 972.4639 - val_loss: 877.1728\n",
      "\n",
      "Epoch 00005: val_loss improved from 1516.37685 to 877.17280, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 0s 580us/step - loss: 783.2388 - val_loss: 942.9657\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 877.17280\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 0s 577us/step - loss: 777.6064 - val_loss: 756.9938\n",
      "\n",
      "Epoch 00007: val_loss improved from 877.17280 to 756.99383, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 0s 553us/step - loss: 605.0974 - val_loss: 703.1440\n",
      "\n",
      "Epoch 00008: val_loss improved from 756.99383 to 703.14402, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 0s 615us/step - loss: 514.1887 - val_loss: 470.4989\n",
      "\n",
      "Epoch 00009: val_loss improved from 703.14402 to 470.49891, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 0s 568us/step - loss: 316.8183 - val_loss: 352.3679\n",
      "\n",
      "Epoch 00010: val_loss improved from 470.49891 to 352.36792, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 11/40\n",
      "208/208 [==============================] - 0s 588us/step - loss: 218.3974 - val_loss: 278.9948\n",
      "\n",
      "Epoch 00011: val_loss improved from 352.36792 to 278.99477, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 12/40\n",
      "208/208 [==============================] - 0s 585us/step - loss: 167.8839 - val_loss: 242.2717\n",
      "\n",
      "Epoch 00012: val_loss improved from 278.99477 to 242.27169, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 13/40\n",
      "208/208 [==============================] - 0s 569us/step - loss: 158.3983 - val_loss: 237.9820\n",
      "\n",
      "Epoch 00013: val_loss improved from 242.27169 to 237.98201, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 14/40\n",
      "208/208 [==============================] - 0s 575us/step - loss: 145.3745 - val_loss: 208.5198\n",
      "\n",
      "Epoch 00014: val_loss improved from 237.98201 to 208.51981, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 15/40\n",
      "208/208 [==============================] - 0s 565us/step - loss: 135.1463 - val_loss: 192.8143\n",
      "\n",
      "Epoch 00015: val_loss improved from 208.51981 to 192.81432, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 16/40\n",
      "208/208 [==============================] - 0s 572us/step - loss: 120.6537 - val_loss: 182.6948\n",
      "\n",
      "Epoch 00016: val_loss improved from 192.81432 to 182.69483, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 17/40\n",
      "208/208 [==============================] - 0s 556us/step - loss: 112.5241 - val_loss: 177.6016\n",
      "\n",
      "Epoch 00017: val_loss improved from 182.69483 to 177.60156, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 18/40\n",
      "208/208 [==============================] - 0s 575us/step - loss: 106.9354 - val_loss: 176.7950\n",
      "\n",
      "Epoch 00018: val_loss improved from 177.60156 to 176.79503, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 19/40\n",
      "208/208 [==============================] - 0s 547us/step - loss: 103.4069 - val_loss: 174.7449\n",
      "\n",
      "Epoch 00019: val_loss improved from 176.79503 to 174.74486, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 20/40\n",
      "208/208 [==============================] - 0s 571us/step - loss: 98.7164 - val_loss: 173.1985\n",
      "\n",
      "Epoch 00020: val_loss improved from 174.74486 to 173.19846, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 21/40\n",
      "208/208 [==============================] - 0s 539us/step - loss: 96.7530 - val_loss: 171.2709\n",
      "\n",
      "Epoch 00021: val_loss improved from 173.19846 to 171.27089, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 22/40\n",
      "208/208 [==============================] - 0s 548us/step - loss: 93.3952 - val_loss: 169.0093\n",
      "\n",
      "Epoch 00022: val_loss improved from 171.27089 to 169.00926, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 23/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 0s 538us/step - loss: 90.3219 - val_loss: 165.2366\n",
      "\n",
      "Epoch 00023: val_loss improved from 169.00926 to 165.23655, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 24/40\n",
      "208/208 [==============================] - 0s 608us/step - loss: 86.5451 - val_loss: 162.9280\n",
      "\n",
      "Epoch 00024: val_loss improved from 165.23655 to 162.92801, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 25/40\n",
      "208/208 [==============================] - 0s 567us/step - loss: 83.1460 - val_loss: 160.7989\n",
      "\n",
      "Epoch 00025: val_loss improved from 162.92801 to 160.79892, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 26/40\n",
      "208/208 [==============================] - 0s 552us/step - loss: 80.2768 - val_loss: 158.7148\n",
      "\n",
      "Epoch 00026: val_loss improved from 160.79892 to 158.71485, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 27/40\n",
      "208/208 [==============================] - 0s 540us/step - loss: 78.2007 - val_loss: 157.2012\n",
      "\n",
      "Epoch 00027: val_loss improved from 158.71485 to 157.20123, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 28/40\n",
      "208/208 [==============================] - 0s 557us/step - loss: 77.2247 - val_loss: 156.2220\n",
      "\n",
      "Epoch 00028: val_loss improved from 157.20123 to 156.22200, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 29/40\n",
      "208/208 [==============================] - 0s 584us/step - loss: 71.2343 - val_loss: 155.7357\n",
      "\n",
      "Epoch 00029: val_loss improved from 156.22200 to 155.73568, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 30/40\n",
      "208/208 [==============================] - 0s 539us/step - loss: 70.2920 - val_loss: 153.4662\n",
      "\n",
      "Epoch 00030: val_loss improved from 155.73568 to 153.46623, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 31/40\n",
      "208/208 [==============================] - 0s 566us/step - loss: 66.6974 - val_loss: 152.4597\n",
      "\n",
      "Epoch 00031: val_loss improved from 153.46623 to 152.45974, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 32/40\n",
      "208/208 [==============================] - 0s 553us/step - loss: 64.3747 - val_loss: 150.5729\n",
      "\n",
      "Epoch 00032: val_loss improved from 152.45974 to 150.57290, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 33/40\n",
      "208/208 [==============================] - 0s 564us/step - loss: 61.9979 - val_loss: 149.2104\n",
      "\n",
      "Epoch 00033: val_loss improved from 150.57290 to 149.21042, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 34/40\n",
      "208/208 [==============================] - 0s 558us/step - loss: 59.3149 - val_loss: 147.6288\n",
      "\n",
      "Epoch 00034: val_loss improved from 149.21042 to 147.62881, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 35/40\n",
      "208/208 [==============================] - 0s 565us/step - loss: 57.4868 - val_loss: 149.2572\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 147.62881\n",
      "Epoch 36/40\n",
      "208/208 [==============================] - 0s 565us/step - loss: 57.0143 - val_loss: 147.4097\n",
      "\n",
      "Epoch 00036: val_loss improved from 147.62881 to 147.40965, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 37/40\n",
      "208/208 [==============================] - 0s 565us/step - loss: 54.1614 - val_loss: 147.2257\n",
      "\n",
      "Epoch 00037: val_loss improved from 147.40965 to 147.22566, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 38/40\n",
      "208/208 [==============================] - 0s 534us/step - loss: 52.3167 - val_loss: 145.6739\n",
      "\n",
      "Epoch 00038: val_loss improved from 147.22566 to 145.67386, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 39/40\n",
      "208/208 [==============================] - 0s 569us/step - loss: 50.3004 - val_loss: 144.2887\n",
      "\n",
      "Epoch 00039: val_loss improved from 145.67386 to 144.28866, saving model to arrPower_usage0_best_model_fold2_18_25_28.h5\n",
      "Epoch 40/40\n",
      "208/208 [==============================] - 0s 537us/step - loss: 48.9175 - val_loss: 146.2864\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 144.28866\n",
      "104/104 [==============================] - 0s 1ms/step\n",
      "Train on 208 samples, validate on 104 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1s 4ms/step - loss: 5650.1288 - val_loss: 5302.5156\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5302.51559, saving model to arrPower_usage0_best_model_fold3_18_25_59.h5\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 0s 580us/step - loss: 5175.6221 - val_loss: 4446.8468\n",
      "\n",
      "Epoch 00002: val_loss improved from 5302.51559 to 4446.84675, saving model to arrPower_usage0_best_model_fold3_18_25_59.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 0s 562us/step - loss: 3994.3849 - val_loss: 2976.1601\n",
      "\n",
      "Epoch 00003: val_loss improved from 4446.84675 to 2976.16008, saving model to arrPower_usage0_best_model_fold3_18_25_59.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 0s 575us/step - loss: 2501.6586 - val_loss: 1500.8955\n",
      "\n",
      "Epoch 00004: val_loss improved from 2976.16008 to 1500.89546, saving model to arrPower_usage0_best_model_fold3_18_25_59.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 0s 559us/step - loss: 1315.4344 - val_loss: 789.0312\n",
      "\n",
      "Epoch 00005: val_loss improved from 1500.89546 to 789.03120, saving model to arrPower_usage0_best_model_fold3_18_25_59.h5\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 0s 555us/step - loss: 890.4886 - val_loss: 794.2664\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 789.03120\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 0s 590us/step - loss: 881.8810 - val_loss: 801.3145\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 789.03120\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 0s 583us/step - loss: 796.9158 - val_loss: 669.5133\n",
      "\n",
      "Epoch 00008: val_loss improved from 789.03120 to 669.51328, saving model to arrPower_usage0_best_model_fold3_18_25_59.h5\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 0s 576us/step - loss: 680.9239 - val_loss: 565.8164\n",
      "\n",
      "Epoch 00009: val_loss improved from 669.51328 to 565.81644, saving model to arrPower_usage0_best_model_fold3_18_25_59.h5\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 0s 549us/step - loss: 591.2422 - val_loss: 470.5600\n",
      "\n",
      "Epoch 00010: val_loss improved from 565.81644 to 470.55999, saving model to arrPower_usage0_best_model_fold3_18_25_59.h5\n",
      "Epoch 11/40\n",
      "208/208 [==============================] - 0s 615us/step - loss: 488.5987 - val_loss: 378.6082\n",
      "\n",
      "Epoch 00011: val_loss improved from 470.55999 to 378.60821, saving model to arrPower_usage0_best_model_fold3_18_25_59.h5\n",
      "Epoch 12/40\n",
      "208/208 [==============================] - 0s 581us/step - loss: 381.7760 - val_loss: 269.7946\n",
      "\n",
      "Epoch 00012: val_loss improved from 378.60821 to 269.79458, saving model to arrPower_usage0_best_model_fold3_18_25_59.h5\n",
      "Epoch 13/40\n",
      "208/208 [==============================] - 0s 572us/step - loss: 277.7151 - val_loss: 201.0782\n",
      "\n",
      "Epoch 00013: val_loss improved from 269.79458 to 201.07817, saving model to arrPower_usage0_best_model_fold3_18_25_59.h5\n",
      "Epoch 14/40\n",
      "208/208 [==============================] - 0s 558us/step - loss: 218.8770 - val_loss: 179.2365\n",
      "\n",
      "Epoch 00014: val_loss improved from 201.07817 to 179.23649, saving model to arrPower_usage0_best_model_fold3_18_25_59.h5\n",
      "Epoch 15/40\n",
      "208/208 [==============================] - 0s 561us/step - loss: 188.0353 - val_loss: 194.0349\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 179.23649\n",
      "Epoch 16/40\n",
      "208/208 [==============================] - 0s 592us/step - loss: 195.3571 - val_loss: 186.6903\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 179.23649\n",
      "Epoch 17/40\n",
      "208/208 [==============================] - 0s 575us/step - loss: 220.1070 - val_loss: 179.0750\n",
      "\n",
      "Epoch 00017: val_loss improved from 179.23649 to 179.07502, saving model to arrPower_usage0_best_model_fold3_18_25_59.h5\n",
      "Epoch 18/40\n",
      "208/208 [==============================] - 0s 557us/step - loss: 220.5054 - val_loss: 175.5827\n",
      "\n",
      "Epoch 00018: val_loss improved from 179.07502 to 175.58275, saving model to arrPower_usage0_best_model_fold3_18_25_59.h5\n",
      "Epoch 19/40\n",
      "208/208 [==============================] - 0s 586us/step - loss: 209.5721 - val_loss: 166.6967\n",
      "\n",
      "Epoch 00019: val_loss improved from 175.58275 to 166.69669, saving model to arrPower_usage0_best_model_fold3_18_25_59.h5\n",
      "Epoch 20/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 0s 566us/step - loss: 201.7346 - val_loss: 174.4136\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 166.69669\n",
      "Epoch 21/40\n",
      "208/208 [==============================] - 0s 559us/step - loss: 196.5427 - val_loss: 169.3847\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 166.69669\n",
      "Epoch 22/40\n",
      "208/208 [==============================] - 0s 599us/step - loss: 189.4454 - val_loss: 169.0086\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 166.69669\n",
      "Epoch 00022: early stopping\n",
      "104/104 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "# ten fold\n",
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=3, shuffle=True)\n",
    "from keras.models import load_model\n",
    "from datetime import datetime\n",
    "\n",
    "msescores = []\n",
    "\n",
    "allVariables = ['arrTemperature0', 'arrTemperature1', 'arrTemperature2', 'arrCPU_load0', 'arrMemory_usage0', 'arrFans_health0', 'arrFans_health1', 'arrFans_health2', 'arrFans_health3', 'arrPower_usage0']\n",
    "\n",
    "start_time = datetime.now()\n",
    "print(start_time)\n",
    "for feature in allVariables:\n",
    "    print(feature)\n",
    "    X_train, X_test, y_train, Y_test = splitTrainTest(feature)\n",
    "\n",
    "    counter= 0\n",
    "    for trainIdx, testIdx in kfold.split(X_train, y_train):\n",
    "        counter = counter + 1\n",
    "        # create callbacks\n",
    "        model_path = feature+'_best_model_fold'+str(counter)+\"_\"+datetime.now().strftime(\"%H_%M_%S\")+'.h5'\n",
    "        mc = ModelCheckpoint(model_path, monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "        es = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=1)\n",
    "        # create model\n",
    "        model = createModel(64, 64, 8, 8, (X_train.shape[1], X_train.shape[2]))\n",
    "        model.fit(X_train[trainIdx], y_train[trainIdx], validation_data=(X_train[testIdx], y_train[testIdx]), batch_size=32, epochs=40, callbacks=[mc, es])\n",
    "        # Done load the best model of this fold\n",
    "        saved_model = load_model(model_path)\n",
    "        msescores.append({'path': model_path, 'mse': saved_model.evaluate(X_train[testIdx], y_train[testIdx])})\n",
    "        \n",
    "end_time = datetime.now()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time:  2019-10-23 18:09:25.736849\n",
      "end time: 2019-10-23 18:26:28.002689\n"
     ]
    }
   ],
   "source": [
    "print ('start time: ', start_time)\n",
    "print ('end time:', end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and see data distribution\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plotAttrDataOfId(data, compute, features):\n",
    "    plt.figure(figsize=(30, 20))\n",
    "    for i, v in enumerate(features):\n",
    "        plt.subplot(10, 3, i+1)\n",
    "        cDf = df[df['compute']==compute]\n",
    "        plt.plot(cDf['timespan'], cDf[v])\n",
    "        plt.title(v)\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in np.random.randint(0, len(computes), 3):\n",
    "#     plotAttrDataOfId(df, computes[x], features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotDataDistribution(data, features):\n",
    "    plt.figure(figsize=(30, 10))\n",
    "    for i, v in enumerate(features):\n",
    "        plt.subplot(3, 10, i+1)\n",
    "        sns.distplot(list(data[v].values))\n",
    "        plt.title(v)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotDataDistribution(df, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17_54_25\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now().strftime(\"%H_%M_%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (type(X_dfs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
