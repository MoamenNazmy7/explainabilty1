{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"service1906_1506.json\") as of:\n",
    "    data = json.load(of)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "computes = [c for c in data.keys() if c!=\"timespan\"]\n",
    "variables = [v for v in data[computes[0]] if v!='index' and v!='arrJob_scheduling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c= compute-1-26\n",
      "v= arrTemperature\n"
     ]
    }
   ],
   "source": [
    "#Check empty array\n",
    "def getEmptyArr(data, c):\n",
    "    cObj = data[c]\n",
    "    cDf = pd.DataFrame()\n",
    "    cDf['compute'] = [c for _ in data['timespan']]\n",
    "    cDf['timespan'] = data['timespan']\n",
    "    for v in variables:\n",
    "        vArr = np.array(cObj[v])\n",
    "        if len(vArr)==0:\n",
    "            print('c=', c)\n",
    "            print('v=', v)\n",
    "for c in computes:\n",
    "    getEmptyArr(data, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTarget(cDf, predictedVar, predictedStep, target):\n",
    "    cDf[target] = cDf[predictedVar].shift(-predictedStep)\n",
    "    cDf.dropna(inplace=True)\n",
    "    return cDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getComputeDf(data, c, predictedVar, predictedStep, target):\n",
    "    cObj = data[c]\n",
    "    cDf = pd.DataFrame()\n",
    "    cDf['compute'] = [c for _ in data['timespan']]\n",
    "    cDf['timespan'] = data['timespan']\n",
    "    for v in variables:\n",
    "        vArr = np.array(cObj[v])\n",
    "        if len(vArr)==0:\n",
    "            return None\n",
    "        else:\n",
    "            for i in range(len(vArr[0])):\n",
    "                cDf[v+str(i)] = vArr[:, i]\n",
    "    cDf['timespan'] = pd.to_datetime(cDf['timespan'])\n",
    "    return addTarget(cDf, predictedVar, predictedStep, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from IPython.display import FileLink\n",
    "import codecs, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportNPArrayToJson(a, fileName):\n",
    "    b = a.tolist()\n",
    "    json.dump(b, codecs.open(fileName, 'w', encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitTrainTest(predictedVar):\n",
    "    target = predictedVar + \"_target\"\n",
    "    predictedSteps = 4\n",
    "    df = pd.concat([x for x in [getComputeDf(data, c, predictedVar, predictedSteps, target) for c in computes] if type(x)!=\"NoneType\"])\n",
    "    \n",
    "    df = df.reset_index().drop('index', axis=1)\n",
    "    features = [x for x in df.columns if x not in ['compute', 'timespan', target]]\n",
    "        \n",
    "    X_dfs = []\n",
    "    y = []\n",
    "    numberOfSequences = 1\n",
    "    # generate training data.\n",
    "    for compute in computes:\n",
    "        cDf = df[df['compute']==compute]\n",
    "        if(len(cDf) > sequenceSteps):\n",
    "            randSteps = np.random.randint(0, len(cDf)-sequenceSteps, numberOfSequences)\n",
    "            for randStep in randSteps:\n",
    "                X_dfs.append(cDf.iloc[randStep:randStep+sequenceSteps])\n",
    "                y.append(X_dfs[-1][target].values[-1])\n",
    "\n",
    "    X_train_dfs, X_test_dfs, y_train, y_test = train_test_split(X_dfs, y, test_size=0.33)\n",
    "            \n",
    "    #Scale data\n",
    "\n",
    "    # combine the training data to create a scaler\n",
    "    train_dfs = pd.concat(X_train_dfs)\n",
    "\n",
    "    scaler = StandardScaler().fit(train_dfs[features].values)\n",
    "    \n",
    "    X_train = np.array([scaler.transform(item[features].values) for item in X_train_dfs])\n",
    "    X_test = np.array([scaler.transform(item[features].values) for item in X_test_dfs])\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    exportNPArrayToJson(X_train, 'newData/'+target+'_X_train_HPCC_'+str(sequenceSteps)+'.json')\n",
    "    exportNPArrayToJson(X_test, 'newData/'+target+'_X_test_HPCC_'+str(sequenceSteps)+'.json')\n",
    "    exportNPArrayToJson(y_train, 'newData/'+target+'_y_train_HPCC_'+str(sequenceSteps)+'.json')\n",
    "    exportNPArrayToJson(y_test, 'newData/'+target+'_y_test_HPCC_'+str(sequenceSteps)+'.json')\n",
    "    \n",
    "    FileLink('newData/'+target+'_X_train_HPCC_'+str(sequenceSteps)+'.json')\n",
    "    FileLink('newData/'+target+'_X_test_HPCC_'+str(sequenceSteps)+'.json')\n",
    "    FileLink('newData/'+target+'_y_train_HPCC_'+str(sequenceSteps)+'.json')\n",
    "    FileLink('newData/'+target+'_y_test_HPCC_'+str(sequenceSteps)+'.json')\n",
    "    \n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "\n",
    "# from keras import backend as K\n",
    "# K.set_session(K.tf.Session(config=K.tf.ConfigProto(intra_op_parallelism_threads=36, inter_op_parallelism_threads=36)))\n",
    "\n",
    "\n",
    "def createModel(l1Nodes, l2Nodes, d1Nodes, d2Nodes, inputShape):\n",
    "    # input layer\n",
    "    lstm1 = LSTM(l1Nodes, input_shape=inputShape, return_sequences=True, kernel_regularizer=regularizers.l2(0.1))\n",
    "    do1 = Dropout(0.2)\n",
    "    \n",
    "    lstm2 = LSTM(l2Nodes, return_sequences=True, kernel_regularizer=regularizers.l2(0.1))\n",
    "    do2 = Dropout(0.2)\n",
    "    \n",
    "    flatten = Flatten()\n",
    "    \n",
    "    dense1 = Dense(d1Nodes, activation='relu')\n",
    "    do3 = Dropout(0.2)\n",
    "    \n",
    "    dense2 = Dense(d2Nodes, activation='relu')\n",
    "    do4 = Dropout(0.2)\n",
    "    \n",
    "    # output layer\n",
    "    outL = Dense(1, activation='relu')\n",
    "    # combine the layers\n",
    "#     layers = [lstm1, do1, lstm2, do2, dense1, do3, dense2, do4, outL]\n",
    "    layers = [lstm1, lstm2, flatten,  dense1, dense2, outL]\n",
    "#     layers = [lstm1, flatten,  dense1, outL]\n",
    "\n",
    "    # create the model\n",
    "    model = Sequential(layers)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arrTemperature0\n",
      "2019-11-04 19:17:34.847275\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 249 samples, validate on 63 samples\n",
      "Epoch 1/40\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 4019.5911 - val_loss: 3750.1671\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3750.16706, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 2/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 3964.1338 - val_loss: 3672.7190\n",
      "\n",
      "Epoch 00002: val_loss improved from 3750.16706 to 3672.71896, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 3/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 3864.9169 - val_loss: 3541.9813\n",
      "\n",
      "Epoch 00003: val_loss improved from 3672.71896 to 3541.98133, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 4/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 3693.5626 - val_loss: 3332.1890\n",
      "\n",
      "Epoch 00004: val_loss improved from 3541.98133 to 3332.18902, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 5/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 3424.6888 - val_loss: 3008.0466\n",
      "\n",
      "Epoch 00005: val_loss improved from 3332.18902 to 3008.04659, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 6/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 3017.3392 - val_loss: 2547.3276\n",
      "\n",
      "Epoch 00006: val_loss improved from 3008.04659 to 2547.32764, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 7/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 2445.7816 - val_loss: 1966.9624\n",
      "\n",
      "Epoch 00007: val_loss improved from 2547.32764 to 1966.96237, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 8/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 1771.1583 - val_loss: 1377.8937\n",
      "\n",
      "Epoch 00008: val_loss improved from 1966.96237 to 1377.89369, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 9/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 1126.7865 - val_loss: 872.5221\n",
      "\n",
      "Epoch 00009: val_loss improved from 1377.89369 to 872.52211, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 10/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 624.9475 - val_loss: 535.9932\n",
      "\n",
      "Epoch 00010: val_loss improved from 872.52211 to 535.99317, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 11/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 354.8638 - val_loss: 347.8948\n",
      "\n",
      "Epoch 00011: val_loss improved from 535.99317 to 347.89477, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 12/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 237.4785 - val_loss: 279.6910\n",
      "\n",
      "Epoch 00012: val_loss improved from 347.89477 to 279.69099, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 13/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 205.4281 - val_loss: 230.1331\n",
      "\n",
      "Epoch 00013: val_loss improved from 279.69099 to 230.13306, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 14/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 164.5491 - val_loss: 182.2690\n",
      "\n",
      "Epoch 00014: val_loss improved from 230.13306 to 182.26900, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 15/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 125.2408 - val_loss: 150.1246\n",
      "\n",
      "Epoch 00015: val_loss improved from 182.26900 to 150.12458, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 16/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 104.5687 - val_loss: 128.6322\n",
      "\n",
      "Epoch 00016: val_loss improved from 150.12458 to 128.63217, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 17/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 92.8442 - val_loss: 112.3637\n",
      "\n",
      "Epoch 00017: val_loss improved from 128.63217 to 112.36375, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 18/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 82.9289 - val_loss: 99.2981\n",
      "\n",
      "Epoch 00018: val_loss improved from 112.36375 to 99.29808, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 19/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 78.3964 - val_loss: 92.4889\n",
      "\n",
      "Epoch 00019: val_loss improved from 99.29808 to 92.48894, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 20/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 75.1164 - val_loss: 89.1692\n",
      "\n",
      "Epoch 00020: val_loss improved from 92.48894 to 89.16917, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 21/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 72.4932 - val_loss: 87.0232\n",
      "\n",
      "Epoch 00021: val_loss improved from 89.16917 to 87.02317, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 22/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 69.9390 - val_loss: 85.8680\n",
      "\n",
      "Epoch 00022: val_loss improved from 87.02317 to 85.86803, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 23/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 67.9409 - val_loss: 84.3860\n",
      "\n",
      "Epoch 00023: val_loss improved from 85.86803 to 84.38597, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 24/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 66.3472 - val_loss: 82.4352\n",
      "\n",
      "Epoch 00024: val_loss improved from 84.38597 to 82.43523, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 25/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 64.7097 - val_loss: 81.3802\n",
      "\n",
      "Epoch 00025: val_loss improved from 82.43523 to 81.38017, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 26/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 63.0467 - val_loss: 79.4558\n",
      "\n",
      "Epoch 00026: val_loss improved from 81.38017 to 79.45582, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 27/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 61.2402 - val_loss: 78.6383\n",
      "\n",
      "Epoch 00027: val_loss improved from 79.45582 to 78.63834, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 28/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 59.5412 - val_loss: 77.2698\n",
      "\n",
      "Epoch 00028: val_loss improved from 78.63834 to 77.26979, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - 0s 2ms/step - loss: 57.9658 - val_loss: 75.6791\n",
      "\n",
      "Epoch 00029: val_loss improved from 77.26979 to 75.67907, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 30/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 56.3860 - val_loss: 74.2677\n",
      "\n",
      "Epoch 00030: val_loss improved from 75.67907 to 74.26768, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 31/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 54.8116 - val_loss: 72.7398\n",
      "\n",
      "Epoch 00031: val_loss improved from 74.26768 to 72.73983, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 32/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 53.4109 - val_loss: 71.4782\n",
      "\n",
      "Epoch 00032: val_loss improved from 72.73983 to 71.47825, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 33/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 52.1665 - val_loss: 70.0798\n",
      "\n",
      "Epoch 00033: val_loss improved from 71.47825 to 70.07975, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 34/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 50.8880 - val_loss: 68.9883\n",
      "\n",
      "Epoch 00034: val_loss improved from 70.07975 to 68.98829, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 35/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 49.6747 - val_loss: 67.8613\n",
      "\n",
      "Epoch 00035: val_loss improved from 68.98829 to 67.86133, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 36/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 48.6705 - val_loss: 66.8346\n",
      "\n",
      "Epoch 00036: val_loss improved from 67.86133 to 66.83460, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 37/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 47.5676 - val_loss: 65.6129\n",
      "\n",
      "Epoch 00037: val_loss improved from 66.83460 to 65.61293, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 38/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 46.5996 - val_loss: 64.6241\n",
      "\n",
      "Epoch 00038: val_loss improved from 65.61293 to 64.62405, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 39/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 45.7234 - val_loss: 63.4912\n",
      "\n",
      "Epoch 00039: val_loss improved from 64.62405 to 63.49121, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "Epoch 40/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 44.6259 - val_loss: 62.7020\n",
      "\n",
      "Epoch 00040: val_loss improved from 63.49121 to 62.70201, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5\n",
      "63/63 [==============================] - 0s 4ms/step\n",
      "Train on 249 samples, validate on 63 samples\n",
      "Epoch 1/40\n",
      "249/249 [==============================] - 1s 5ms/step - loss: 3946.5332 - val_loss: 3933.1016\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3933.10161, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 2/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 3840.7733 - val_loss: 3753.0844\n",
      "\n",
      "Epoch 00002: val_loss improved from 3933.10161 to 3753.08443, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 3/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 3633.1551 - val_loss: 3438.4186\n",
      "\n",
      "Epoch 00003: val_loss improved from 3753.08443 to 3438.41857, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 4/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 3283.4527 - val_loss: 2932.4561\n",
      "\n",
      "Epoch 00004: val_loss improved from 3438.41857 to 2932.45611, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 5/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 2738.8531 - val_loss: 2236.0099\n",
      "\n",
      "Epoch 00005: val_loss improved from 2932.45611 to 2236.00992, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 6/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 2048.2597 - val_loss: 1470.1546\n",
      "\n",
      "Epoch 00006: val_loss improved from 2236.00992 to 1470.15459, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 7/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 1379.6470 - val_loss: 886.7402\n",
      "\n",
      "Epoch 00007: val_loss improved from 1470.15459 to 886.74019, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 8/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 913.8000 - val_loss: 621.5592\n",
      "\n",
      "Epoch 00008: val_loss improved from 886.74019 to 621.55921, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 9/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 756.2337 - val_loss: 559.8003\n",
      "\n",
      "Epoch 00009: val_loss improved from 621.55921 to 559.80025, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 10/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 736.8905 - val_loss: 536.7907\n",
      "\n",
      "Epoch 00010: val_loss improved from 559.80025 to 536.79073, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 11/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 693.5647 - val_loss: 492.0220\n",
      "\n",
      "Epoch 00011: val_loss improved from 536.79073 to 492.02198, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 12/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 642.9919 - val_loss: 461.9652\n",
      "\n",
      "Epoch 00012: val_loss improved from 492.02198 to 461.96522, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 13/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 600.9950 - val_loss: 439.4230\n",
      "\n",
      "Epoch 00013: val_loss improved from 461.96522 to 439.42297, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 14/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 558.6567 - val_loss: 411.4894\n",
      "\n",
      "Epoch 00014: val_loss improved from 439.42297 to 411.48941, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 15/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 509.1078 - val_loss: 380.1717\n",
      "\n",
      "Epoch 00015: val_loss improved from 411.48941 to 380.17171, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 16/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 455.5973 - val_loss: 346.0366\n",
      "\n",
      "Epoch 00016: val_loss improved from 380.17171 to 346.03664, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 17/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 393.1879 - val_loss: 303.6458\n",
      "\n",
      "Epoch 00017: val_loss improved from 346.03664 to 303.64579, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 18/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 332.8766 - val_loss: 261.1739\n",
      "\n",
      "Epoch 00018: val_loss improved from 303.64579 to 261.17390, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 19/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 273.7455 - val_loss: 224.2357\n",
      "\n",
      "Epoch 00019: val_loss improved from 261.17390 to 224.23573, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 20/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - 0s 2ms/step - loss: 226.4947 - val_loss: 192.5920\n",
      "\n",
      "Epoch 00020: val_loss improved from 224.23573 to 192.59196, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 21/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 187.1277 - val_loss: 167.6110\n",
      "\n",
      "Epoch 00021: val_loss improved from 192.59196 to 167.61097, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 22/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 161.0396 - val_loss: 156.1738\n",
      "\n",
      "Epoch 00022: val_loss improved from 167.61097 to 156.17377, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 23/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 149.8530 - val_loss: 147.5351\n",
      "\n",
      "Epoch 00023: val_loss improved from 156.17377 to 147.53512, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 24/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 137.3970 - val_loss: 142.0448\n",
      "\n",
      "Epoch 00024: val_loss improved from 147.53512 to 142.04481, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 25/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 129.4475 - val_loss: 139.0970\n",
      "\n",
      "Epoch 00025: val_loss improved from 142.04481 to 139.09703, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 26/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 119.9695 - val_loss: 136.6487\n",
      "\n",
      "Epoch 00026: val_loss improved from 139.09703 to 136.64869, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 27/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 111.9527 - val_loss: 134.9366\n",
      "\n",
      "Epoch 00027: val_loss improved from 136.64869 to 134.93660, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 28/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 104.7256 - val_loss: 132.5062\n",
      "\n",
      "Epoch 00028: val_loss improved from 134.93660 to 132.50620, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 29/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 98.5210 - val_loss: 129.9723\n",
      "\n",
      "Epoch 00029: val_loss improved from 132.50620 to 129.97225, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 30/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 92.7580 - val_loss: 126.5467\n",
      "\n",
      "Epoch 00030: val_loss improved from 129.97225 to 126.54671, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 31/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 87.0256 - val_loss: 122.2028\n",
      "\n",
      "Epoch 00031: val_loss improved from 126.54671 to 122.20283, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 32/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 82.2819 - val_loss: 118.8449\n",
      "\n",
      "Epoch 00032: val_loss improved from 122.20283 to 118.84487, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 33/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 77.7809 - val_loss: 115.4529\n",
      "\n",
      "Epoch 00033: val_loss improved from 118.84487 to 115.45294, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 34/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 73.9683 - val_loss: 110.7324\n",
      "\n",
      "Epoch 00034: val_loss improved from 115.45294 to 110.73241, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 35/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 70.9595 - val_loss: 106.2517\n",
      "\n",
      "Epoch 00035: val_loss improved from 110.73241 to 106.25167, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 36/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 68.7953 - val_loss: 102.6350\n",
      "\n",
      "Epoch 00036: val_loss improved from 106.25167 to 102.63495, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 37/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 66.3148 - val_loss: 100.1661\n",
      "\n",
      "Epoch 00037: val_loss improved from 102.63495 to 100.16608, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 38/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 65.7883 - val_loss: 99.5161\n",
      "\n",
      "Epoch 00038: val_loss improved from 100.16608 to 99.51613, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 39/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 63.8268 - val_loss: 97.5670\n",
      "\n",
      "Epoch 00039: val_loss improved from 99.51613 to 97.56698, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "Epoch 40/40\n",
      "249/249 [==============================] - 0s 2ms/step - loss: 63.2733 - val_loss: 95.6536\n",
      "\n",
      "Epoch 00040: val_loss improved from 97.56698 to 95.65365, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5\n",
      "63/63 [==============================] - 0s 6ms/step\n",
      "Train on 250 samples, validate on 62 samples\n",
      "Epoch 1/40\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 4037.1346 - val_loss: 3635.1420\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3635.14200, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 2/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 3963.8166 - val_loss: 3556.6520\n",
      "\n",
      "Epoch 00002: val_loss improved from 3635.14200 to 3556.65202, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 3/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 3835.0714 - val_loss: 3415.9373\n",
      "\n",
      "Epoch 00003: val_loss improved from 3556.65202 to 3415.93726, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 4/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 3604.0721 - val_loss: 3187.8118\n",
      "\n",
      "Epoch 00004: val_loss improved from 3415.93726 to 3187.81177, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 5/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 3272.0298 - val_loss: 2857.8470\n",
      "\n",
      "Epoch 00005: val_loss improved from 3187.81177 to 2857.84702, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 6/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 2773.7418 - val_loss: 2424.5834\n",
      "\n",
      "Epoch 00006: val_loss improved from 2857.84702 to 2424.58339, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 7/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 2191.1554 - val_loss: 1876.0147\n",
      "\n",
      "Epoch 00007: val_loss improved from 2424.58339 to 1876.01468, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 8/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 1570.7100 - val_loss: 1323.3786\n",
      "\n",
      "Epoch 00008: val_loss improved from 1876.01468 to 1323.37863, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 9/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 1040.5570 - val_loss: 922.6953\n",
      "\n",
      "Epoch 00009: val_loss improved from 1323.37863 to 922.69528, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 10/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 712.3839 - val_loss: 707.8252\n",
      "\n",
      "Epoch 00010: val_loss improved from 922.69528 to 707.82517, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 2ms/step - loss: 566.0969 - val_loss: 626.5826\n",
      "\n",
      "Epoch 00011: val_loss improved from 707.82517 to 626.58262, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 12/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 510.9726 - val_loss: 566.1634\n",
      "\n",
      "Epoch 00012: val_loss improved from 626.58262 to 566.16341, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 13/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 441.4303 - val_loss: 487.7021\n",
      "\n",
      "Epoch 00013: val_loss improved from 566.16341 to 487.70213, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 14/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 372.5927 - val_loss: 413.0562\n",
      "\n",
      "Epoch 00014: val_loss improved from 487.70213 to 413.05621, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 15/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 321.9764 - val_loss: 353.5192\n",
      "\n",
      "Epoch 00015: val_loss improved from 413.05621 to 353.51920, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 16/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 285.0334 - val_loss: 287.4553\n",
      "\n",
      "Epoch 00016: val_loss improved from 353.51920 to 287.45531, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 17/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 248.6102 - val_loss: 249.3501\n",
      "\n",
      "Epoch 00017: val_loss improved from 287.45531 to 249.35006, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 18/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 229.2010 - val_loss: 222.0875\n",
      "\n",
      "Epoch 00018: val_loss improved from 249.35006 to 222.08750, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 19/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 217.1366 - val_loss: 204.3010\n",
      "\n",
      "Epoch 00019: val_loss improved from 222.08750 to 204.30101, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 20/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 207.0038 - val_loss: 195.3734\n",
      "\n",
      "Epoch 00020: val_loss improved from 204.30101 to 195.37341, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 21/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 200.7739 - val_loss: 188.9439\n",
      "\n",
      "Epoch 00021: val_loss improved from 195.37341 to 188.94392, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 22/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 194.3642 - val_loss: 183.2094\n",
      "\n",
      "Epoch 00022: val_loss improved from 188.94392 to 183.20937, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 23/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 188.0002 - val_loss: 177.6451\n",
      "\n",
      "Epoch 00023: val_loss improved from 183.20937 to 177.64513, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 24/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 180.5291 - val_loss: 172.9383\n",
      "\n",
      "Epoch 00024: val_loss improved from 177.64513 to 172.93834, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 25/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 175.3379 - val_loss: 166.0937\n",
      "\n",
      "Epoch 00025: val_loss improved from 172.93834 to 166.09370, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 26/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 167.0634 - val_loss: 160.2812\n",
      "\n",
      "Epoch 00026: val_loss improved from 166.09370 to 160.28123, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 27/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 160.3234 - val_loss: 156.2578\n",
      "\n",
      "Epoch 00027: val_loss improved from 160.28123 to 156.25779, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 28/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 153.8290 - val_loss: 148.5875\n",
      "\n",
      "Epoch 00028: val_loss improved from 156.25779 to 148.58748, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 29/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 146.5152 - val_loss: 143.3277\n",
      "\n",
      "Epoch 00029: val_loss improved from 148.58748 to 143.32773, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 30/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 139.7415 - val_loss: 138.4265\n",
      "\n",
      "Epoch 00030: val_loss improved from 143.32773 to 138.42648, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 31/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 132.7580 - val_loss: 133.8393\n",
      "\n",
      "Epoch 00031: val_loss improved from 138.42648 to 133.83929, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 32/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 125.6933 - val_loss: 128.6973\n",
      "\n",
      "Epoch 00032: val_loss improved from 133.83929 to 128.69729, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 33/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 118.0460 - val_loss: 123.3600\n",
      "\n",
      "Epoch 00033: val_loss improved from 128.69729 to 123.35998, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 34/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 110.8712 - val_loss: 119.5655\n",
      "\n",
      "Epoch 00034: val_loss improved from 123.35998 to 119.56549, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 35/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 104.7832 - val_loss: 117.2002\n",
      "\n",
      "Epoch 00035: val_loss improved from 119.56549 to 117.20025, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 36/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 96.9424 - val_loss: 112.5547\n",
      "\n",
      "Epoch 00036: val_loss improved from 117.20025 to 112.55472, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 37/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 91.1362 - val_loss: 108.0133\n",
      "\n",
      "Epoch 00037: val_loss improved from 112.55472 to 108.01325, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 38/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 86.7310 - val_loss: 105.4235\n",
      "\n",
      "Epoch 00038: val_loss improved from 108.01325 to 105.42352, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 39/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 81.1564 - val_loss: 101.2930\n",
      "\n",
      "Epoch 00039: val_loss improved from 105.42352 to 101.29299, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "Epoch 40/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 76.3248 - val_loss: 99.3011\n",
      "\n",
      "Epoch 00040: val_loss improved from 101.29299 to 99.30111, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5\n",
      "62/62 [==============================] - 1s 8ms/step\n",
      "Train on 250 samples, validate on 62 samples\n",
      "Epoch 1/40\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 3905.8742 - val_loss: 3946.2972\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3946.29719, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 3782.6942 - val_loss: 3765.1181\n",
      "\n",
      "Epoch 00002: val_loss improved from 3946.29719 to 3765.11807, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 3/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 3580.9605 - val_loss: 3444.6351\n",
      "\n",
      "Epoch 00003: val_loss improved from 3765.11807 to 3444.63509, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 4/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 3265.6661 - val_loss: 2955.0411\n",
      "\n",
      "Epoch 00004: val_loss improved from 3444.63509 to 2955.04109, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 5/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 2782.0679 - val_loss: 2338.6641\n",
      "\n",
      "Epoch 00005: val_loss improved from 2955.04109 to 2338.66409, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 6/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 2222.8273 - val_loss: 1684.5340\n",
      "\n",
      "Epoch 00006: val_loss improved from 2338.66409 to 1684.53405, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 7/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 1664.0212 - val_loss: 1113.6397\n",
      "\n",
      "Epoch 00007: val_loss improved from 1684.53405 to 1113.63965, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 8/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 1233.1583 - val_loss: 753.6911\n",
      "\n",
      "Epoch 00008: val_loss improved from 1113.63965 to 753.69110, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 9/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 985.9170 - val_loss: 576.2277\n",
      "\n",
      "Epoch 00009: val_loss improved from 753.69110 to 576.22766, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 10/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 833.2667 - val_loss: 486.7588\n",
      "\n",
      "Epoch 00010: val_loss improved from 576.22766 to 486.75876, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 11/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 689.1942 - val_loss: 383.7454\n",
      "\n",
      "Epoch 00011: val_loss improved from 486.75876 to 383.74544, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 12/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 583.9744 - val_loss: 347.7271\n",
      "\n",
      "Epoch 00012: val_loss improved from 383.74544 to 347.72713, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 13/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 476.2045 - val_loss: 314.7766\n",
      "\n",
      "Epoch 00013: val_loss improved from 347.72713 to 314.77662, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 14/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 392.4651 - val_loss: 288.6873\n",
      "\n",
      "Epoch 00014: val_loss improved from 314.77662 to 288.68735, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 15/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 332.3151 - val_loss: 274.4972\n",
      "\n",
      "Epoch 00015: val_loss improved from 288.68735 to 274.49725, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 16/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 298.9484 - val_loss: 274.0289\n",
      "\n",
      "Epoch 00016: val_loss improved from 274.49725 to 274.02894, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 17/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 275.4517 - val_loss: 274.5906\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 274.02894\n",
      "Epoch 18/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 263.3902 - val_loss: 275.4943\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 274.02894\n",
      "Epoch 19/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 248.9082 - val_loss: 271.9127\n",
      "\n",
      "Epoch 00019: val_loss improved from 274.02894 to 271.91266, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 20/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 236.1222 - val_loss: 264.8161\n",
      "\n",
      "Epoch 00020: val_loss improved from 271.91266 to 264.81607, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 21/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 224.6319 - val_loss: 261.0752\n",
      "\n",
      "Epoch 00021: val_loss improved from 264.81607 to 261.07517, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 22/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 211.9119 - val_loss: 252.8564\n",
      "\n",
      "Epoch 00022: val_loss improved from 261.07517 to 252.85642, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 23/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 201.5933 - val_loss: 244.4088\n",
      "\n",
      "Epoch 00023: val_loss improved from 252.85642 to 244.40876, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 24/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 189.1358 - val_loss: 241.5992\n",
      "\n",
      "Epoch 00024: val_loss improved from 244.40876 to 241.59924, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 25/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 179.0495 - val_loss: 237.7948\n",
      "\n",
      "Epoch 00025: val_loss improved from 241.59924 to 237.79479, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 26/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 168.9371 - val_loss: 235.2249\n",
      "\n",
      "Epoch 00026: val_loss improved from 237.79479 to 235.22485, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 27/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 160.8162 - val_loss: 230.1765\n",
      "\n",
      "Epoch 00027: val_loss improved from 235.22485 to 230.17652, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 28/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 151.5033 - val_loss: 227.0046\n",
      "\n",
      "Epoch 00028: val_loss improved from 230.17652 to 227.00456, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 29/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 142.6589 - val_loss: 221.1850\n",
      "\n",
      "Epoch 00029: val_loss improved from 227.00456 to 221.18496, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 30/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 136.1393 - val_loss: 214.7352\n",
      "\n",
      "Epoch 00030: val_loss improved from 221.18496 to 214.73515, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 31/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 128.8545 - val_loss: 208.2001\n",
      "\n",
      "Epoch 00031: val_loss improved from 214.73515 to 208.20014, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 32/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 122.3165 - val_loss: 203.2768\n",
      "\n",
      "Epoch 00032: val_loss improved from 208.20014 to 203.27684, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 33/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 116.3274 - val_loss: 197.3741\n",
      "\n",
      "Epoch 00033: val_loss improved from 203.27684 to 197.37413, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 34/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 2ms/step - loss: 110.5313 - val_loss: 192.4279\n",
      "\n",
      "Epoch 00034: val_loss improved from 197.37413 to 192.42793, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 35/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 105.0751 - val_loss: 180.7282\n",
      "\n",
      "Epoch 00035: val_loss improved from 192.42793 to 180.72823, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 36/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 99.3677 - val_loss: 169.4701\n",
      "\n",
      "Epoch 00036: val_loss improved from 180.72823 to 169.47013, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 37/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 94.1123 - val_loss: 161.9383\n",
      "\n",
      "Epoch 00037: val_loss improved from 169.47013 to 161.93827, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 38/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 88.5092 - val_loss: 155.9121\n",
      "\n",
      "Epoch 00038: val_loss improved from 161.93827 to 155.91206, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 39/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 84.6104 - val_loss: 150.3480\n",
      "\n",
      "Epoch 00039: val_loss improved from 155.91206 to 150.34801, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "Epoch 40/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 80.2074 - val_loss: 143.9893\n",
      "\n",
      "Epoch 00040: val_loss improved from 150.34801 to 143.98928, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5\n",
      "62/62 [==============================] - 1s 11ms/step\n",
      "Train on 250 samples, validate on 62 samples\n",
      "Epoch 1/40\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 3785.4126 - val_loss: 4194.0261\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4194.02607, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 2/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 3601.2779 - val_loss: 3978.8847\n",
      "\n",
      "Epoch 00002: val_loss improved from 4194.02607 to 3978.88468, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 3/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 3303.5842 - val_loss: 3649.6459\n",
      "\n",
      "Epoch 00003: val_loss improved from 3978.88468 to 3649.64590, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 4/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 2884.5803 - val_loss: 3147.1413\n",
      "\n",
      "Epoch 00004: val_loss improved from 3649.64590 to 3147.14130, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 5/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 2318.8165 - val_loss: 2457.7018\n",
      "\n",
      "Epoch 00005: val_loss improved from 3147.14130 to 2457.70179, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 6/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 1615.3364 - val_loss: 1670.8374\n",
      "\n",
      "Epoch 00006: val_loss improved from 2457.70179 to 1670.83740, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 7/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 950.1665 - val_loss: 970.3462\n",
      "\n",
      "Epoch 00007: val_loss improved from 1670.83740 to 970.34623, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 8/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 443.7162 - val_loss: 500.6338\n",
      "\n",
      "Epoch 00008: val_loss improved from 970.34623 to 500.63378, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 9/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 233.1601 - val_loss: 284.3520\n",
      "\n",
      "Epoch 00009: val_loss improved from 500.63378 to 284.35204, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 10/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 178.2217 - val_loss: 208.3729\n",
      "\n",
      "Epoch 00010: val_loss improved from 284.35204 to 208.37293, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 11/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 127.9603 - val_loss: 187.4288\n",
      "\n",
      "Epoch 00011: val_loss improved from 208.37293 to 187.42877, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 12/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 112.0693 - val_loss: 179.1846\n",
      "\n",
      "Epoch 00012: val_loss improved from 187.42877 to 179.18457, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 13/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 102.2918 - val_loss: 152.9222\n",
      "\n",
      "Epoch 00013: val_loss improved from 179.18457 to 152.92216, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 14/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 91.0057 - val_loss: 127.4379\n",
      "\n",
      "Epoch 00014: val_loss improved from 152.92216 to 127.43790, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 15/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 78.3365 - val_loss: 117.3048\n",
      "\n",
      "Epoch 00015: val_loss improved from 127.43790 to 117.30478, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 16/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 74.2080 - val_loss: 114.5667\n",
      "\n",
      "Epoch 00016: val_loss improved from 117.30478 to 114.56671, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 17/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 70.8918 - val_loss: 110.9104\n",
      "\n",
      "Epoch 00017: val_loss improved from 114.56671 to 110.91044, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 18/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 68.8167 - val_loss: 106.4253\n",
      "\n",
      "Epoch 00018: val_loss improved from 110.91044 to 106.42526, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 19/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 66.6655 - val_loss: 105.8881\n",
      "\n",
      "Epoch 00019: val_loss improved from 106.42526 to 105.88812, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 20/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 64.9639 - val_loss: 104.5862\n",
      "\n",
      "Epoch 00020: val_loss improved from 105.88812 to 104.58621, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 21/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 63.7809 - val_loss: 103.7231\n",
      "\n",
      "Epoch 00021: val_loss improved from 104.58621 to 103.72314, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 22/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 62.4433 - val_loss: 100.0901\n",
      "\n",
      "Epoch 00022: val_loss improved from 103.72314 to 100.09008, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 23/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 61.3920 - val_loss: 97.0365\n",
      "\n",
      "Epoch 00023: val_loss improved from 100.09008 to 97.03647, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 24/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 60.4181 - val_loss: 94.3693\n",
      "\n",
      "Epoch 00024: val_loss improved from 97.03647 to 94.36933, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 25/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 2ms/step - loss: 59.6465 - val_loss: 93.5229\n",
      "\n",
      "Epoch 00025: val_loss improved from 94.36933 to 93.52286, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 26/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 58.6846 - val_loss: 94.4910\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 93.52286\n",
      "Epoch 27/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 57.8573 - val_loss: 92.9746\n",
      "\n",
      "Epoch 00027: val_loss improved from 93.52286 to 92.97459, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 28/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 57.0162 - val_loss: 90.5180\n",
      "\n",
      "Epoch 00028: val_loss improved from 92.97459 to 90.51796, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 29/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 56.1568 - val_loss: 89.7593\n",
      "\n",
      "Epoch 00029: val_loss improved from 90.51796 to 89.75926, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 30/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 55.4641 - val_loss: 90.6306\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 89.75926\n",
      "Epoch 31/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 54.4873 - val_loss: 88.7131\n",
      "\n",
      "Epoch 00031: val_loss improved from 89.75926 to 88.71311, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 32/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 53.8113 - val_loss: 86.0380\n",
      "\n",
      "Epoch 00032: val_loss improved from 88.71311 to 86.03798, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 33/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 53.0859 - val_loss: 86.3298\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 86.03798\n",
      "Epoch 34/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 52.3844 - val_loss: 86.7844\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 86.03798\n",
      "Epoch 35/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 51.6651 - val_loss: 84.8705\n",
      "\n",
      "Epoch 00035: val_loss improved from 86.03798 to 84.87046, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 36/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 51.0587 - val_loss: 84.8212\n",
      "\n",
      "Epoch 00036: val_loss improved from 84.87046 to 84.82117, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 37/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 50.3611 - val_loss: 81.4907\n",
      "\n",
      "Epoch 00037: val_loss improved from 84.82117 to 81.49068, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "Epoch 38/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 49.5362 - val_loss: 82.7476\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 81.49068\n",
      "Epoch 39/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 49.0888 - val_loss: 84.4052\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 81.49068\n",
      "Epoch 40/40\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 48.3774 - val_loss: 81.0743\n",
      "\n",
      "Epoch 00040: val_loss improved from 81.49068 to 81.07432, saving model to newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5\n",
      "62/62 [==============================] - 1s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "# ten fold\n",
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "from datetime import datetime\n",
    "# import tensorflowjs as tfjs\n",
    "\n",
    "sequenceSteps = 100\n",
    "\n",
    "msescores = []\n",
    "model_config = \"config_8_8_8_4_ts\"+str(sequenceSteps)\n",
    "\n",
    "tempAllVariables = ['arrTemperature0', 'arrTemperature1', 'arrTemperature2', 'arrCPU_load0', 'arrMemory_usage0', 'arrFans_health0', 'arrFans_health1', 'arrFans_health2', 'arrFans_health3', 'arrPower_usage0']\n",
    "allVariables = ['arrTemperature0']\n",
    "timeList = []\n",
    "\n",
    "\n",
    "\n",
    "for feature in allVariables:\n",
    "    print(feature)\n",
    "    X_train, X_test, y_train, Y_test = splitTrainTest(feature)\n",
    "\n",
    "    for training_time in range(0,1):\n",
    "        start_time = datetime.now()\n",
    "        print(start_time)\n",
    "\n",
    "        counter= 0\n",
    "        for trainIdx, testIdx in kfold.split(X_train, y_train):\n",
    "            # create callbacks\n",
    "            model_path = feature+'_training_time_'+str(training_time)+'_best_model_fold_'+str(counter)+\"_\"+model_config+'.h5'\n",
    "            mc = ModelCheckpoint('newModel/'+model_path, monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "            es = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=1)\n",
    "            # create model\n",
    "            model = createModel(l1Nodes = 8, l2Nodes = 8, d1Nodes = 8, d2Nodes = 4, inputShape= (X_train.shape[1], X_train.shape[2]))\n",
    "            model.fit(X_train[trainIdx], y_train[trainIdx], validation_data=(X_train[testIdx], y_train[testIdx]), batch_size=32, epochs=40, callbacks=[mc, es])\n",
    "            # Done load the best model of this fold\n",
    "            saved_model = load_model('newModel/'+model_path)\n",
    "            msescores.append({'path': 'newModel/'+model_path, 'mse': saved_model.evaluate(X_train[testIdx], y_train[testIdx])})\n",
    "            counter = counter + 1\n",
    "        \n",
    "#             tfjs.converters.save_keras_model(saved_model, 'newModel/'+model_path)\n",
    "\n",
    "        end_time = datetime.now()\n",
    "    \n",
    "        timeList.append({'start': start_time, 'end': end_time, 'time': datetime.timestamp(end_time)-datetime.timestamp(start_time)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time:  1572916654.847275\n",
      "end time: 1572916789.971276\n",
      "training time:  135.12400102615356\n"
     ]
    }
   ],
   "source": [
    "print ('start time: ',  datetime.timestamp(start_time))\n",
    "print ('end time:', datetime.timestamp(end_time))\n",
    "print ('training time: ', datetime.timestamp(end_time)-datetime.timestamp(start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'path': 'newModel/arrTemperature0_training_time_0_best_model_fold_0_config_8_8_8_4_ts100.h5',\n",
       "  'mse': 62.702007354251926},\n",
       " {'path': 'newModel/arrTemperature0_training_time_0_best_model_fold_1_config_8_8_8_4_ts100.h5',\n",
       "  'mse': 95.65364886087085},\n",
       " {'path': 'newModel/arrTemperature0_training_time_0_best_model_fold_2_config_8_8_8_4_ts100.h5',\n",
       "  'mse': 99.30110537621283},\n",
       " {'path': 'newModel/arrTemperature0_training_time_0_best_model_fold_3_config_8_8_8_4_ts100.h5',\n",
       "  'mse': 143.98928316177862},\n",
       " {'path': 'newModel/arrTemperature0_training_time_0_best_model_fold_4_config_8_8_8_4_ts100.h5',\n",
       "  'mse': 81.0743162093624}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msescores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 100, 8)            608       \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 100, 8)            544       \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 8)                 6408      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 7,601\n",
      "Trainable params: 7,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# timeList\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and see data distribution\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plotAttrDataOfId(data, compute, features):\n",
    "    plt.figure(figsize=(30, 20))\n",
    "    for i, v in enumerate(features):\n",
    "        plt.subplot(10, 3, i+1)\n",
    "        cDf = df[df['compute']==compute]\n",
    "        plt.plot(cDf['timespan'], cDf[v])\n",
    "        plt.title(v)\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in np.random.randint(0, len(computes), 3):\n",
    "#     plotAttrDataOfId(df, computes[x], features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotDataDistribution(data, features):\n",
    "    plt.figure(figsize=(30, 10))\n",
    "    for i, v in enumerate(features):\n",
    "        plt.subplot(3, 10, i+1)\n",
    "        sns.distplot(list(data[v].values))\n",
    "        plt.title(v)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotDataDistribution(df, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now().strftime(\"%H_%M_%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in range(1,11\n",
    "                 )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (type(X_dfs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
